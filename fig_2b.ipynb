{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pw5yCgwZ7B7"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IJEJb3NAZ7CA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBgennaCZ7CH",
        "outputId": "0a4750b5-c95d-4735-f766-1ec1fd5a361a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Import the best device available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.mps.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyaDvDM8Z7CK"
      },
      "source": [
        "### Choice of dataset\n",
        "\n",
        "The first possible dataset is **permuted MNIST**. The model will be trained on different variations of the same dataset. Each variation corresponds to a different classification task as stated in the paper. The permuted MNIST dataset consists in fist flattening the black and white images of hand written digits and applying a random permutation to the whole dataset of flattened pixel data vectors.\n",
        "\n",
        "The second possible dataset is **rotated MNIST**. Each variation corresponds to MNIST rotated by $ 10(i-1)$ degree if $i$ is the index of the variation/task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "CUwrhoIcZ7CM"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "VAL_FRAC   = 0.1\n",
        "DEBUG      = True # accelerate code tests\n",
        "\n",
        "TRANSFORM = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.view(-1))  # Flatten the image\n",
        "])\n",
        "\n",
        "def take_subset(dataset, frac):\n",
        "    subset_size = int(frac * len(dataset))\n",
        "    indices = torch.randperm(len(dataset))[:subset_size]\n",
        "    return Subset(dataset, indices)\n",
        "\n",
        "def generate_permuted_mnist(i):\n",
        "    # load dataset\n",
        "    raw_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=TRANSFORM, download=True)\n",
        "    test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=TRANSFORM, download=True)\n",
        "\n",
        "    # Permute dataset splits\n",
        "    permutation = torch.randperm(28 * 28)\n",
        "    raw_dataset.data = raw_dataset.data.view(-1, 28 * 28)[:, permutation].view(-1, 28, 28)\n",
        "    test_dataset.data = test_dataset.data.view(-1, 28 * 28)[:, permutation].view(-1, 28, 28)\n",
        "\n",
        "    # DEBUG CODE\n",
        "    if DEBUG:\n",
        "        raw_dataset = take_subset(raw_dataset, 0.1)\n",
        "        test_dataset = take_subset(test_dataset, 0.1)\n",
        "\n",
        "    # Split train into train and validation\n",
        "    val_size = int(VAL_FRAC * len(raw_dataset))\n",
        "    train_size = len(raw_dataset) - val_size\n",
        "    torch.manual_seed(42) # make sure epochs have the same validation dataset\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(raw_dataset, [train_size, val_size])\n",
        "\n",
        "    # Turn into data loaders\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "#===================================================================================================\n",
        "# Added by Pierre\n",
        "def generate_rotated_mnist(i):\n",
        "\n",
        "\n",
        "    # Define constants\n",
        "    TRANSFORM = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    # Load datasets\n",
        "    raw_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=TRANSFORM, download=True)\n",
        "    test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=TRANSFORM, download=True)\n",
        "\n",
        "    # Rotate dataset splits\n",
        "    angle = 2 * np.pi * i / 10  # Define the rotation angle\n",
        "\n",
        "    def rotate_dataset(dataset, angle):\n",
        "        rotated_data = []\n",
        "        for j in range(len(dataset)):\n",
        "            img, label = dataset[j]\n",
        "            img = transforms.functional.rotate(img, angle * 180 / np.pi)  # Rotate image\n",
        "            img = img.view(-1)\n",
        "            rotated_data.append((img, label))\n",
        "        return rotated_data\n",
        "\n",
        "    raw_dataset = rotate_dataset(raw_dataset, angle)\n",
        "    test_dataset = rotate_dataset(test_dataset, angle)\n",
        "\n",
        "    # DEBUG CODE\n",
        "    if DEBUG:\n",
        "        raw_dataset = take_subset(raw_dataset, 0.1)\n",
        "        test_dataset = take_subset(test_dataset, 0.1)\n",
        "\n",
        "    # Split train into train and validation\n",
        "    val_size = int(VAL_FRAC * len(raw_dataset))\n",
        "    train_size = len(raw_dataset) - val_size\n",
        "    torch.manual_seed(42)  # make sure epochs have the same validation dataset\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(raw_dataset, [train_size, val_size])\n",
        "\n",
        "    # Turn into data loaders\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "#===================================================================================================\n",
        "\n",
        "def generate_tasks(n_tasks, dataset_gen):\n",
        "    \"\"\"\n",
        "    Used to generate N dataloaders corresponding to N different tasks.\n",
        "    Training dataset is split into training and validation.\n",
        "    \"\"\"\n",
        "\n",
        "    train_loaders = []\n",
        "    val_loaders = []\n",
        "    test_loaders = []\n",
        "\n",
        "    for i_task in range(n_tasks):\n",
        "        train_loader, val_loader, test_loader = dataset_gen(i_task)\n",
        "\n",
        "        print(f'Task {i_task + 1} Splits: {len(train_loader.dataset)} train, {len(val_loader.dataset)} val, {len(test_loader.dataset)} test')\n",
        "\n",
        "        train_loaders.append(train_loader)\n",
        "        val_loaders.append(val_loader)\n",
        "        test_loaders.append(test_loader)\n",
        "\n",
        "    return train_loaders, val_loaders, test_loaders\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxwDdZYvZ7CQ"
      },
      "source": [
        "## Util Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVcftF1BZ7CS"
      },
      "source": [
        "### Validation\n",
        "\n",
        "Appendix 4.1 suggests figure 3B was realized using early stopping, which requires the use of a validation split. For this reason, we split the training dataset into a validation and training dataset. Early stopping is as follows in the paper: if validation is seen increasing 5 consecutive times (arbitrary threshold), training is stopped and the model performing the best on previous epochs is kept. This requires to periodically save the dataset and load again the best performing model at the end of the training function.\n",
        "\n",
        "Validation dataset is used to compute the validation loss, however the test set is used to compute the test accuracy (or `Fraction correct` in the paper)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "u_6JmfltZ7CU"
      },
      "outputs": [],
      "source": [
        "def evaluate_accuracy(\n",
        "    model: torch.nn.Module,\n",
        "    test_dataloader: DataLoader,\n",
        "    device: torch.device,\n",
        "):\n",
        "    \"\"\"\n",
        "    Evaluate test accuracy of the given model on the test split\n",
        "    \"\"\"\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in test_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ujw2tAHHZ7CX"
      },
      "outputs": [],
      "source": [
        "def validate_epoch(\n",
        "    model: torch.nn.Module,\n",
        "    val_dataloader: DataLoader,\n",
        "    criterion,\n",
        "    device: torch.device,\n",
        "    early_stopping = False\n",
        "):\n",
        "    \"\"\"\n",
        "    This function validates the model on the validation dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    val_loss = 0.0\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    count_increase = 0\n",
        "    previous_loss = -1\n",
        "    best_model = None\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(val_dataloader):\n",
        "            # move data and target to device\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            # do the forward pass\n",
        "            output = model(data)\n",
        "\n",
        "            # compute the loss\n",
        "            try:    #Case of EWC\n",
        "                loss = criterion(output, target, model)\n",
        "            except TypeError:\n",
        "                loss = criterion(output, target)\n",
        "\n",
        "            # print statistics\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    return val_loss / len(val_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMDP9uSAZ7Cc"
      },
      "source": [
        "### Training Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UktMEJbNZ7Cc"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "    model: torch.nn.Module,\n",
        "    train_dataloader: DataLoader,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    criterion,\n",
        "    device: torch.device,\n",
        "):\n",
        "    \"\"\"\n",
        "    Training function. Loads the batch, perform forward pass, compute gradients and perform backward pass.\n",
        "    Only difference is that you can pass the loss function as an argument.\n",
        "    This allows to use a simple cross entropy loss function, or a more complex one including L2 or EWC regularization.\n",
        "    \"\"\"\n",
        "\n",
        "    train_loss = 0.0\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
        "        # move data and target to device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # do the forward pass\n",
        "        output = model(data)\n",
        "\n",
        "        # compute the loss\n",
        "        try:    # For EWC\n",
        "            loss = criterion(output, target, model)\n",
        "        except TypeError:\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "        # compute the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # perform the gradient step\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    return train_loss / len(train_dataloader)\n",
        "\n",
        "def fit(\n",
        "    model: torch.nn.Module,\n",
        "    train_dataloader: DataLoader,\n",
        "    val_dataloader: DataLoader,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    scheduler: torch.optim.lr_scheduler.LRScheduler,\n",
        "    criterion,\n",
        "    epochs: int,\n",
        "    device: torch.device,\n",
        "    early_stopping = False\n",
        "):\n",
        "    \"\"\"\n",
        "    The fit method calls the train_epoch() method for a specified\n",
        "    number of epochs and returns the train and validation losses.\n",
        "    \"\"\"\n",
        "\n",
        "    global N_TASKS\n",
        "\n",
        "    # keep track of losses and accuracies\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    count_increase = 0\n",
        "    best_model = None   # For early stopping\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        t = time() # current time\n",
        "\n",
        "        # train function\n",
        "        train_loss = train_epoch(\n",
        "            model=model,\n",
        "            train_dataloader=train_dataloader,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            device=device,\n",
        "        )\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # validate epoch\n",
        "        val_loss = validate_epoch(\n",
        "            model=model,\n",
        "            val_dataloader=val_dataloader,\n",
        "            criterion=criterion,\n",
        "            device=device,\n",
        "            early_stopping=early_stopping\n",
        "        )\n",
        "\n",
        "        if early_stopping and len(val_losses) >0 and val_loss > max(val_losses):\n",
        "            best_model = model.state_dict()\n",
        "\n",
        "        if early_stopping and epoch > 0:\n",
        "            if val_loss > val_losses[-1]:\n",
        "                count_increase += 1\n",
        "                if count_increase == 5:\n",
        "                    print(f\"Early stopping at epoch {epoch + 1}\")\n",
        "                    # We reset the weights to the best epoch in terms of validation error\n",
        "                    model.load_state_dict(best_model)\n",
        "                    return train_losses, val_losses\n",
        "            else:\n",
        "                count_increase = 0\n",
        "\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "\n",
        "        # step scheduler if needed\n",
        "        if scheduler != None:\n",
        "            scheduler.step()\n",
        "\n",
        "        dt = time() - t # time difference\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}]: train={round(train_loss, 4)} val={round(val_loss, 4)}, ({round(dt, 2)}s)\")\n",
        "\n",
        "    return train_losses, val_losses\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVYLa34PZ7Ce"
      },
      "source": [
        "## EWC loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "U-2rSqjjZ7Ce"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "class EWC(object):\n",
        "    def __init__(self, model, dataset: list):\n",
        "\n",
        "        self.model = model\n",
        "        self.dataset = dataset\n",
        "\n",
        "        self.params = {n: p for n, p in self.model.named_parameters() if p.requires_grad}\n",
        "        self._means = {}\n",
        "        self._precision_matrices = self._diag_fisher()\n",
        "\n",
        "        for n, p in deepcopy(self.params).items():\n",
        "            self._means[n] = p.data\n",
        "\n",
        "    def _diag_fisher(self):\n",
        "        precision_matrices = {}\n",
        "        for n, p in deepcopy(self.params).items():\n",
        "            p.data.zero_()\n",
        "            precision_matrices[n] = p.data\n",
        "\n",
        "        self.model.eval()\n",
        "        for batch_idx, (data, target) in enumerate(self.dataset):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            self.model.zero_grad()\n",
        "            output = self.model(data)\n",
        "            loss = F.nll_loss(F.log_softmax(output, dim=1), target)\n",
        "            loss.backward()\n",
        "\n",
        "            for n, p in self.model.named_parameters():\n",
        "                precision_matrices[n].data += p.grad.data ** 2 / len(self.dataset)\n",
        "\n",
        "        precision_matrices = {n: p for n, p in precision_matrices.items()}\n",
        "        return precision_matrices\n",
        "\n",
        "    def penalty(self, new_model):\n",
        "        loss = 0\n",
        "        for n, p in new_model.named_parameters():\n",
        "            _loss = 1/2 *self._precision_matrices[n] * (p - self._means[n]) ** 2\n",
        "            loss += _loss.sum()\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wHposqgZ7Cf"
      },
      "source": [
        "## Model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNmRBcgGZ7Cf",
        "outputId": "4d97eb14-c545-4bb7-c870-6ebb76445a09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Parameters:  478410\n"
          ]
        }
      ],
      "source": [
        "class SmallNet(torch.nn.Module):\n",
        "    def __init__(self, width_hidden_layers = 400):\n",
        "        super(SmallNet, self).__init__()\n",
        "\n",
        "        self._input_size = 28 * 28\n",
        "        self._n_ff      = width_hidden_layers\n",
        "        self._n_output   = 10\n",
        "        self._do_input   = 0.2\n",
        "        self._do_ff      = 0.5\n",
        "\n",
        "        self.do0 = torch.nn.Dropout(self._do_input)\n",
        "\n",
        "        self.ff1 = torch.nn.Linear(self._input_size, self._n_ff)\n",
        "        self.do1 = torch.nn.Dropout(self._do_ff)\n",
        "\n",
        "        self.ff2 = torch.nn.Linear(self._n_ff, self._n_ff)\n",
        "        self.do2 = torch.nn.Dropout(self._do_ff)\n",
        "\n",
        "        #self.ff3 = torch.nn.Linear(self._n_ff, self._n_ff)\n",
        "        #self.do3 = torch.nn.Dropout(self._do_ff)\n",
        "\n",
        "        #self.ff4 = torch.nn.Linear(self._n_ff, self._n_ff)\n",
        "        #self.do4 = torch.nn.Dropout(self._do_ff)\n",
        "\n",
        "        #self.ff5 = torch.nn.Linear(self._n_ff, self._n_ff)\n",
        "        #self.do5 = torch.nn.Dropout(self._do_ff)\n",
        "\n",
        "        #self.ff6 = torch.nn.Linear(self._n_ff, self._n_ff)\n",
        "        #self.do6 = torch.nn.Dropout(self._do_ff)\n",
        "\n",
        "        self.ff7 = torch.nn.Linear(self._n_ff, self._n_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # input dropout of 20% as stated in paper\n",
        "        x = self.do0(x)\n",
        "\n",
        "        # dense FF hidden layers, each with 50% dropout and ReLU activation\n",
        "        # dropout is generally placed after the activation\n",
        "        x = self.do1(F.relu(self.ff1(x)))\n",
        "        x = self.do2(F.relu(self.ff2(x)))\n",
        "        #x = self.do3(F.relu(self.ff3(x)))\n",
        "        #x = self.do4(F.relu(self.ff4(x)))\n",
        "        #x = self.do5(F.relu(self.ff5(x)))\n",
        "        #x = self.do6(F.relu(self.ff6(x)))\n",
        "\n",
        "        # classification layer\n",
        "        x = self.ff7(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "print(\"Model Parameters: \", sum(p.numel() for p in SmallNet().parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5ka8MHDxbfp"
      },
      "source": [
        "## Grid Search for learning rate and width of hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HM7bKrd5xmC-",
        "outputId": "4aad8ff6-28a5-4fb4-c966-5c232e2c6a16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rate : 0.001 ; Width layer : 400\n",
            "Task 1 Splits: 5400 train, 600 val, 1000 test\n",
            "Epoch [1/10]: train=2.3033 val=2.3009, (0.8s)\n",
            "Epoch [2/10]: train=2.302 val=2.2998, (0.8s)\n",
            "Epoch [3/10]: train=2.3001 val=2.2987, (1.0s)\n",
            "Epoch [4/10]: train=2.2991 val=2.2976, (0.8s)\n",
            "Epoch [5/10]: train=2.2987 val=2.2965, (0.7s)\n",
            "Epoch [6/10]: train=2.298 val=2.2953, (0.6s)\n",
            "Epoch [7/10]: train=2.296 val=2.2942, (0.6s)\n",
            "Epoch [8/10]: train=2.2959 val=2.2931, (0.6s)\n",
            "Epoch [9/10]: train=2.2932 val=2.2919, (0.7s)\n",
            "Epoch [10/10]: train=2.2923 val=2.2908, (0.6s)\n",
            "Learning rate : 0.001 ; Width layer : 577\n",
            "Task 1 Splits: 5400 train, 600 val, 1000 test\n",
            "Epoch [1/10]: train=2.305 val=2.3033, (0.7s)\n",
            "Epoch [2/10]: train=2.3027 val=2.3018, (0.6s)\n",
            "Epoch [3/10]: train=2.3022 val=2.3003, (0.7s)\n",
            "Epoch [4/10]: train=2.301 val=2.2988, (0.7s)\n",
            "Epoch [5/10]: train=2.3002 val=2.2973, (0.6s)\n",
            "Epoch [6/10]: train=2.2962 val=2.2958, (0.6s)\n",
            "Epoch [7/10]: train=2.2959 val=2.2943, (0.6s)\n",
            "Epoch [8/10]: train=2.2948 val=2.2928, (0.6s)\n",
            "Epoch [9/10]: train=2.2929 val=2.2913, (0.9s)\n",
            "Epoch [10/10]: train=2.2929 val=2.2898, (0.9s)\n",
            "Learning rate : 0.001 ; Width layer : 755\n",
            "Task 1 Splits: 5400 train, 600 val, 1000 test\n",
            "Epoch [1/10]: train=2.3074 val=2.3042, (0.8s)\n",
            "Epoch [2/10]: train=2.3058 val=2.3024, (0.7s)\n",
            "Epoch [3/10]: train=2.3049 val=2.3006, (0.6s)\n",
            "Epoch [4/10]: train=2.3 val=2.2987, (0.6s)\n",
            "Epoch [5/10]: train=2.3016 val=2.2969, (0.6s)\n",
            "Epoch [6/10]: train=2.2976 val=2.295, (0.6s)\n",
            "Epoch [7/10]: train=2.2968 val=2.2932, (0.6s)\n",
            "Epoch [8/10]: train=2.2941 val=2.2914, (0.7s)\n",
            "Epoch [9/10]: train=2.2942 val=2.2896, (0.6s)\n",
            "Epoch [10/10]: train=2.2914 val=2.2877, (0.6s)\n",
            "Learning rate : 0.001 ; Width layer : 933\n",
            "Task 1 Splits: 5400 train, 600 val, 1000 test\n",
            "Epoch [1/10]: train=2.3029 val=2.3018, (0.7s)\n",
            "Epoch [2/10]: train=2.3002 val=2.2994, (0.6s)\n",
            "Epoch [3/10]: train=2.2987 val=2.2969, (0.7s)\n",
            "Epoch [4/10]: train=2.2975 val=2.2945, (0.6s)\n",
            "Epoch [5/10]: train=2.2936 val=2.2921, (0.6s)\n",
            "Epoch [6/10]: train=2.2914 val=2.2897, (0.9s)\n",
            "Epoch [7/10]: train=2.2902 val=2.2873, (0.9s)\n",
            "Epoch [8/10]: train=2.2874 val=2.2848, (0.9s)\n",
            "Epoch [9/10]: train=2.2871 val=2.2824, (0.6s)\n",
            "Epoch [10/10]: train=2.2853 val=2.28, (0.7s)\n",
            "Learning rate : 0.001 ; Width layer : 1111\n",
            "Task 1 Splits: 5400 train, 600 val, 1000 test\n",
            "Epoch [1/10]: train=2.3058 val=2.3027, (0.7s)\n",
            "Epoch [2/10]: train=2.304 val=2.3001, (0.7s)\n",
            "Epoch [3/10]: train=2.3013 val=2.2976, (0.7s)\n",
            "Epoch [4/10]: train=2.2989 val=2.295, (0.6s)\n",
            "Epoch [5/10]: train=2.296 val=2.2924, (0.6s)\n",
            "Epoch [6/10]: train=2.2956 val=2.2899, (0.7s)\n",
            "Epoch [7/10]: train=2.2919 val=2.2873, (0.6s)\n",
            "Epoch [8/10]: train=2.2917 val=2.2848, (0.6s)\n",
            "Epoch [9/10]: train=2.2881 val=2.2822, (0.7s)\n",
            "Epoch [10/10]: train=2.2857 val=2.2797, (0.6s)\n",
            "Learning rate : 0.001 ; Width layer : 1288\n",
            "Task 1 Splits: 5400 train, 600 val, 1000 test\n",
            "Epoch [1/10]: train=2.3024 val=2.297, (0.7s)\n",
            "Epoch [2/10]: train=2.2992 val=2.2945, (0.8s)\n",
            "Epoch [3/10]: train=2.2964 val=2.2919, (0.8s)\n",
            "Epoch [4/10]: train=2.2944 val=2.2894, (1.0s)\n",
            "Epoch [5/10]: train=2.2908 val=2.2868, (0.8s)\n",
            "Epoch [6/10]: train=2.2877 val=2.2843, (0.7s)\n",
            "Epoch [7/10]: train=2.2864 val=2.2817, (0.7s)\n",
            "Epoch [8/10]: train=2.2843 val=2.2792, (0.6s)\n",
            "Epoch [9/10]: train=2.282 val=2.2766, (0.7s)\n",
            "Epoch [10/10]: train=2.2783 val=2.2741, (0.7s)\n",
            "Learning rate : 0.001 ; Width layer : 1466\n",
            "Task 1 Splits: 5400 train, 600 val, 1000 test\n",
            "Epoch [1/10]: train=2.3054 val=2.3054, (0.7s)\n",
            "Epoch [2/10]: train=2.3022 val=2.3026, (0.6s)\n",
            "Epoch [3/10]: train=2.2986 val=2.2998, (0.7s)\n",
            "Epoch [4/10]: train=2.2966 val=2.297, (0.7s)\n",
            "Epoch [5/10]: train=2.2921 val=2.2943, (0.7s)\n",
            "Epoch [6/10]: train=2.2916 val=2.2915, (0.9s)\n",
            "Epoch [7/10]: train=2.2901 val=2.2888, (1.0s)\n",
            "Epoch [8/10]: train=2.2852 val=2.2861, (0.8s)\n",
            "Epoch [9/10]: train=2.2821 val=2.2833, (0.9s)\n",
            "Epoch [10/10]: train=2.2782 val=2.2806, (1.0s)\n",
            "Learning rate : 0.001 ; Width layer : 1644\n",
            "Task 1 Splits: 5400 train, 600 val, 1000 test\n",
            "Epoch [1/10]: train=2.3072 val=2.3029, (0.7s)\n",
            "Epoch [2/10]: train=2.3033 val=2.2996, (0.7s)\n",
            "Epoch [3/10]: train=2.2986 val=2.2962, (0.7s)\n",
            "Epoch [4/10]: train=2.2961 val=2.2929, (0.7s)\n",
            "Epoch [5/10]: train=2.2942 val=2.2896, (0.7s)\n",
            "Epoch [6/10]: train=2.2902 val=2.2864, (0.7s)\n",
            "Epoch [7/10]: train=2.2867 val=2.2831, (0.7s)\n",
            "Epoch [8/10]: train=2.2837 val=2.2799, (0.7s)\n",
            "Epoch [9/10]: train=2.2802 val=2.2766, (0.7s)\n",
            "Epoch [10/10]: train=2.2766 val=2.2734, (0.7s)\n",
            "Learning rate : 0.001 ; Width layer : 1822\n",
            "Task 1 Splits: 5400 train, 600 val, 1000 test\n",
            "Epoch [1/10]: train=2.3057 val=2.3033, (0.7s)\n",
            "Epoch [2/10]: train=2.3053 val=2.2998, (0.7s)\n",
            "Epoch [3/10]: train=2.3003 val=2.2963, (0.7s)\n",
            "Epoch [4/10]: train=2.2976 val=2.2929, (0.7s)\n",
            "Epoch [5/10]: train=2.2947 val=2.2894, (0.9s)\n",
            "Epoch [6/10]: train=2.2915 val=2.286, (0.9s)\n",
            "Epoch [7/10]: train=2.2881 val=2.2825, (1.1s)\n",
            "Epoch [8/10]: train=2.2858 val=2.279, (0.7s)\n",
            "Epoch [9/10]: train=2.2813 val=2.2756, (0.7s)\n",
            "Epoch [10/10]: train=2.2789 val=2.2721, (0.7s)\n",
            "Learning rate : 0.001 ; Width layer : 2000\n",
            "Task 1 Splits: 5400 train, 600 val, 1000 test\n",
            "Epoch [1/10]: train=2.3037 val=2.3021, (0.7s)\n",
            "Epoch [2/10]: train=2.2999 val=2.2983, (0.7s)\n",
            "Epoch [3/10]: train=2.2978 val=2.2946, (0.7s)\n",
            "Epoch [4/10]: train=2.2935 val=2.2909, (0.7s)\n",
            "Epoch [5/10]: train=2.2916 val=2.2872, (0.7s)\n",
            "Epoch [6/10]: train=2.2875 val=2.2835, (0.7s)\n",
            "Epoch [7/10]: train=2.2836 val=2.2799, (0.7s)\n",
            "Epoch [8/10]: train=2.2809 val=2.2762, (0.7s)\n",
            "Epoch [9/10]: train=2.2773 val=2.2725, (0.7s)\n",
            "Epoch [10/10]: train=2.2754 val=2.2688, (0.7s)\n",
            "Best parameters: {'width_hidden_layer': 2000}\n",
            "Best validation loss: 2.2688498497009277\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "N_EPOCHS = 10\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    #'lr': np.logspace(-5, -3, 10),\n",
        "    'width_hidden_layer': np.linspace(400, 2000, 10).astype(int)\n",
        "}\n",
        "\n",
        "width_hidden_layer = 800\n",
        "lr=0.001\n",
        "# Initialize variables to store the best parameters and the best validation loss\n",
        "best_params = None\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "# Perform grid search\n",
        "for params in ParameterGrid(param_grid):\n",
        "\n",
        "    #lr = params['lr']\n",
        "    width_hidden_layer = params['width_hidden_layer']\n",
        "    print(\"Learning rate :\", lr, '; Width layer :', width_hidden_layer)\n",
        "    # Initialize model with the current width_hidden_layer\n",
        "    model = SmallNet(width_hidden_layers=width_hidden_layer)\n",
        "    model.to(device)\n",
        "\n",
        "    # Define optimizer with the current learning rate\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)#, momentum=0.9)\n",
        "    criterion = F.cross_entropy\n",
        "\n",
        "    # Train the model\n",
        "    train_dataloader, val_dataloader, _ = generate_tasks(1, generate_permuted_mnist)\n",
        "    train_losses, val_losses = fit(\n",
        "        model=model,\n",
        "        train_dataloader=train_dataloader[0],\n",
        "        val_dataloader=val_dataloader[0],\n",
        "        optimizer=optimizer,\n",
        "        scheduler=None,\n",
        "        criterion=criterion,\n",
        "        epochs=N_EPOCHS,\n",
        "        device=device,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # Get the validation loss of the last epoch\n",
        "    val_loss = val_losses[-1]\n",
        "\n",
        "    # Update the best parameters if the current validation loss is lower\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_params = params\n",
        "\n",
        "print(f'Best parameters: {best_params}')\n",
        "print(f'Best validation loss: {best_val_loss}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp26C908Z7Ch"
      },
      "source": [
        "## Training Script\n",
        "\n",
        "The training script generates $N$ different tasks and calls the `fit(..)` function as many times on different tasks. It then saves the curves and model obtained. It has to be ran multiple times with different loss functions to generate subfigure 2A\n",
        "\n",
        "No scheduler seems to have been used in the paper, so we are not using any here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6EkEwTlZ7Ch",
        "outputId": "96a92323-6dbc-40ae-ba5a-cf6470eb72d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task 1 Splits: 5400 train, 600 val, 1000 test\n",
            "Task 2 Splits: 5400 train, 600 val, 1000 test\n",
            "Task 3 Splits: 5400 train, 600 val, 1000 test\n",
            "Task 4 Splits: 5400 train, 600 val, 1000 test\n",
            "Task 5 Splits: 5400 train, 600 val, 1000 test\n",
            "Task 6 Splits: 5400 train, 600 val, 1000 test\n",
            "Task 7 Splits: 5400 train, 600 val, 1000 test\n",
            "Task 8 Splits: 5400 train, 600 val, 1000 test\n",
            "Task 9 Splits: 5400 train, 600 val, 1000 test\n",
            "Task 10 Splits: 5400 train, 600 val, 1000 test\n",
            "================================================\n",
            "EWC\n",
            "Training on task 1...\n",
            "Epoch [1/100]: train=2.302 val=2.2958, (0.3s)\n",
            "Epoch [2/100]: train=2.2976 val=2.2922, (0.3s)\n",
            "Epoch [3/100]: train=2.2948 val=2.2887, (0.3s)\n",
            "Epoch [4/100]: train=2.2912 val=2.2852, (0.2s)\n",
            "Epoch [5/100]: train=2.288 val=2.2816, (0.2s)\n",
            "Epoch [6/100]: train=2.2841 val=2.2781, (0.2s)\n",
            "Epoch [7/100]: train=2.2794 val=2.2746, (0.2s)\n",
            "Epoch [8/100]: train=2.2781 val=2.2711, (0.2s)\n",
            "Epoch [9/100]: train=2.2755 val=2.2675, (0.2s)\n",
            "Epoch [10/100]: train=2.2701 val=2.2639, (0.2s)\n",
            "Epoch [11/100]: train=2.2678 val=2.2604, (0.2s)\n",
            "Epoch [12/100]: train=2.2648 val=2.2568, (0.3s)\n",
            "Epoch [13/100]: train=2.2608 val=2.2531, (0.2s)\n",
            "Epoch [14/100]: train=2.259 val=2.2494, (0.2s)\n",
            "Epoch [15/100]: train=2.2545 val=2.2457, (0.2s)\n",
            "Epoch [16/100]: train=2.2508 val=2.242, (0.2s)\n",
            "Epoch [17/100]: train=2.2475 val=2.2383, (0.2s)\n",
            "Epoch [18/100]: train=2.2434 val=2.2345, (0.3s)\n",
            "Epoch [19/100]: train=2.241 val=2.2306, (0.3s)\n",
            "Epoch [20/100]: train=2.2379 val=2.2268, (0.3s)\n",
            "Epoch [21/100]: train=2.2342 val=2.2228, (0.3s)\n",
            "Epoch [22/100]: train=2.2304 val=2.2188, (0.3s)\n",
            "Epoch [23/100]: train=2.2258 val=2.2147, (0.2s)\n",
            "Epoch [24/100]: train=2.2218 val=2.2106, (0.2s)\n",
            "Epoch [25/100]: train=2.2193 val=2.2065, (0.2s)\n",
            "Epoch [26/100]: train=2.2143 val=2.2022, (0.2s)\n",
            "Epoch [27/100]: train=2.2112 val=2.1979, (0.2s)\n",
            "Epoch [28/100]: train=2.2077 val=2.1935, (0.2s)\n",
            "Epoch [29/100]: train=2.2029 val=2.189, (0.2s)\n",
            "Epoch [30/100]: train=2.2 val=2.1844, (0.2s)\n",
            "Epoch [31/100]: train=2.1946 val=2.1797, (0.2s)\n",
            "Epoch [32/100]: train=2.1918 val=2.175, (0.2s)\n",
            "Epoch [33/100]: train=2.1861 val=2.1702, (0.2s)\n",
            "Epoch [34/100]: train=2.1829 val=2.1653, (0.2s)\n",
            "Epoch [35/100]: train=2.1769 val=2.1602, (0.2s)\n",
            "Epoch [36/100]: train=2.1736 val=2.1551, (0.2s)\n",
            "Epoch [37/100]: train=2.1691 val=2.1499, (0.2s)\n",
            "Epoch [38/100]: train=2.1655 val=2.1445, (0.2s)\n",
            "Epoch [39/100]: train=2.1586 val=2.1391, (0.2s)\n",
            "Epoch [40/100]: train=2.1544 val=2.1335, (0.2s)\n",
            "Epoch [41/100]: train=2.1477 val=2.1277, (0.2s)\n",
            "Epoch [42/100]: train=2.1441 val=2.1219, (0.2s)\n",
            "Epoch [43/100]: train=2.1382 val=2.1159, (0.2s)\n",
            "Epoch [44/100]: train=2.1344 val=2.1098, (0.2s)\n",
            "Epoch [45/100]: train=2.1271 val=2.1035, (0.2s)\n",
            "Epoch [46/100]: train=2.1239 val=2.0972, (0.2s)\n",
            "Epoch [47/100]: train=2.1181 val=2.0906, (0.2s)\n",
            "Epoch [48/100]: train=2.1105 val=2.0839, (0.2s)\n",
            "Epoch [49/100]: train=2.1071 val=2.0771, (0.2s)\n",
            "Epoch [50/100]: train=2.0992 val=2.07, (0.2s)\n",
            "Epoch [51/100]: train=2.0947 val=2.0629, (0.2s)\n",
            "Epoch [52/100]: train=2.0858 val=2.0555, (0.2s)\n",
            "Epoch [53/100]: train=2.078 val=2.048, (0.2s)\n",
            "Epoch [54/100]: train=2.0733 val=2.0402, (0.2s)\n",
            "Epoch [55/100]: train=2.0649 val=2.0322, (0.2s)\n",
            "Epoch [56/100]: train=2.0582 val=2.0241, (0.2s)\n",
            "Epoch [57/100]: train=2.0495 val=2.0158, (0.2s)\n",
            "Epoch [58/100]: train=2.0433 val=2.0072, (0.2s)\n",
            "Epoch [59/100]: train=2.0364 val=1.9985, (0.2s)\n",
            "Epoch [60/100]: train=2.0303 val=1.9897, (0.2s)\n",
            "Epoch [61/100]: train=2.0206 val=1.9806, (0.2s)\n",
            "Epoch [62/100]: train=2.0116 val=1.9712, (0.2s)\n",
            "Epoch [63/100]: train=2.0023 val=1.9615, (0.2s)\n",
            "Epoch [64/100]: train=1.9943 val=1.9517, (0.2s)\n",
            "Epoch [65/100]: train=1.988 val=1.9417, (0.2s)\n",
            "Epoch [66/100]: train=1.9769 val=1.9315, (0.2s)\n",
            "Epoch [67/100]: train=1.967 val=1.921, (0.2s)\n",
            "Epoch [68/100]: train=1.9587 val=1.9103, (0.2s)\n",
            "Epoch [69/100]: train=1.9476 val=1.8993, (0.2s)\n",
            "Epoch [70/100]: train=1.9342 val=1.8881, (0.2s)\n",
            "Epoch [71/100]: train=1.9273 val=1.8768, (0.3s)\n",
            "Epoch [72/100]: train=1.9184 val=1.8652, (0.2s)\n",
            "Epoch [73/100]: train=1.9046 val=1.8533, (0.2s)\n",
            "Epoch [74/100]: train=1.8992 val=1.8412, (0.2s)\n",
            "Epoch [75/100]: train=1.8878 val=1.8289, (0.2s)\n",
            "Epoch [76/100]: train=1.8735 val=1.8163, (0.2s)\n",
            "Epoch [77/100]: train=1.8606 val=1.8034, (0.3s)\n",
            "Epoch [78/100]: train=1.8493 val=1.7903, (0.3s)\n",
            "Epoch [79/100]: train=1.8368 val=1.777, (0.3s)\n",
            "Epoch [80/100]: train=1.8275 val=1.7636, (0.2s)\n",
            "Epoch [81/100]: train=1.8157 val=1.75, (0.2s)\n",
            "Epoch [82/100]: train=1.8012 val=1.7361, (0.2s)\n",
            "Epoch [83/100]: train=1.7913 val=1.7221, (0.2s)\n",
            "Epoch [84/100]: train=1.7787 val=1.7078, (0.2s)\n",
            "Epoch [85/100]: train=1.7583 val=1.6933, (0.2s)\n",
            "Epoch [86/100]: train=1.7489 val=1.6788, (0.2s)\n",
            "Epoch [87/100]: train=1.7338 val=1.664, (0.2s)\n",
            "Epoch [88/100]: train=1.722 val=1.649, (0.2s)\n",
            "Epoch [89/100]: train=1.7109 val=1.634, (0.2s)\n",
            "Epoch [90/100]: train=1.6934 val=1.619, (0.2s)\n",
            "Epoch [91/100]: train=1.6835 val=1.6038, (0.2s)\n",
            "Epoch [92/100]: train=1.6649 val=1.5884, (0.2s)\n",
            "Epoch [93/100]: train=1.652 val=1.573, (0.2s)\n",
            "Epoch [94/100]: train=1.6369 val=1.5574, (0.2s)\n",
            "Epoch [95/100]: train=1.6215 val=1.542, (0.2s)\n",
            "Epoch [96/100]: train=1.6086 val=1.5264, (0.2s)\n",
            "Epoch [97/100]: train=1.5917 val=1.5109, (0.2s)\n",
            "Epoch [98/100]: train=1.5754 val=1.4953, (0.2s)\n",
            "Epoch [99/100]: train=1.5615 val=1.4796, (0.2s)\n",
            "Epoch [100/100]: train=1.5502 val=1.4641, (0.2s)\n",
            "Training on task 2...\n",
            "Epoch [1/100]: train=1.9561 val=1.8869, (0.3s)\n",
            "Epoch [2/100]: train=1.9421 val=1.8681, (0.3s)\n",
            "Epoch [3/100]: train=1.9244 val=1.8493, (0.3s)\n",
            "Epoch [4/100]: train=1.9135 val=1.8309, (0.3s)\n",
            "Epoch [5/100]: train=1.8898 val=1.8126, (0.3s)\n",
            "Epoch [6/100]: train=1.8717 val=1.7945, (0.3s)\n",
            "Epoch [7/100]: train=1.8526 val=1.7764, (0.3s)\n",
            "Epoch [8/100]: train=1.8388 val=1.7582, (0.3s)\n",
            "Epoch [9/100]: train=1.819 val=1.7399, (0.3s)\n",
            "Epoch [10/100]: train=1.8084 val=1.7219, (0.3s)\n",
            "Epoch [11/100]: train=1.7951 val=1.704, (0.3s)\n",
            "Epoch [12/100]: train=1.7776 val=1.686, (0.3s)\n",
            "Epoch [13/100]: train=1.7626 val=1.668, (0.3s)\n",
            "Epoch [14/100]: train=1.7456 val=1.6502, (0.3s)\n",
            "Epoch [15/100]: train=1.7203 val=1.6323, (0.3s)\n",
            "Epoch [16/100]: train=1.7103 val=1.6147, (0.3s)\n",
            "Epoch [17/100]: train=1.6907 val=1.597, (0.3s)\n",
            "Epoch [18/100]: train=1.6801 val=1.5796, (0.3s)\n",
            "Epoch [19/100]: train=1.6608 val=1.5623, (0.3s)\n",
            "Epoch [20/100]: train=1.6435 val=1.5453, (0.3s)\n",
            "Epoch [21/100]: train=1.6274 val=1.5281, (0.3s)\n",
            "Epoch [22/100]: train=1.6093 val=1.5109, (0.4s)\n",
            "Epoch [23/100]: train=1.5977 val=1.4939, (0.4s)\n",
            "Epoch [24/100]: train=1.5789 val=1.4769, (0.4s)\n",
            "Epoch [25/100]: train=1.5657 val=1.4602, (0.3s)\n",
            "Epoch [26/100]: train=1.5491 val=1.4434, (0.3s)\n",
            "Epoch [27/100]: train=1.5302 val=1.4269, (0.3s)\n",
            "Epoch [28/100]: train=1.519 val=1.4106, (0.3s)\n",
            "Epoch [29/100]: train=1.5034 val=1.3943, (0.3s)\n",
            "Epoch [30/100]: train=1.4897 val=1.3784, (0.3s)\n",
            "Epoch [31/100]: train=1.4735 val=1.3627, (0.3s)\n",
            "Epoch [32/100]: train=1.4567 val=1.347, (0.3s)\n",
            "Epoch [33/100]: train=1.4349 val=1.3315, (0.3s)\n",
            "Epoch [34/100]: train=1.4234 val=1.3161, (0.3s)\n",
            "Epoch [35/100]: train=1.4114 val=1.3011, (0.3s)\n",
            "Epoch [36/100]: train=1.4014 val=1.2864, (0.3s)\n",
            "Epoch [37/100]: train=1.387 val=1.272, (0.3s)\n",
            "Epoch [38/100]: train=1.3783 val=1.2577, (0.3s)\n",
            "Epoch [39/100]: train=1.3646 val=1.2431, (0.3s)\n",
            "Epoch [40/100]: train=1.3434 val=1.2288, (0.3s)\n",
            "Epoch [41/100]: train=1.3273 val=1.2152, (0.3s)\n",
            "Epoch [42/100]: train=1.321 val=1.2015, (0.3s)\n",
            "Epoch [43/100]: train=1.3071 val=1.1884, (0.3s)\n",
            "Epoch [44/100]: train=1.2895 val=1.1754, (0.3s)\n",
            "Epoch [45/100]: train=1.2752 val=1.1623, (0.3s)\n",
            "Epoch [46/100]: train=1.2785 val=1.1496, (0.3s)\n",
            "Epoch [47/100]: train=1.2533 val=1.1373, (0.3s)\n",
            "Epoch [48/100]: train=1.2421 val=1.125, (0.3s)\n",
            "Epoch [49/100]: train=1.235 val=1.1131, (0.3s)\n",
            "Epoch [50/100]: train=1.2189 val=1.1009, (0.3s)\n",
            "Epoch [51/100]: train=1.2039 val=1.0894, (0.3s)\n",
            "Epoch [52/100]: train=1.1919 val=1.0781, (0.3s)\n",
            "Epoch [53/100]: train=1.1918 val=1.0669, (0.3s)\n",
            "Epoch [54/100]: train=1.1778 val=1.0557, (0.3s)\n",
            "Epoch [55/100]: train=1.1585 val=1.0448, (0.3s)\n",
            "Epoch [56/100]: train=1.1548 val=1.0343, (0.3s)\n",
            "Epoch [57/100]: train=1.1459 val=1.0238, (0.4s)\n",
            "Epoch [58/100]: train=1.133 val=1.0135, (0.3s)\n",
            "Epoch [59/100]: train=1.1274 val=1.0035, (0.3s)\n",
            "Epoch [60/100]: train=1.1104 val=0.994, (0.3s)\n",
            "Epoch [61/100]: train=1.1061 val=0.9844, (0.4s)\n",
            "Epoch [62/100]: train=1.0993 val=0.9751, (0.4s)\n",
            "Epoch [63/100]: train=1.0835 val=0.9657, (0.4s)\n",
            "Epoch [64/100]: train=1.07 val=0.9563, (0.3s)\n",
            "Epoch [65/100]: train=1.0617 val=0.9475, (0.3s)\n",
            "Epoch [66/100]: train=1.0538 val=0.939, (0.3s)\n",
            "Epoch [67/100]: train=1.0438 val=0.9304, (0.3s)\n",
            "Epoch [68/100]: train=1.0337 val=0.9217, (0.3s)\n",
            "Epoch [69/100]: train=1.0321 val=0.9134, (0.3s)\n",
            "Epoch [70/100]: train=1.0192 val=0.9055, (0.3s)\n",
            "Epoch [71/100]: train=1.0213 val=0.8976, (0.3s)\n",
            "Epoch [72/100]: train=1.0046 val=0.8901, (0.3s)\n",
            "Epoch [73/100]: train=1.0042 val=0.8831, (0.3s)\n",
            "Epoch [74/100]: train=1.0001 val=0.8757, (0.3s)\n",
            "Epoch [75/100]: train=0.9865 val=0.8684, (0.3s)\n",
            "Epoch [76/100]: train=0.9844 val=0.8614, (0.3s)\n",
            "Epoch [77/100]: train=0.9707 val=0.8546, (0.3s)\n",
            "Epoch [78/100]: train=0.9484 val=0.8481, (0.3s)\n",
            "Epoch [79/100]: train=0.9552 val=0.8414, (0.3s)\n",
            "Epoch [80/100]: train=0.9482 val=0.8347, (0.3s)\n",
            "Epoch [81/100]: train=0.9429 val=0.8282, (0.3s)\n",
            "Epoch [82/100]: train=0.9391 val=0.8216, (0.3s)\n",
            "Epoch [83/100]: train=0.9311 val=0.8156, (0.3s)\n",
            "Epoch [84/100]: train=0.9268 val=0.8094, (0.3s)\n",
            "Epoch [85/100]: train=0.9198 val=0.8035, (0.3s)\n",
            "Epoch [86/100]: train=0.8983 val=0.7978, (0.3s)\n",
            "Epoch [87/100]: train=0.9064 val=0.792, (0.3s)\n",
            "Epoch [88/100]: train=0.8992 val=0.7866, (0.3s)\n",
            "Epoch [89/100]: train=0.8865 val=0.7813, (0.3s)\n",
            "Epoch [90/100]: train=0.8966 val=0.7761, (0.3s)\n",
            "Epoch [91/100]: train=0.8806 val=0.7712, (0.3s)\n",
            "Epoch [92/100]: train=0.8752 val=0.7661, (0.3s)\n",
            "Epoch [93/100]: train=0.8714 val=0.7605, (0.3s)\n",
            "Epoch [94/100]: train=0.8742 val=0.7559, (0.3s)\n",
            "Epoch [95/100]: train=0.8601 val=0.7516, (0.3s)\n",
            "Epoch [96/100]: train=0.8545 val=0.7469, (0.3s)\n",
            "Epoch [97/100]: train=0.8512 val=0.7423, (0.3s)\n",
            "Epoch [98/100]: train=0.8497 val=0.7375, (0.3s)\n",
            "Epoch [99/100]: train=0.8296 val=0.7331, (0.4s)\n",
            "Epoch [100/100]: train=0.8317 val=0.7288, (0.4s)\n",
            "Training on task 3...\n",
            "Epoch [1/100]: train=1.6954 val=1.5619, (0.4s)\n",
            "Epoch [2/100]: train=1.6256 val=1.5111, (0.4s)\n",
            "Epoch [3/100]: train=1.5811 val=1.4698, (0.4s)\n",
            "Epoch [4/100]: train=1.5382 val=1.4335, (0.4s)\n",
            "Epoch [5/100]: train=1.5274 val=1.4008, (0.4s)\n",
            "Epoch [6/100]: train=1.4748 val=1.3703, (0.4s)\n",
            "Epoch [7/100]: train=1.4588 val=1.342, (0.4s)\n",
            "Epoch [8/100]: train=1.4312 val=1.3145, (0.4s)\n",
            "Epoch [9/100]: train=1.4169 val=1.2872, (0.4s)\n",
            "Epoch [10/100]: train=1.3955 val=1.2613, (0.4s)\n",
            "Epoch [11/100]: train=1.3512 val=1.2379, (0.4s)\n",
            "Epoch [12/100]: train=1.3438 val=1.2158, (0.4s)\n",
            "Epoch [13/100]: train=1.3181 val=1.1945, (0.4s)\n",
            "Epoch [14/100]: train=1.3004 val=1.1746, (0.4s)\n",
            "Epoch [15/100]: train=1.2708 val=1.1554, (0.4s)\n",
            "Epoch [16/100]: train=1.2521 val=1.1363, (0.4s)\n",
            "Epoch [17/100]: train=1.2318 val=1.119, (0.4s)\n",
            "Epoch [18/100]: train=1.2115 val=1.1022, (0.4s)\n",
            "Epoch [19/100]: train=1.2122 val=1.0859, (0.4s)\n",
            "Epoch [20/100]: train=1.1841 val=1.0708, (0.4s)\n",
            "Epoch [21/100]: train=1.1868 val=1.0555, (0.4s)\n",
            "Epoch [22/100]: train=1.1609 val=1.0419, (0.4s)\n",
            "Epoch [23/100]: train=1.1633 val=1.0278, (0.4s)\n",
            "Epoch [24/100]: train=1.1252 val=1.0143, (0.4s)\n",
            "Epoch [25/100]: train=1.1237 val=1.0015, (0.4s)\n",
            "Epoch [26/100]: train=1.0994 val=0.9886, (0.5s)\n",
            "Epoch [27/100]: train=1.0927 val=0.9775, (0.5s)\n",
            "Epoch [28/100]: train=1.0796 val=0.9656, (0.5s)\n",
            "Epoch [29/100]: train=1.0689 val=0.9549, (0.5s)\n",
            "Epoch [30/100]: train=1.0619 val=0.9443, (0.4s)\n",
            "Epoch [31/100]: train=1.0535 val=0.9347, (0.4s)\n",
            "Epoch [32/100]: train=1.0325 val=0.925, (0.4s)\n",
            "Epoch [33/100]: train=1.0242 val=0.9153, (0.4s)\n",
            "Epoch [34/100]: train=1.0268 val=0.9061, (0.4s)\n",
            "Epoch [35/100]: train=1.0077 val=0.8971, (0.4s)\n",
            "Epoch [36/100]: train=0.9958 val=0.8883, (0.4s)\n",
            "Epoch [37/100]: train=0.9953 val=0.8795, (0.4s)\n",
            "Epoch [38/100]: train=0.9829 val=0.8715, (0.4s)\n",
            "Epoch [39/100]: train=0.9662 val=0.8632, (0.4s)\n",
            "Epoch [40/100]: train=0.9709 val=0.8552, (0.4s)\n",
            "Epoch [41/100]: train=0.9566 val=0.8481, (0.4s)\n",
            "Epoch [42/100]: train=0.9499 val=0.841, (0.4s)\n",
            "Epoch [43/100]: train=0.9343 val=0.8346, (0.4s)\n",
            "Epoch [44/100]: train=0.9439 val=0.8279, (0.4s)\n",
            "Epoch [45/100]: train=0.9342 val=0.8213, (0.4s)\n",
            "Epoch [46/100]: train=0.9245 val=0.8148, (0.4s)\n",
            "Epoch [47/100]: train=0.9217 val=0.8081, (0.4s)\n",
            "Epoch [48/100]: train=0.9051 val=0.8012, (0.4s)\n",
            "Epoch [49/100]: train=0.902 val=0.7955, (0.4s)\n",
            "Epoch [50/100]: train=0.8898 val=0.79, (0.4s)\n",
            "Epoch [51/100]: train=0.8858 val=0.7843, (0.4s)\n",
            "Epoch [52/100]: train=0.8767 val=0.7789, (0.4s)\n",
            "Epoch [53/100]: train=0.8773 val=0.7735, (0.4s)\n",
            "Epoch [54/100]: train=0.8704 val=0.7685, (0.5s)\n",
            "Epoch [55/100]: train=0.8696 val=0.7636, (0.4s)\n",
            "Epoch [56/100]: train=0.8597 val=0.7579, (0.4s)\n",
            "Epoch [57/100]: train=0.8526 val=0.7538, (0.5s)\n",
            "Epoch [58/100]: train=0.8535 val=0.749, (0.5s)\n",
            "Epoch [59/100]: train=0.8462 val=0.7444, (0.4s)\n",
            "Epoch [60/100]: train=0.84 val=0.7393, (0.4s)\n",
            "Epoch [61/100]: train=0.8328 val=0.7345, (0.4s)\n",
            "Epoch [62/100]: train=0.8379 val=0.7299, (0.4s)\n",
            "Epoch [63/100]: train=0.8179 val=0.726, (0.4s)\n",
            "Epoch [64/100]: train=0.814 val=0.7215, (0.4s)\n",
            "Epoch [65/100]: train=0.814 val=0.718, (0.4s)\n",
            "Epoch [66/100]: train=0.8062 val=0.7145, (0.4s)\n",
            "Epoch [67/100]: train=0.8059 val=0.7105, (0.4s)\n",
            "Epoch [68/100]: train=0.8098 val=0.7073, (0.4s)\n",
            "Epoch [69/100]: train=0.7909 val=0.7035, (0.4s)\n",
            "Epoch [70/100]: train=0.8081 val=0.6992, (0.4s)\n",
            "Epoch [71/100]: train=0.7913 val=0.6956, (0.4s)\n",
            "Epoch [72/100]: train=0.7901 val=0.6924, (0.4s)\n",
            "Epoch [73/100]: train=0.7752 val=0.6889, (0.4s)\n",
            "Epoch [74/100]: train=0.7837 val=0.6853, (0.4s)\n",
            "Epoch [75/100]: train=0.7829 val=0.6817, (0.4s)\n",
            "Epoch [76/100]: train=0.7853 val=0.6779, (0.4s)\n",
            "Epoch [77/100]: train=0.7758 val=0.6747, (0.4s)\n",
            "Epoch [78/100]: train=0.774 val=0.6716, (0.4s)\n",
            "Epoch [79/100]: train=0.7544 val=0.6687, (0.4s)\n",
            "Epoch [80/100]: train=0.7477 val=0.6661, (0.4s)\n",
            "Epoch [81/100]: train=0.76 val=0.6631, (0.4s)\n",
            "Epoch [82/100]: train=0.7585 val=0.6608, (0.4s)\n",
            "Epoch [83/100]: train=0.7592 val=0.6581, (0.5s)\n",
            "Epoch [84/100]: train=0.7429 val=0.6557, (0.4s)\n",
            "Epoch [85/100]: train=0.7589 val=0.6524, (0.4s)\n",
            "Epoch [86/100]: train=0.7641 val=0.6495, (0.5s)\n",
            "Epoch [87/100]: train=0.7368 val=0.6467, (0.5s)\n",
            "Epoch [88/100]: train=0.7234 val=0.6441, (0.4s)\n",
            "Epoch [89/100]: train=0.7131 val=0.642, (0.4s)\n",
            "Epoch [90/100]: train=0.7418 val=0.6392, (0.4s)\n",
            "Epoch [91/100]: train=0.7106 val=0.6368, (0.4s)\n",
            "Epoch [92/100]: train=0.7175 val=0.634, (0.4s)\n",
            "Epoch [93/100]: train=0.7176 val=0.6314, (0.4s)\n",
            "Epoch [94/100]: train=0.7185 val=0.6294, (0.4s)\n",
            "Epoch [95/100]: train=0.73 val=0.6273, (0.4s)\n",
            "Epoch [96/100]: train=0.7139 val=0.6251, (0.4s)\n",
            "Epoch [97/100]: train=0.7122 val=0.6225, (0.4s)\n",
            "Epoch [98/100]: train=0.7085 val=0.6199, (0.4s)\n",
            "Epoch [99/100]: train=0.7003 val=0.6182, (0.4s)\n",
            "Epoch [100/100]: train=0.7056 val=0.6161, (0.4s)\n",
            "Training on task 4...\n",
            "Epoch [1/100]: train=1.746 val=1.5782, (0.5s)\n",
            "Epoch [2/100]: train=1.6514 val=1.5088, (0.5s)\n",
            "Epoch [3/100]: train=1.6096 val=1.454, (0.5s)\n",
            "Epoch [4/100]: train=1.5601 val=1.408, (0.5s)\n",
            "Epoch [5/100]: train=1.5128 val=1.3666, (0.5s)\n",
            "Epoch [6/100]: train=1.4725 val=1.3271, (0.5s)\n",
            "Epoch [7/100]: train=1.4263 val=1.2917, (0.6s)\n",
            "Epoch [8/100]: train=1.3949 val=1.2593, (0.5s)\n",
            "Epoch [9/100]: train=1.3745 val=1.229, (0.6s)\n",
            "Epoch [10/100]: train=1.3483 val=1.2023, (0.6s)\n",
            "Epoch [11/100]: train=1.3122 val=1.1768, (0.6s)\n",
            "Epoch [12/100]: train=1.31 val=1.1517, (0.5s)\n",
            "Epoch [13/100]: train=1.2498 val=1.129, (0.5s)\n",
            "Epoch [14/100]: train=1.2366 val=1.1073, (0.5s)\n",
            "Epoch [15/100]: train=1.2186 val=1.0877, (0.5s)\n",
            "Epoch [16/100]: train=1.2093 val=1.069, (0.5s)\n",
            "Epoch [17/100]: train=1.1938 val=1.0509, (0.5s)\n",
            "Epoch [18/100]: train=1.1672 val=1.0341, (0.5s)\n",
            "Epoch [19/100]: train=1.1502 val=1.0189, (0.5s)\n",
            "Epoch [20/100]: train=1.1313 val=1.0041, (0.5s)\n",
            "Epoch [21/100]: train=1.119 val=0.9889, (0.5s)\n",
            "Epoch [22/100]: train=1.1187 val=0.9759, (0.5s)\n",
            "Epoch [23/100]: train=1.0861 val=0.9626, (0.5s)\n",
            "Epoch [24/100]: train=1.0824 val=0.9516, (0.5s)\n",
            "Epoch [25/100]: train=1.0624 val=0.9394, (0.5s)\n",
            "Epoch [26/100]: train=1.0562 val=0.9281, (0.5s)\n",
            "Epoch [27/100]: train=1.0371 val=0.9171, (0.5s)\n",
            "Epoch [28/100]: train=1.0387 val=0.9067, (0.5s)\n",
            "Epoch [29/100]: train=1.029 val=0.8976, (0.5s)\n",
            "Epoch [30/100]: train=1.0051 val=0.8882, (0.5s)\n",
            "Epoch [31/100]: train=0.9979 val=0.8791, (0.6s)\n",
            "Epoch [32/100]: train=0.9934 val=0.8704, (0.5s)\n",
            "Epoch [33/100]: train=0.9872 val=0.8623, (0.6s)\n",
            "Epoch [34/100]: train=0.9673 val=0.8541, (0.6s)\n",
            "Epoch [35/100]: train=0.9549 val=0.8463, (0.5s)\n",
            "Epoch [36/100]: train=0.9576 val=0.839, (0.5s)\n",
            "Epoch [37/100]: train=0.9482 val=0.8319, (0.5s)\n",
            "Epoch [38/100]: train=0.9363 val=0.8249, (0.5s)\n",
            "Epoch [39/100]: train=0.9345 val=0.8178, (0.5s)\n",
            "Epoch [40/100]: train=0.9236 val=0.8114, (0.5s)\n",
            "Epoch [41/100]: train=0.9226 val=0.8048, (0.5s)\n",
            "Epoch [42/100]: train=0.9032 val=0.7993, (0.5s)\n",
            "Epoch [43/100]: train=0.9095 val=0.7934, (0.5s)\n",
            "Epoch [44/100]: train=0.9028 val=0.787, (0.5s)\n",
            "Epoch [45/100]: train=0.886 val=0.7815, (0.5s)\n",
            "Epoch [46/100]: train=0.8798 val=0.7766, (0.5s)\n",
            "Epoch [47/100]: train=0.8806 val=0.7708, (0.5s)\n",
            "Epoch [48/100]: train=0.8863 val=0.7654, (0.5s)\n",
            "Epoch [49/100]: train=0.8713 val=0.7602, (0.5s)\n",
            "Epoch [50/100]: train=0.8613 val=0.7552, (0.5s)\n",
            "Epoch [51/100]: train=0.8538 val=0.7509, (0.5s)\n",
            "Epoch [52/100]: train=0.8631 val=0.7457, (0.5s)\n",
            "Epoch [53/100]: train=0.8519 val=0.7415, (0.5s)\n",
            "Epoch [54/100]: train=0.8469 val=0.7387, (0.5s)\n",
            "Epoch [55/100]: train=0.8388 val=0.7334, (0.5s)\n",
            "Epoch [56/100]: train=0.8371 val=0.7293, (0.5s)\n",
            "Epoch [57/100]: train=0.8289 val=0.7257, (0.6s)\n",
            "Epoch [58/100]: train=0.8276 val=0.722, (0.6s)\n",
            "Epoch [59/100]: train=0.8186 val=0.717, (0.5s)\n",
            "Epoch [60/100]: train=0.8084 val=0.7132, (0.5s)\n",
            "Epoch [61/100]: train=0.8184 val=0.7092, (0.5s)\n",
            "Epoch [62/100]: train=0.8047 val=0.7059, (0.5s)\n",
            "Epoch [63/100]: train=0.8052 val=0.7025, (0.5s)\n",
            "Epoch [64/100]: train=0.7992 val=0.6986, (0.5s)\n",
            "Epoch [65/100]: train=0.7926 val=0.6957, (0.5s)\n",
            "Epoch [66/100]: train=0.784 val=0.6923, (0.5s)\n",
            "Epoch [67/100]: train=0.7859 val=0.6886, (0.5s)\n",
            "Epoch [68/100]: train=0.789 val=0.6853, (0.5s)\n",
            "Epoch [69/100]: train=0.7754 val=0.6827, (0.5s)\n",
            "Epoch [70/100]: train=0.7795 val=0.6796, (0.5s)\n",
            "Epoch [71/100]: train=0.7652 val=0.6766, (0.5s)\n",
            "Epoch [72/100]: train=0.7715 val=0.674, (0.5s)\n",
            "Epoch [73/100]: train=0.7643 val=0.6713, (0.5s)\n",
            "Epoch [74/100]: train=0.7531 val=0.669, (0.5s)\n",
            "Epoch [75/100]: train=0.7537 val=0.6656, (0.5s)\n",
            "Epoch [76/100]: train=0.7533 val=0.6626, (0.5s)\n",
            "Epoch [77/100]: train=0.7478 val=0.6598, (0.5s)\n",
            "Epoch [78/100]: train=0.741 val=0.6578, (0.6s)\n",
            "Epoch [79/100]: train=0.7634 val=0.6555, (0.6s)\n",
            "Epoch [80/100]: train=0.7488 val=0.6523, (0.5s)\n",
            "Epoch [81/100]: train=0.7487 val=0.65, (0.6s)\n",
            "Epoch [82/100]: train=0.7357 val=0.6473, (0.6s)\n",
            "Epoch [83/100]: train=0.7285 val=0.6446, (0.5s)\n",
            "Epoch [84/100]: train=0.7481 val=0.6426, (0.5s)\n",
            "Epoch [85/100]: train=0.7341 val=0.6403, (0.5s)\n",
            "Epoch [86/100]: train=0.7204 val=0.6376, (0.5s)\n",
            "Epoch [87/100]: train=0.739 val=0.6349, (0.5s)\n",
            "Epoch [88/100]: train=0.7353 val=0.6338, (0.5s)\n",
            "Epoch [89/100]: train=0.714 val=0.6316, (0.5s)\n",
            "Epoch [90/100]: train=0.7195 val=0.6287, (0.5s)\n",
            "Epoch [91/100]: train=0.7083 val=0.6264, (0.5s)\n",
            "Epoch [92/100]: train=0.7237 val=0.624, (0.5s)\n",
            "Epoch [93/100]: train=0.7095 val=0.6214, (0.5s)\n",
            "Epoch [94/100]: train=0.7199 val=0.6192, (0.5s)\n",
            "Epoch [95/100]: train=0.7162 val=0.6174, (0.5s)\n",
            "Epoch [96/100]: train=0.6964 val=0.6162, (0.5s)\n",
            "Epoch [97/100]: train=0.7124 val=0.6141, (0.5s)\n",
            "Epoch [98/100]: train=0.6968 val=0.6115, (0.5s)\n",
            "Epoch [99/100]: train=0.6967 val=0.6092, (0.5s)\n",
            "Epoch [100/100]: train=0.7091 val=0.6079, (0.5s)\n",
            "Training on task 5...\n",
            "Epoch [1/100]: train=1.6906 val=1.5042, (0.6s)\n",
            "Epoch [2/100]: train=1.6101 val=1.4333, (0.6s)\n",
            "Epoch [3/100]: train=1.5633 val=1.3799, (0.6s)\n",
            "Epoch [4/100]: train=1.4944 val=1.3331, (0.6s)\n",
            "Epoch [5/100]: train=1.4598 val=1.2925, (0.6s)\n",
            "Epoch [6/100]: train=1.417 val=1.2551, (0.6s)\n",
            "Epoch [7/100]: train=1.3818 val=1.2221, (0.6s)\n",
            "Epoch [8/100]: train=1.3491 val=1.1915, (0.6s)\n",
            "Epoch [9/100]: train=1.3159 val=1.1626, (0.6s)\n",
            "Epoch [10/100]: train=1.2829 val=1.1358, (0.6s)\n",
            "Epoch [11/100]: train=1.2652 val=1.1125, (0.6s)\n",
            "Epoch [12/100]: train=1.2325 val=1.0903, (0.6s)\n",
            "Epoch [13/100]: train=1.2222 val=1.0688, (0.6s)\n",
            "Epoch [14/100]: train=1.1818 val=1.0482, (0.6s)\n",
            "Epoch [15/100]: train=1.1728 val=1.0308, (0.6s)\n",
            "Epoch [16/100]: train=1.1416 val=1.0138, (0.6s)\n",
            "Epoch [17/100]: train=1.1411 val=0.9973, (0.7s)\n",
            "Epoch [18/100]: train=1.1195 val=0.9819, (0.6s)\n",
            "Epoch [19/100]: train=1.1017 val=0.9679, (0.7s)\n",
            "Epoch [20/100]: train=1.0904 val=0.9541, (0.7s)\n",
            "Epoch [21/100]: train=1.0712 val=0.9412, (0.6s)\n",
            "Epoch [22/100]: train=1.0445 val=0.9292, (0.6s)\n",
            "Epoch [23/100]: train=1.0551 val=0.9173, (0.6s)\n",
            "Epoch [24/100]: train=1.0272 val=0.9056, (0.6s)\n",
            "Epoch [25/100]: train=1.0357 val=0.8953, (0.6s)\n",
            "Epoch [26/100]: train=1.0094 val=0.8861, (0.6s)\n",
            "Epoch [27/100]: train=0.9994 val=0.8754, (0.6s)\n",
            "Epoch [28/100]: train=0.987 val=0.8664, (0.6s)\n",
            "Epoch [29/100]: train=0.9785 val=0.8577, (0.6s)\n",
            "Epoch [30/100]: train=0.9619 val=0.8494, (0.6s)\n",
            "Epoch [31/100]: train=0.9654 val=0.8418, (0.6s)\n",
            "Epoch [32/100]: train=0.9505 val=0.8334, (0.6s)\n",
            "Epoch [33/100]: train=0.9554 val=0.8261, (0.6s)\n",
            "Epoch [34/100]: train=0.9373 val=0.8188, (0.6s)\n",
            "Epoch [35/100]: train=0.9257 val=0.8113, (0.6s)\n",
            "Epoch [36/100]: train=0.907 val=0.8051, (0.6s)\n",
            "Epoch [37/100]: train=0.8913 val=0.7989, (0.7s)\n",
            "Epoch [38/100]: train=0.8938 val=0.7923, (0.6s)\n",
            "Epoch [39/100]: train=0.9015 val=0.7859, (0.7s)\n",
            "Epoch [40/100]: train=0.8918 val=0.7806, (0.7s)\n",
            "Epoch [41/100]: train=0.8824 val=0.7749, (0.6s)\n",
            "Epoch [42/100]: train=0.8764 val=0.7697, (0.6s)\n",
            "Epoch [43/100]: train=0.8651 val=0.7644, (0.6s)\n",
            "Epoch [44/100]: train=0.8559 val=0.7593, (0.6s)\n",
            "Epoch [45/100]: train=0.8583 val=0.7546, (0.6s)\n",
            "Epoch [46/100]: train=0.8504 val=0.7492, (0.6s)\n",
            "Epoch [47/100]: train=0.8486 val=0.7453, (0.6s)\n",
            "Epoch [48/100]: train=0.8508 val=0.7399, (0.6s)\n",
            "Epoch [49/100]: train=0.8368 val=0.7353, (0.6s)\n",
            "Epoch [50/100]: train=0.827 val=0.7306, (0.6s)\n",
            "Epoch [51/100]: train=0.8362 val=0.7265, (0.6s)\n",
            "Epoch [52/100]: train=0.8256 val=0.7226, (0.6s)\n",
            "Epoch [53/100]: train=0.8238 val=0.718, (0.6s)\n",
            "Epoch [54/100]: train=0.8164 val=0.7141, (0.6s)\n",
            "Epoch [55/100]: train=0.7935 val=0.7106, (0.6s)\n",
            "Epoch [56/100]: train=0.816 val=0.7062, (0.6s)\n",
            "Epoch [57/100]: train=0.7947 val=0.7032, (0.7s)\n",
            "Epoch [58/100]: train=0.8063 val=0.6992, (0.7s)\n",
            "Epoch [59/100]: train=0.7877 val=0.6959, (0.7s)\n",
            "Epoch [60/100]: train=0.8011 val=0.6923, (0.7s)\n",
            "Epoch [61/100]: train=0.784 val=0.6889, (0.6s)\n",
            "Epoch [62/100]: train=0.7799 val=0.6854, (0.6s)\n",
            "Epoch [63/100]: train=0.782 val=0.6822, (0.6s)\n",
            "Epoch [64/100]: train=0.7732 val=0.6787, (0.6s)\n",
            "Epoch [65/100]: train=0.771 val=0.6766, (0.6s)\n",
            "Epoch [66/100]: train=0.7644 val=0.6731, (0.6s)\n",
            "Epoch [67/100]: train=0.7724 val=0.6698, (0.6s)\n",
            "Epoch [68/100]: train=0.7684 val=0.6676, (0.6s)\n",
            "Epoch [69/100]: train=0.7595 val=0.6646, (0.6s)\n",
            "Epoch [70/100]: train=0.7615 val=0.6618, (0.6s)\n",
            "Epoch [71/100]: train=0.7431 val=0.6592, (0.6s)\n",
            "Epoch [72/100]: train=0.7373 val=0.6564, (0.6s)\n",
            "Epoch [73/100]: train=0.7366 val=0.654, (0.6s)\n",
            "Epoch [74/100]: train=0.7405 val=0.6516, (0.6s)\n",
            "Epoch [75/100]: train=0.7448 val=0.6489, (0.6s)\n",
            "Epoch [76/100]: train=0.7388 val=0.6463, (0.6s)\n",
            "Epoch [77/100]: train=0.7305 val=0.643, (0.6s)\n",
            "Epoch [78/100]: train=0.7302 val=0.6402, (0.6s)\n",
            "Epoch [79/100]: train=0.7218 val=0.638, (0.7s)\n",
            "Epoch [80/100]: train=0.7222 val=0.6364, (0.7s)\n",
            "Epoch [81/100]: train=0.7212 val=0.6334, (0.6s)\n",
            "Epoch [82/100]: train=0.7225 val=0.6312, (0.6s)\n",
            "Epoch [83/100]: train=0.7109 val=0.6293, (0.6s)\n",
            "Epoch [84/100]: train=0.7195 val=0.627, (0.6s)\n",
            "Epoch [85/100]: train=0.7059 val=0.6252, (0.6s)\n",
            "Epoch [86/100]: train=0.6959 val=0.6231, (0.6s)\n",
            "Epoch [87/100]: train=0.7077 val=0.6205, (0.6s)\n",
            "Epoch [88/100]: train=0.6881 val=0.6184, (0.6s)\n",
            "Epoch [89/100]: train=0.7098 val=0.6161, (0.6s)\n",
            "Epoch [90/100]: train=0.6995 val=0.6145, (0.6s)\n",
            "Epoch [91/100]: train=0.7012 val=0.612, (0.6s)\n",
            "Epoch [92/100]: train=0.6904 val=0.6101, (0.6s)\n",
            "Epoch [93/100]: train=0.6854 val=0.608, (0.6s)\n",
            "Epoch [94/100]: train=0.6978 val=0.6059, (0.6s)\n",
            "Epoch [95/100]: train=0.6897 val=0.6043, (0.6s)\n",
            "Epoch [96/100]: train=0.6799 val=0.6023, (0.6s)\n",
            "Epoch [97/100]: train=0.6811 val=0.6007, (0.7s)\n",
            "Epoch [98/100]: train=0.6662 val=0.5993, (0.6s)\n",
            "Epoch [99/100]: train=0.6723 val=0.5978, (0.7s)\n",
            "Epoch [100/100]: train=0.6717 val=0.5966, (0.7s)\n",
            "Training on task 6...\n",
            "Epoch [1/100]: train=1.8145 val=1.6128, (0.7s)\n",
            "Epoch [2/100]: train=1.6913 val=1.5333, (0.7s)\n",
            "Epoch [3/100]: train=1.6223 val=1.4688, (0.7s)\n",
            "Epoch [4/100]: train=1.5707 val=1.413, (0.7s)\n",
            "Epoch [5/100]: train=1.4942 val=1.3641, (0.7s)\n",
            "Epoch [6/100]: train=1.4706 val=1.3202, (0.7s)\n",
            "Epoch [7/100]: train=1.438 val=1.2787, (0.7s)\n",
            "Epoch [8/100]: train=1.4015 val=1.2423, (0.7s)\n",
            "Epoch [9/100]: train=1.3727 val=1.2077, (0.7s)\n",
            "Epoch [10/100]: train=1.3012 val=1.1789, (0.7s)\n",
            "Epoch [11/100]: train=1.3115 val=1.1507, (0.8s)\n",
            "Epoch [12/100]: train=1.2359 val=1.1253, (0.8s)\n",
            "Epoch [13/100]: train=1.2405 val=1.1022, (0.8s)\n",
            "Epoch [14/100]: train=1.2073 val=1.0803, (0.7s)\n",
            "Epoch [15/100]: train=1.1851 val=1.0591, (0.7s)\n",
            "Epoch [16/100]: train=1.1768 val=1.0397, (0.7s)\n",
            "Epoch [17/100]: train=1.1564 val=1.0225, (0.7s)\n",
            "Epoch [18/100]: train=1.1412 val=1.0067, (0.7s)\n",
            "Epoch [19/100]: train=1.1151 val=0.9909, (0.7s)\n",
            "Epoch [20/100]: train=1.0955 val=0.9757, (0.7s)\n",
            "Epoch [21/100]: train=1.0968 val=0.9607, (0.7s)\n",
            "Epoch [22/100]: train=1.067 val=0.9479, (0.7s)\n",
            "Epoch [23/100]: train=1.0584 val=0.9352, (0.7s)\n",
            "Epoch [24/100]: train=1.0445 val=0.923, (0.7s)\n",
            "Epoch [25/100]: train=1.0241 val=0.9115, (0.7s)\n",
            "Epoch [26/100]: train=1.0147 val=0.9008, (0.7s)\n",
            "Epoch [27/100]: train=0.9928 val=0.8907, (0.7s)\n",
            "Epoch [28/100]: train=0.9886 val=0.881, (0.8s)\n",
            "Epoch [29/100]: train=0.9797 val=0.8716, (0.8s)\n",
            "Epoch [30/100]: train=0.9885 val=0.8619, (0.8s)\n",
            "Epoch [31/100]: train=0.9708 val=0.8539, (0.8s)\n",
            "Epoch [32/100]: train=0.9565 val=0.846, (0.7s)\n",
            "Epoch [33/100]: train=0.9475 val=0.837, (0.7s)\n",
            "Epoch [34/100]: train=0.9437 val=0.8294, (0.7s)\n",
            "Epoch [35/100]: train=0.9212 val=0.8237, (0.7s)\n",
            "Epoch [36/100]: train=0.9346 val=0.8166, (0.7s)\n",
            "Epoch [37/100]: train=0.9127 val=0.8098, (0.7s)\n",
            "Epoch [38/100]: train=0.8992 val=0.8039, (0.7s)\n",
            "Epoch [39/100]: train=0.8992 val=0.7979, (0.7s)\n",
            "Epoch [40/100]: train=0.9036 val=0.7909, (0.7s)\n",
            "Epoch [41/100]: train=0.8872 val=0.7854, (0.7s)\n",
            "Epoch [42/100]: train=0.8729 val=0.7799, (0.7s)\n",
            "Epoch [43/100]: train=0.8722 val=0.7745, (0.7s)\n",
            "Epoch [44/100]: train=0.8674 val=0.7697, (0.7s)\n",
            "Epoch [45/100]: train=0.8538 val=0.765, (0.7s)\n",
            "Epoch [46/100]: train=0.8502 val=0.7592, (0.8s)\n",
            "Epoch [47/100]: train=0.8531 val=0.7539, (0.8s)\n",
            "Epoch [48/100]: train=0.8432 val=0.7488, (0.8s)\n",
            "Epoch [49/100]: train=0.8376 val=0.7437, (0.7s)\n",
            "Epoch [50/100]: train=0.8388 val=0.7393, (0.7s)\n",
            "Epoch [51/100]: train=0.8289 val=0.7353, (0.7s)\n",
            "Epoch [52/100]: train=0.8216 val=0.732, (0.7s)\n",
            "Epoch [53/100]: train=0.8257 val=0.7269, (0.7s)\n",
            "Epoch [54/100]: train=0.8187 val=0.7232, (0.7s)\n",
            "Epoch [55/100]: train=0.8022 val=0.7194, (0.7s)\n",
            "Epoch [56/100]: train=0.8046 val=0.7156, (0.7s)\n",
            "Epoch [57/100]: train=0.806 val=0.7125, (0.7s)\n",
            "Epoch [58/100]: train=0.7904 val=0.7091, (0.7s)\n",
            "Epoch [59/100]: train=0.7995 val=0.7058, (0.7s)\n",
            "Epoch [60/100]: train=0.7943 val=0.7017, (0.7s)\n",
            "Epoch [61/100]: train=0.783 val=0.6979, (0.7s)\n",
            "Epoch [62/100]: train=0.7644 val=0.6942, (0.8s)\n",
            "Epoch [63/100]: train=0.7724 val=0.6911, (0.8s)\n",
            "Epoch [64/100]: train=0.7754 val=0.6873, (0.8s)\n",
            "Epoch [65/100]: train=0.766 val=0.6833, (0.8s)\n",
            "Epoch [66/100]: train=0.764 val=0.6811, (0.7s)\n",
            "Epoch [67/100]: train=0.7638 val=0.6774, (0.7s)\n",
            "Epoch [68/100]: train=0.763 val=0.6748, (0.7s)\n",
            "Epoch [69/100]: train=0.7543 val=0.6727, (0.7s)\n",
            "Epoch [70/100]: train=0.7647 val=0.6693, (0.7s)\n",
            "Epoch [71/100]: train=0.7431 val=0.6666, (0.7s)\n",
            "Epoch [72/100]: train=0.7508 val=0.6637, (0.7s)\n",
            "Epoch [73/100]: train=0.7431 val=0.6614, (0.7s)\n",
            "Epoch [74/100]: train=0.7446 val=0.6594, (0.7s)\n",
            "Epoch [75/100]: train=0.7352 val=0.6569, (0.7s)\n",
            "Epoch [76/100]: train=0.738 val=0.6541, (0.7s)\n",
            "Epoch [77/100]: train=0.7378 val=0.6512, (0.7s)\n",
            "Epoch [78/100]: train=0.7339 val=0.6487, (0.7s)\n",
            "Epoch [79/100]: train=0.7255 val=0.6456, (0.8s)\n",
            "Epoch [80/100]: train=0.7319 val=0.6429, (0.8s)\n",
            "Epoch [81/100]: train=0.7177 val=0.6412, (0.8s)\n",
            "Epoch [82/100]: train=0.7253 val=0.6381, (0.8s)\n",
            "Epoch [83/100]: train=0.7157 val=0.6363, (0.7s)\n",
            "Epoch [84/100]: train=0.7157 val=0.634, (0.7s)\n",
            "Epoch [85/100]: train=0.7197 val=0.6319, (0.7s)\n",
            "Epoch [86/100]: train=0.7105 val=0.6296, (0.7s)\n",
            "Epoch [87/100]: train=0.7116 val=0.6274, (0.7s)\n",
            "Epoch [88/100]: train=0.6966 val=0.6256, (0.7s)\n",
            "Epoch [89/100]: train=0.6934 val=0.6241, (0.7s)\n",
            "Epoch [90/100]: train=0.7033 val=0.6214, (0.7s)\n",
            "Epoch [91/100]: train=0.6958 val=0.6196, (0.7s)\n",
            "Epoch [92/100]: train=0.6858 val=0.6174, (0.7s)\n",
            "Epoch [93/100]: train=0.681 val=0.6155, (0.7s)\n",
            "Epoch [94/100]: train=0.683 val=0.6132, (0.7s)\n",
            "Epoch [95/100]: train=0.6802 val=0.6116, (0.7s)\n",
            "Epoch [96/100]: train=0.6892 val=0.6093, (0.8s)\n",
            "Epoch [97/100]: train=0.684 val=0.6081, (0.8s)\n",
            "Epoch [98/100]: train=0.6798 val=0.6061, (0.8s)\n",
            "Epoch [99/100]: train=0.6785 val=0.6038, (0.8s)\n",
            "Epoch [100/100]: train=0.677 val=0.6015, (0.7s)\n",
            "Training on task 7...\n",
            "Epoch [1/100]: train=1.7485 val=1.588, (0.8s)\n",
            "Epoch [2/100]: train=1.6502 val=1.5067, (0.8s)\n",
            "Epoch [3/100]: train=1.5978 val=1.4417, (0.8s)\n",
            "Epoch [4/100]: train=1.5402 val=1.3868, (0.8s)\n",
            "Epoch [5/100]: train=1.4846 val=1.3385, (0.8s)\n",
            "Epoch [6/100]: train=1.4249 val=1.2945, (0.8s)\n",
            "Epoch [7/100]: train=1.3962 val=1.2572, (0.8s)\n",
            "Epoch [8/100]: train=1.3628 val=1.2224, (0.9s)\n",
            "Epoch [9/100]: train=1.3171 val=1.1906, (0.9s)\n",
            "Epoch [10/100]: train=1.3014 val=1.1595, (0.9s)\n",
            "Epoch [11/100]: train=1.2533 val=1.1336, (0.8s)\n",
            "Epoch [12/100]: train=1.2337 val=1.1092, (0.8s)\n",
            "Epoch [13/100]: train=1.2134 val=1.0864, (0.8s)\n",
            "Epoch [14/100]: train=1.1986 val=1.065, (0.8s)\n",
            "Epoch [15/100]: train=1.1644 val=1.0438, (0.8s)\n",
            "Epoch [16/100]: train=1.1438 val=1.0252, (0.8s)\n",
            "Epoch [17/100]: train=1.1299 val=1.0075, (0.8s)\n",
            "Epoch [18/100]: train=1.1155 val=0.9912, (0.8s)\n",
            "Epoch [19/100]: train=1.0941 val=0.9759, (0.8s)\n",
            "Epoch [20/100]: train=1.0619 val=0.961, (0.8s)\n",
            "Epoch [21/100]: train=1.0624 val=0.9482, (0.8s)\n",
            "Epoch [22/100]: train=1.0536 val=0.9341, (0.8s)\n",
            "Epoch [23/100]: train=1.0365 val=0.9226, (0.9s)\n",
            "Epoch [24/100]: train=1.0239 val=0.9116, (0.9s)\n",
            "Epoch [25/100]: train=1.0209 val=0.9004, (0.9s)\n",
            "Epoch [26/100]: train=1.0043 val=0.889, (0.9s)\n",
            "Epoch [27/100]: train=0.985 val=0.8795, (0.8s)\n",
            "Epoch [28/100]: train=0.9741 val=0.8691, (0.8s)\n",
            "Epoch [29/100]: train=0.9729 val=0.8603, (0.8s)\n",
            "Epoch [30/100]: train=0.9535 val=0.8512, (0.8s)\n",
            "Epoch [31/100]: train=0.9507 val=0.8432, (0.8s)\n",
            "Epoch [32/100]: train=0.9413 val=0.8351, (0.8s)\n",
            "Epoch [33/100]: train=0.9221 val=0.8275, (0.8s)\n",
            "Epoch [34/100]: train=0.9164 val=0.8197, (0.8s)\n",
            "Epoch [35/100]: train=0.9134 val=0.8129, (0.8s)\n",
            "Epoch [36/100]: train=0.9014 val=0.8058, (0.8s)\n",
            "Epoch [37/100]: train=0.8997 val=0.7995, (0.8s)\n",
            "Epoch [38/100]: train=0.894 val=0.7945, (0.9s)\n",
            "Epoch [39/100]: train=0.8875 val=0.7889, (0.9s)\n",
            "Epoch [40/100]: train=0.8697 val=0.7827, (0.9s)\n",
            "Epoch [41/100]: train=0.8789 val=0.7766, (0.9s)\n",
            "Epoch [42/100]: train=0.8622 val=0.7704, (0.8s)\n",
            "Epoch [43/100]: train=0.8619 val=0.7655, (0.8s)\n",
            "Epoch [44/100]: train=0.8629 val=0.7605, (0.8s)\n",
            "Epoch [45/100]: train=0.8507 val=0.7553, (0.8s)\n",
            "Epoch [46/100]: train=0.848 val=0.7501, (0.8s)\n",
            "Epoch [47/100]: train=0.8302 val=0.7448, (0.8s)\n",
            "Epoch [48/100]: train=0.8364 val=0.7399, (0.8s)\n",
            "Epoch [49/100]: train=0.8304 val=0.7352, (0.8s)\n",
            "Epoch [50/100]: train=0.819 val=0.731, (0.8s)\n",
            "Epoch [51/100]: train=0.8082 val=0.7271, (0.8s)\n",
            "Epoch [52/100]: train=0.8125 val=0.7227, (0.8s)\n",
            "Epoch [53/100]: train=0.8074 val=0.718, (0.9s)\n",
            "Epoch [54/100]: train=0.8031 val=0.7137, (0.9s)\n",
            "Epoch [55/100]: train=0.795 val=0.7095, (0.9s)\n",
            "Epoch [56/100]: train=0.7978 val=0.7061, (0.9s)\n",
            "Epoch [57/100]: train=0.783 val=0.7024, (0.8s)\n",
            "Epoch [58/100]: train=0.7847 val=0.6991, (0.8s)\n",
            "Epoch [59/100]: train=0.7836 val=0.6953, (0.8s)\n",
            "Epoch [60/100]: train=0.7766 val=0.6922, (0.8s)\n",
            "Epoch [61/100]: train=0.7715 val=0.6887, (0.8s)\n",
            "Epoch [62/100]: train=0.771 val=0.6845, (0.8s)\n",
            "Epoch [63/100]: train=0.7715 val=0.6813, (0.8s)\n",
            "Epoch [64/100]: train=0.7698 val=0.6784, (0.8s)\n",
            "Epoch [65/100]: train=0.7615 val=0.6757, (0.8s)\n",
            "Epoch [66/100]: train=0.7512 val=0.6718, (0.8s)\n",
            "Epoch [67/100]: train=0.7573 val=0.6689, (0.8s)\n",
            "Epoch [68/100]: train=0.7416 val=0.6662, (0.9s)\n",
            "Epoch [69/100]: train=0.7487 val=0.6627, (0.9s)\n",
            "Epoch [70/100]: train=0.7496 val=0.6598, (0.9s)\n",
            "Epoch [71/100]: train=0.7341 val=0.6573, (0.9s)\n",
            "Epoch [72/100]: train=0.719 val=0.6541, (0.8s)\n",
            "Epoch [73/100]: train=0.7332 val=0.6513, (0.8s)\n",
            "Epoch [74/100]: train=0.7309 val=0.6486, (0.8s)\n",
            "Epoch [75/100]: train=0.7421 val=0.6457, (0.8s)\n",
            "Epoch [76/100]: train=0.7109 val=0.6435, (0.8s)\n",
            "Epoch [77/100]: train=0.7293 val=0.6413, (0.8s)\n",
            "Epoch [78/100]: train=0.7166 val=0.6392, (0.8s)\n",
            "Epoch [79/100]: train=0.7183 val=0.6365, (0.8s)\n",
            "Epoch [80/100]: train=0.7045 val=0.6335, (0.8s)\n",
            "Epoch [81/100]: train=0.7091 val=0.631, (0.8s)\n",
            "Epoch [82/100]: train=0.7181 val=0.6284, (0.8s)\n",
            "Epoch [83/100]: train=0.698 val=0.6265, (0.8s)\n",
            "Epoch [84/100]: train=0.7147 val=0.6242, (0.9s)\n",
            "Epoch [85/100]: train=0.712 val=0.6221, (0.9s)\n",
            "Epoch [86/100]: train=0.6975 val=0.6197, (0.9s)\n",
            "Epoch [87/100]: train=0.6969 val=0.6183, (0.8s)\n",
            "Epoch [88/100]: train=0.6849 val=0.6156, (0.8s)\n",
            "Epoch [89/100]: train=0.7018 val=0.6137, (0.8s)\n",
            "Epoch [90/100]: train=0.6878 val=0.6117, (0.8s)\n",
            "Epoch [91/100]: train=0.6804 val=0.6106, (0.8s)\n",
            "Epoch [92/100]: train=0.6949 val=0.6083, (0.8s)\n",
            "Epoch [93/100]: train=0.6698 val=0.6063, (0.8s)\n",
            "Epoch [94/100]: train=0.6869 val=0.6041, (0.8s)\n",
            "Epoch [95/100]: train=0.6924 val=0.6016, (0.8s)\n",
            "Epoch [96/100]: train=0.6836 val=0.5993, (0.8s)\n",
            "Epoch [97/100]: train=0.673 val=0.5978, (0.8s)\n",
            "Epoch [98/100]: train=0.6755 val=0.5958, (0.9s)\n",
            "Epoch [99/100]: train=0.6545 val=0.5945, (0.9s)\n",
            "Epoch [100/100]: train=0.6629 val=0.5923, (0.9s)\n",
            "Training on task 8...\n",
            "Epoch [1/100]: train=1.6528 val=1.4915, (0.9s)\n",
            "Epoch [2/100]: train=1.5635 val=1.4231, (0.9s)\n",
            "Epoch [3/100]: train=1.5134 val=1.3677, (0.9s)\n",
            "Epoch [4/100]: train=1.4651 val=1.3194, (0.9s)\n",
            "Epoch [5/100]: train=1.4113 val=1.2777, (0.9s)\n",
            "Epoch [6/100]: train=1.3868 val=1.2398, (0.9s)\n",
            "Epoch [7/100]: train=1.334 val=1.2053, (0.9s)\n",
            "Epoch [8/100]: train=1.2964 val=1.1758, (1.0s)\n",
            "Epoch [9/100]: train=1.2651 val=1.1477, (1.0s)\n",
            "Epoch [10/100]: train=1.2508 val=1.1225, (1.0s)\n",
            "Epoch [11/100]: train=1.2202 val=1.0982, (0.9s)\n",
            "Epoch [12/100]: train=1.2034 val=1.0759, (0.9s)\n",
            "Epoch [13/100]: train=1.1731 val=1.0552, (0.9s)\n",
            "Epoch [14/100]: train=1.1387 val=1.0365, (0.9s)\n",
            "Epoch [15/100]: train=1.133 val=1.0192, (0.9s)\n",
            "Epoch [16/100]: train=1.1126 val=1.0022, (0.9s)\n",
            "Epoch [17/100]: train=1.0927 val=0.9865, (0.9s)\n",
            "Epoch [18/100]: train=1.0805 val=0.9714, (0.9s)\n",
            "Epoch [19/100]: train=1.0561 val=0.9575, (0.9s)\n",
            "Epoch [20/100]: train=1.0453 val=0.9447, (0.9s)\n",
            "Epoch [21/100]: train=1.043 val=0.9331, (1.0s)\n",
            "Epoch [22/100]: train=1.023 val=0.921, (1.0s)\n",
            "Epoch [23/100]: train=1.0152 val=0.9092, (1.0s)\n",
            "Epoch [24/100]: train=1.0058 val=0.8988, (0.9s)\n",
            "Epoch [25/100]: train=0.9943 val=0.888, (0.9s)\n",
            "Epoch [26/100]: train=0.9796 val=0.8786, (0.9s)\n",
            "Epoch [27/100]: train=0.9648 val=0.8687, (0.9s)\n",
            "Epoch [28/100]: train=0.9519 val=0.8587, (0.9s)\n",
            "Epoch [29/100]: train=0.9488 val=0.8501, (0.9s)\n",
            "Epoch [30/100]: train=0.9433 val=0.8427, (0.9s)\n",
            "Epoch [31/100]: train=0.938 val=0.835, (0.9s)\n",
            "Epoch [32/100]: train=0.9229 val=0.8272, (0.9s)\n",
            "Epoch [33/100]: train=0.9188 val=0.8201, (0.9s)\n",
            "Epoch [34/100]: train=0.9183 val=0.8133, (0.9s)\n",
            "Epoch [35/100]: train=0.9031 val=0.8068, (1.0s)\n",
            "Epoch [36/100]: train=0.8956 val=0.8001, (1.0s)\n",
            "Epoch [37/100]: train=0.8686 val=0.7942, (1.0s)\n",
            "Epoch [38/100]: train=0.8686 val=0.7884, (0.9s)\n",
            "Epoch [39/100]: train=0.8703 val=0.7827, (0.9s)\n",
            "Epoch [40/100]: train=0.8662 val=0.778, (0.9s)\n",
            "Epoch [41/100]: train=0.863 val=0.772, (0.9s)\n",
            "Epoch [42/100]: train=0.8565 val=0.766, (0.9s)\n",
            "Epoch [43/100]: train=0.8358 val=0.7608, (0.9s)\n",
            "Epoch [44/100]: train=0.8338 val=0.7554, (0.9s)\n",
            "Epoch [45/100]: train=0.8441 val=0.7501, (0.9s)\n",
            "Epoch [46/100]: train=0.8293 val=0.7452, (0.9s)\n",
            "Epoch [47/100]: train=0.8337 val=0.7419, (0.9s)\n",
            "Epoch [48/100]: train=0.8083 val=0.7372, (1.0s)\n",
            "Epoch [49/100]: train=0.8174 val=0.7324, (1.0s)\n",
            "Epoch [50/100]: train=0.8244 val=0.7277, (1.0s)\n",
            "Epoch [51/100]: train=0.8165 val=0.7238, (0.9s)\n",
            "Epoch [52/100]: train=0.7919 val=0.7199, (0.9s)\n",
            "Epoch [53/100]: train=0.7897 val=0.7161, (0.9s)\n",
            "Epoch [54/100]: train=0.7942 val=0.7132, (0.9s)\n",
            "Epoch [55/100]: train=0.7916 val=0.7094, (0.9s)\n",
            "Epoch [56/100]: train=0.7813 val=0.7061, (0.9s)\n",
            "Epoch [57/100]: train=0.7824 val=0.7018, (0.9s)\n",
            "Epoch [58/100]: train=0.77 val=0.6979, (0.9s)\n",
            "Epoch [59/100]: train=0.7867 val=0.6941, (0.9s)\n",
            "Epoch [60/100]: train=0.7632 val=0.6907, (0.9s)\n",
            "Epoch [61/100]: train=0.7662 val=0.6874, (1.0s)\n",
            "Epoch [62/100]: train=0.7728 val=0.684, (1.0s)\n",
            "Epoch [63/100]: train=0.7626 val=0.6813, (1.0s)\n",
            "Epoch [64/100]: train=0.7528 val=0.6785, (1.0s)\n",
            "Epoch [65/100]: train=0.746 val=0.6749, (0.9s)\n",
            "Epoch [66/100]: train=0.7367 val=0.672, (0.9s)\n",
            "Epoch [67/100]: train=0.7432 val=0.6686, (0.9s)\n",
            "Epoch [68/100]: train=0.7416 val=0.6653, (0.9s)\n",
            "Epoch [69/100]: train=0.7472 val=0.6623, (0.9s)\n",
            "Epoch [70/100]: train=0.7502 val=0.6594, (0.9s)\n",
            "Epoch [71/100]: train=0.7297 val=0.6571, (0.9s)\n",
            "Epoch [72/100]: train=0.7178 val=0.6548, (0.9s)\n",
            "Epoch [73/100]: train=0.7287 val=0.6524, (0.9s)\n",
            "Epoch [74/100]: train=0.7217 val=0.6499, (0.9s)\n",
            "Epoch [75/100]: train=0.7215 val=0.6475, (1.0s)\n",
            "Epoch [76/100]: train=0.7076 val=0.6453, (1.0s)\n",
            "Epoch [77/100]: train=0.7083 val=0.6427, (1.0s)\n",
            "Epoch [78/100]: train=0.7044 val=0.6406, (0.9s)\n",
            "Epoch [79/100]: train=0.7165 val=0.6376, (0.9s)\n",
            "Epoch [80/100]: train=0.7194 val=0.6346, (0.9s)\n",
            "Epoch [81/100]: train=0.7075 val=0.6333, (0.9s)\n",
            "Epoch [82/100]: train=0.7037 val=0.6311, (0.9s)\n",
            "Epoch [83/100]: train=0.6855 val=0.6281, (0.9s)\n",
            "Epoch [84/100]: train=0.7023 val=0.6273, (0.9s)\n",
            "Epoch [85/100]: train=0.6961 val=0.6247, (0.9s)\n",
            "Epoch [86/100]: train=0.6954 val=0.6228, (0.9s)\n",
            "Epoch [87/100]: train=0.6893 val=0.6204, (0.9s)\n",
            "Epoch [88/100]: train=0.6856 val=0.6189, (1.0s)\n",
            "Epoch [89/100]: train=0.6853 val=0.6166, (1.0s)\n",
            "Epoch [90/100]: train=0.6745 val=0.6142, (1.0s)\n",
            "Epoch [91/100]: train=0.6795 val=0.6124, (0.9s)\n",
            "Epoch [92/100]: train=0.6695 val=0.6101, (0.9s)\n",
            "Epoch [93/100]: train=0.6728 val=0.6085, (0.9s)\n",
            "Epoch [94/100]: train=0.6869 val=0.6067, (0.9s)\n",
            "Epoch [95/100]: train=0.6594 val=0.6042, (0.9s)\n",
            "Epoch [96/100]: train=0.6713 val=0.6028, (0.9s)\n",
            "Epoch [97/100]: train=0.6708 val=0.6006, (0.9s)\n",
            "Epoch [98/100]: train=0.6675 val=0.5983, (0.9s)\n",
            "Epoch [99/100]: train=0.6558 val=0.5968, (0.9s)\n",
            "Epoch [100/100]: train=0.6654 val=0.5948, (0.9s)\n",
            "Training on task 9...\n",
            "Epoch [1/100]: train=1.7129 val=1.5312, (1.0s)\n",
            "Epoch [2/100]: train=1.6055 val=1.4564, (1.0s)\n",
            "Epoch [3/100]: train=1.544 val=1.3975, (1.0s)\n",
            "Epoch [4/100]: train=1.4873 val=1.3488, (1.0s)\n",
            "Epoch [5/100]: train=1.4445 val=1.3061, (1.0s)\n",
            "Epoch [6/100]: train=1.3982 val=1.2673, (1.0s)\n",
            "Epoch [7/100]: train=1.3703 val=1.2323, (1.0s)\n",
            "Epoch [8/100]: train=1.3388 val=1.1997, (1.1s)\n",
            "Epoch [9/100]: train=1.291 val=1.1713, (1.1s)\n",
            "Epoch [10/100]: train=1.2731 val=1.146, (1.1s)\n",
            "Epoch [11/100]: train=1.2532 val=1.1191, (1.1s)\n",
            "Epoch [12/100]: train=1.2186 val=1.0965, (1.0s)\n",
            "Epoch [13/100]: train=1.1895 val=1.0761, (1.0s)\n",
            "Epoch [14/100]: train=1.1693 val=1.056, (1.0s)\n",
            "Epoch [15/100]: train=1.1486 val=1.0375, (1.0s)\n",
            "Epoch [16/100]: train=1.1304 val=1.0207, (1.0s)\n",
            "Epoch [17/100]: train=1.1013 val=1.0048, (1.0s)\n",
            "Epoch [18/100]: train=1.1048 val=0.9898, (1.0s)\n",
            "Epoch [19/100]: train=1.077 val=0.9755, (1.0s)\n",
            "Epoch [20/100]: train=1.0625 val=0.9619, (1.0s)\n",
            "Epoch [21/100]: train=1.0584 val=0.9491, (1.1s)\n",
            "Epoch [22/100]: train=1.0526 val=0.9366, (1.1s)\n",
            "Epoch [23/100]: train=1.0316 val=0.9251, (1.1s)\n",
            "Epoch [24/100]: train=1.0149 val=0.9143, (1.0s)\n",
            "Epoch [25/100]: train=1.0126 val=0.903, (1.0s)\n",
            "Epoch [26/100]: train=0.9981 val=0.8925, (1.0s)\n",
            "Epoch [27/100]: train=0.9951 val=0.8835, (1.0s)\n",
            "Epoch [28/100]: train=0.9759 val=0.8742, (1.0s)\n",
            "Epoch [29/100]: train=0.9637 val=0.8664, (1.0s)\n",
            "Epoch [30/100]: train=0.9678 val=0.8583, (1.0s)\n",
            "Epoch [31/100]: train=0.9515 val=0.8508, (1.0s)\n",
            "Epoch [32/100]: train=0.9538 val=0.8425, (1.0s)\n",
            "Epoch [33/100]: train=0.9267 val=0.8357, (1.1s)\n",
            "Epoch [34/100]: train=0.9171 val=0.828, (1.1s)\n",
            "Epoch [35/100]: train=0.9274 val=0.8215, (1.1s)\n",
            "Epoch [36/100]: train=0.9062 val=0.8151, (1.0s)\n",
            "Epoch [37/100]: train=0.9001 val=0.8092, (1.0s)\n",
            "Epoch [38/100]: train=0.8895 val=0.8024, (1.0s)\n",
            "Epoch [39/100]: train=0.8965 val=0.7963, (1.0s)\n",
            "Epoch [40/100]: train=0.8793 val=0.7906, (1.0s)\n",
            "Epoch [41/100]: train=0.8763 val=0.7848, (1.0s)\n",
            "Epoch [42/100]: train=0.8715 val=0.78, (1.0s)\n",
            "Epoch [43/100]: train=0.8575 val=0.7748, (1.0s)\n",
            "Epoch [44/100]: train=0.8749 val=0.7694, (1.0s)\n",
            "Epoch [45/100]: train=0.8514 val=0.7645, (1.1s)\n",
            "Epoch [46/100]: train=0.8475 val=0.759, (1.1s)\n",
            "Epoch [47/100]: train=0.8361 val=0.7543, (1.1s)\n",
            "Epoch [48/100]: train=0.8204 val=0.7495, (1.0s)\n",
            "Epoch [49/100]: train=0.8284 val=0.7452, (1.0s)\n",
            "Epoch [50/100]: train=0.8347 val=0.7405, (1.0s)\n",
            "Epoch [51/100]: train=0.8229 val=0.7364, (1.0s)\n",
            "Epoch [52/100]: train=0.8189 val=0.7325, (1.0s)\n",
            "Epoch [53/100]: train=0.819 val=0.7284, (1.0s)\n",
            "Epoch [54/100]: train=0.8101 val=0.7246, (1.0s)\n",
            "Epoch [55/100]: train=0.8132 val=0.7205, (1.0s)\n",
            "Epoch [56/100]: train=0.8107 val=0.7163, (1.0s)\n",
            "Epoch [57/100]: train=0.7899 val=0.7126, (1.1s)\n",
            "Epoch [58/100]: train=0.7973 val=0.7093, (1.1s)\n",
            "Epoch [59/100]: train=0.8002 val=0.7055, (1.1s)\n",
            "Epoch [60/100]: train=0.7849 val=0.7017, (1.0s)\n",
            "Epoch [61/100]: train=0.7856 val=0.698, (1.0s)\n",
            "Epoch [62/100]: train=0.7915 val=0.694, (1.0s)\n",
            "Epoch [63/100]: train=0.7794 val=0.6907, (1.0s)\n",
            "Epoch [64/100]: train=0.769 val=0.6882, (1.0s)\n",
            "Epoch [65/100]: train=0.7675 val=0.6848, (1.0s)\n",
            "Epoch [66/100]: train=0.7442 val=0.6827, (1.0s)\n",
            "Epoch [67/100]: train=0.7582 val=0.6797, (1.0s)\n",
            "Epoch [68/100]: train=0.7541 val=0.677, (1.0s)\n",
            "Epoch [69/100]: train=0.754 val=0.674, (1.1s)\n",
            "Epoch [70/100]: train=0.7535 val=0.6707, (1.1s)\n",
            "Epoch [71/100]: train=0.7535 val=0.6683, (1.1s)\n",
            "Epoch [72/100]: train=0.7449 val=0.665, (1.0s)\n",
            "Epoch [73/100]: train=0.7406 val=0.6623, (1.0s)\n",
            "Epoch [74/100]: train=0.74 val=0.6602, (1.0s)\n",
            "Epoch [75/100]: train=0.7356 val=0.657, (1.0s)\n",
            "Epoch [76/100]: train=0.721 val=0.6541, (1.0s)\n",
            "Epoch [77/100]: train=0.7348 val=0.6515, (1.0s)\n",
            "Epoch [78/100]: train=0.7332 val=0.6492, (1.0s)\n",
            "Epoch [79/100]: train=0.7229 val=0.6468, (1.0s)\n",
            "Epoch [80/100]: train=0.7261 val=0.6442, (1.0s)\n",
            "Epoch [81/100]: train=0.7167 val=0.641, (1.1s)\n",
            "Epoch [82/100]: train=0.7095 val=0.6388, (1.1s)\n",
            "Epoch [83/100]: train=0.7182 val=0.636, (1.1s)\n",
            "Epoch [84/100]: train=0.7098 val=0.6341, (1.0s)\n",
            "Epoch [85/100]: train=0.7085 val=0.6317, (1.0s)\n",
            "Epoch [86/100]: train=0.6966 val=0.6293, (1.0s)\n",
            "Epoch [87/100]: train=0.7105 val=0.6275, (1.0s)\n",
            "Epoch [88/100]: train=0.7014 val=0.6252, (1.0s)\n",
            "Epoch [89/100]: train=0.696 val=0.6236, (1.0s)\n",
            "Epoch [90/100]: train=0.7033 val=0.622, (1.0s)\n",
            "Epoch [91/100]: train=0.6985 val=0.6191, (1.0s)\n",
            "Epoch [92/100]: train=0.6779 val=0.6169, (1.0s)\n",
            "Epoch [93/100]: train=0.693 val=0.6149, (1.1s)\n",
            "Epoch [94/100]: train=0.6864 val=0.6126, (1.1s)\n",
            "Epoch [95/100]: train=0.6819 val=0.6107, (1.1s)\n",
            "Epoch [96/100]: train=0.6815 val=0.6088, (1.0s)\n",
            "Epoch [97/100]: train=0.6838 val=0.6072, (1.0s)\n",
            "Epoch [98/100]: train=0.6778 val=0.6053, (1.0s)\n",
            "Epoch [99/100]: train=0.6737 val=0.6043, (1.0s)\n",
            "Epoch [100/100]: train=0.6741 val=0.6018, (1.0s)\n",
            "Training on task 10...\n",
            "Epoch [1/100]: train=1.6719 val=1.4918, (1.2s)\n",
            "Epoch [2/100]: train=1.5796 val=1.4165, (1.2s)\n",
            "Epoch [3/100]: train=1.5014 val=1.3615, (1.1s)\n",
            "Epoch [4/100]: train=1.4459 val=1.3134, (1.1s)\n",
            "Epoch [5/100]: train=1.4175 val=1.2719, (1.1s)\n",
            "Epoch [6/100]: train=1.3714 val=1.2363, (1.1s)\n",
            "Epoch [7/100]: train=1.3499 val=1.2035, (1.1s)\n",
            "Epoch [8/100]: train=1.3299 val=1.1733, (1.1s)\n",
            "Epoch [9/100]: train=1.2774 val=1.1469, (1.1s)\n",
            "Epoch [10/100]: train=1.2483 val=1.1217, (1.1s)\n",
            "Epoch [11/100]: train=1.2287 val=1.0974, (1.2s)\n",
            "Epoch [12/100]: train=1.196 val=1.0764, (1.2s)\n",
            "Epoch [13/100]: train=1.1641 val=1.0573, (1.2s)\n",
            "Epoch [14/100]: train=1.1546 val=1.0385, (1.1s)\n",
            "Epoch [15/100]: train=1.156 val=1.0216, (1.1s)\n",
            "Epoch [16/100]: train=1.1215 val=1.0049, (1.1s)\n",
            "Epoch [17/100]: train=1.1094 val=0.9888, (1.1s)\n",
            "Epoch [18/100]: train=1.0888 val=0.975, (1.1s)\n",
            "Epoch [19/100]: train=1.073 val=0.9624, (1.1s)\n",
            "Epoch [20/100]: train=1.0624 val=0.9498, (1.1s)\n",
            "Epoch [21/100]: train=1.0557 val=0.9375, (1.1s)\n",
            "Epoch [22/100]: train=1.0288 val=0.9254, (1.2s)\n",
            "Epoch [23/100]: train=1.0282 val=0.9143, (1.2s)\n",
            "Epoch [24/100]: train=1.0025 val=0.9046, (1.2s)\n",
            "Epoch [25/100]: train=0.9944 val=0.8955, (1.1s)\n",
            "Epoch [26/100]: train=1.0006 val=0.8859, (1.1s)\n",
            "Epoch [27/100]: train=0.976 val=0.8765, (1.1s)\n",
            "Epoch [28/100]: train=0.9704 val=0.8677, (1.1s)\n",
            "Epoch [29/100]: train=0.9601 val=0.8601, (1.1s)\n",
            "Epoch [30/100]: train=0.9599 val=0.853, (1.2s)\n",
            "Epoch [31/100]: train=0.9375 val=0.8457, (1.1s)\n",
            "Epoch [32/100]: train=0.9294 val=0.8372, (1.2s)\n",
            "Epoch [33/100]: train=0.9291 val=0.8307, (1.2s)\n",
            "Epoch [34/100]: train=0.9329 val=0.8243, (1.2s)\n",
            "Epoch [35/100]: train=0.9087 val=0.8173, (1.2s)\n",
            "Epoch [36/100]: train=0.9002 val=0.8109, (1.1s)\n",
            "Epoch [37/100]: train=0.8995 val=0.8045, (1.1s)\n",
            "Epoch [38/100]: train=0.8974 val=0.7985, (1.1s)\n",
            "Epoch [39/100]: train=0.895 val=0.7927, (1.2s)\n",
            "Epoch [40/100]: train=0.8741 val=0.7869, (1.2s)\n",
            "Epoch [41/100]: train=0.864 val=0.7821, (1.1s)\n",
            "Epoch [42/100]: train=0.8757 val=0.7763, (1.1s)\n",
            "Epoch [43/100]: train=0.8709 val=0.7706, (1.2s)\n",
            "Epoch [44/100]: train=0.8517 val=0.7662, (1.2s)\n",
            "Epoch [45/100]: train=0.8737 val=0.7613, (1.2s)\n",
            "Epoch [46/100]: train=0.847 val=0.7572, (1.1s)\n",
            "Epoch [47/100]: train=0.8374 val=0.7522, (1.1s)\n",
            "Epoch [48/100]: train=0.8348 val=0.7479, (1.1s)\n",
            "Epoch [49/100]: train=0.8322 val=0.7442, (1.1s)\n",
            "Epoch [50/100]: train=0.8331 val=0.7405, (1.2s)\n",
            "Epoch [51/100]: train=0.8176 val=0.7359, (1.1s)\n",
            "Epoch [52/100]: train=0.8156 val=0.7316, (1.1s)\n",
            "Epoch [53/100]: train=0.8016 val=0.7277, (1.1s)\n",
            "Epoch [54/100]: train=0.8023 val=0.7239, (1.2s)\n",
            "Epoch [55/100]: train=0.801 val=0.7201, (1.2s)\n",
            "Epoch [56/100]: train=0.8008 val=0.7157, (1.2s)\n",
            "Epoch [57/100]: train=0.7998 val=0.7122, (1.2s)\n",
            "Epoch [58/100]: train=0.8069 val=0.7084, (1.1s)\n",
            "Epoch [59/100]: train=0.7948 val=0.7045, (1.1s)\n",
            "Epoch [60/100]: train=0.7889 val=0.7015, (1.1s)\n",
            "Epoch [61/100]: train=0.7743 val=0.6987, (1.1s)\n",
            "Epoch [62/100]: train=0.7886 val=0.6962, (1.1s)\n",
            "Epoch [63/100]: train=0.7672 val=0.6921, (1.1s)\n",
            "Epoch [64/100]: train=0.7756 val=0.6883, (1.1s)\n",
            "Epoch [65/100]: train=0.7609 val=0.6858, (1.2s)\n",
            "Epoch [66/100]: train=0.764 val=0.682, (1.2s)\n",
            "Epoch [67/100]: train=0.7628 val=0.6793, (1.2s)\n",
            "Epoch [68/100]: train=0.7623 val=0.6764, (1.1s)\n",
            "Epoch [69/100]: train=0.7523 val=0.674, (1.1s)\n",
            "Epoch [70/100]: train=0.7503 val=0.6708, (1.1s)\n",
            "Epoch [71/100]: train=0.747 val=0.6685, (1.1s)\n",
            "Epoch [72/100]: train=0.7406 val=0.6656, (1.1s)\n",
            "Epoch [73/100]: train=0.7524 val=0.663, (1.1s)\n",
            "Epoch [74/100]: train=0.7512 val=0.6594, (1.1s)\n",
            "Epoch [75/100]: train=0.7365 val=0.6571, (1.1s)\n",
            "Epoch [76/100]: train=0.7351 val=0.6549, (1.2s)\n",
            "Epoch [77/100]: train=0.736 val=0.6521, (1.2s)\n",
            "Epoch [78/100]: train=0.7256 val=0.65, (1.2s)\n",
            "Epoch [79/100]: train=0.721 val=0.6478, (1.1s)\n",
            "Epoch [80/100]: train=0.7222 val=0.645, (1.1s)\n",
            "Epoch [81/100]: train=0.7247 val=0.6427, (1.1s)\n",
            "Epoch [82/100]: train=0.723 val=0.6396, (1.1s)\n",
            "Epoch [83/100]: train=0.7088 val=0.6373, (1.1s)\n",
            "Epoch [84/100]: train=0.7173 val=0.6351, (1.2s)\n",
            "Epoch [85/100]: train=0.7044 val=0.6328, (1.1s)\n",
            "Epoch [86/100]: train=0.7077 val=0.6301, (1.1s)\n",
            "Epoch [87/100]: train=0.6964 val=0.6284, (1.2s)\n",
            "Epoch [88/100]: train=0.6992 val=0.6258, (1.2s)\n",
            "Epoch [89/100]: train=0.6928 val=0.6237, (1.2s)\n",
            "Epoch [90/100]: train=0.709 val=0.6214, (1.1s)\n",
            "Epoch [91/100]: train=0.6953 val=0.619, (1.1s)\n",
            "Epoch [92/100]: train=0.6852 val=0.6177, (1.2s)\n",
            "Epoch [93/100]: train=0.6957 val=0.6155, (1.1s)\n",
            "Epoch [94/100]: train=0.6821 val=0.6133, (1.1s)\n",
            "Epoch [95/100]: train=0.6729 val=0.6115, (1.1s)\n",
            "Epoch [96/100]: train=0.6885 val=0.6095, (1.1s)\n",
            "Epoch [97/100]: train=0.6854 val=0.6082, (1.1s)\n",
            "Epoch [98/100]: train=0.6692 val=0.6061, (1.2s)\n",
            "Epoch [99/100]: train=0.6705 val=0.6042, (1.2s)\n",
            "Epoch [100/100]: train=0.6662 val=0.603, (1.2s)\n",
            "================================================\n",
            "SGD\n",
            "Training on task 1...\n",
            "Epoch [1/100]: train=2.3024 val=2.2986, (0.1s)\n",
            "Epoch [2/100]: train=2.2985 val=2.2948, (0.1s)\n",
            "Epoch [3/100]: train=2.2962 val=2.291, (0.1s)\n",
            "Epoch [4/100]: train=2.2917 val=2.2873, (0.1s)\n",
            "Epoch [5/100]: train=2.2884 val=2.2836, (0.1s)\n",
            "Epoch [6/100]: train=2.284 val=2.2799, (0.1s)\n",
            "Epoch [7/100]: train=2.2807 val=2.2761, (0.1s)\n",
            "Epoch [8/100]: train=2.2776 val=2.2724, (0.1s)\n",
            "Epoch [9/100]: train=2.2746 val=2.2687, (0.1s)\n",
            "Epoch [10/100]: train=2.2704 val=2.2649, (0.1s)\n",
            "Epoch [11/100]: train=2.2676 val=2.2611, (0.1s)\n",
            "Epoch [12/100]: train=2.264 val=2.2574, (0.1s)\n",
            "Epoch [13/100]: train=2.2599 val=2.2536, (0.1s)\n",
            "Epoch [14/100]: train=2.2579 val=2.2497, (0.1s)\n",
            "Epoch [15/100]: train=2.253 val=2.2459, (0.1s)\n",
            "Epoch [16/100]: train=2.2496 val=2.242, (0.1s)\n",
            "Epoch [17/100]: train=2.2478 val=2.238, (0.1s)\n",
            "Epoch [18/100]: train=2.242 val=2.2341, (0.1s)\n",
            "Epoch [19/100]: train=2.2377 val=2.23, (0.1s)\n",
            "Epoch [20/100]: train=2.2363 val=2.2259, (0.1s)\n",
            "Epoch [21/100]: train=2.2329 val=2.2218, (0.1s)\n",
            "Epoch [22/100]: train=2.2282 val=2.2176, (0.1s)\n",
            "Epoch [23/100]: train=2.2232 val=2.2133, (0.1s)\n",
            "Epoch [24/100]: train=2.2215 val=2.209, (0.1s)\n",
            "Epoch [25/100]: train=2.2172 val=2.2047, (0.1s)\n",
            "Epoch [26/100]: train=2.2134 val=2.2002, (0.1s)\n",
            "Epoch [27/100]: train=2.2069 val=2.1957, (0.1s)\n",
            "Epoch [28/100]: train=2.2034 val=2.191, (0.1s)\n",
            "Epoch [29/100]: train=2.1993 val=2.1863, (0.1s)\n",
            "Epoch [30/100]: train=2.1957 val=2.1816, (0.1s)\n",
            "Epoch [31/100]: train=2.1916 val=2.1767, (0.1s)\n",
            "Epoch [32/100]: train=2.1851 val=2.1717, (0.1s)\n",
            "Epoch [33/100]: train=2.1842 val=2.1666, (0.1s)\n",
            "Epoch [34/100]: train=2.1776 val=2.1615, (0.2s)\n",
            "Epoch [35/100]: train=2.1742 val=2.1563, (0.1s)\n",
            "Epoch [36/100]: train=2.1692 val=2.1509, (0.1s)\n",
            "Epoch [37/100]: train=2.1641 val=2.1454, (0.1s)\n",
            "Epoch [38/100]: train=2.1591 val=2.1398, (0.1s)\n",
            "Epoch [39/100]: train=2.1517 val=2.134, (0.1s)\n",
            "Epoch [40/100]: train=2.1492 val=2.1281, (0.1s)\n",
            "Epoch [41/100]: train=2.1444 val=2.1222, (0.1s)\n",
            "Epoch [42/100]: train=2.1391 val=2.1161, (0.1s)\n",
            "Epoch [43/100]: train=2.1332 val=2.1098, (0.2s)\n",
            "Epoch [44/100]: train=2.127 val=2.1034, (0.1s)\n",
            "Epoch [45/100]: train=2.1208 val=2.0969, (0.2s)\n",
            "Epoch [46/100]: train=2.1133 val=2.0902, (0.2s)\n",
            "Epoch [47/100]: train=2.1079 val=2.0833, (0.1s)\n",
            "Epoch [48/100]: train=2.1054 val=2.0763, (0.1s)\n",
            "Epoch [49/100]: train=2.0974 val=2.0691, (0.1s)\n",
            "Epoch [50/100]: train=2.0916 val=2.0618, (0.2s)\n",
            "Epoch [51/100]: train=2.084 val=2.0543, (0.2s)\n",
            "Epoch [52/100]: train=2.0773 val=2.0466, (0.1s)\n",
            "Epoch [53/100]: train=2.0703 val=2.0387, (0.1s)\n",
            "Epoch [54/100]: train=2.0625 val=2.0306, (0.1s)\n",
            "Epoch [55/100]: train=2.0574 val=2.0223, (0.1s)\n",
            "Epoch [56/100]: train=2.0499 val=2.0139, (0.1s)\n",
            "Epoch [57/100]: train=2.0418 val=2.0052, (0.1s)\n",
            "Epoch [58/100]: train=2.0341 val=1.9964, (0.1s)\n",
            "Epoch [59/100]: train=2.0262 val=1.9873, (0.1s)\n",
            "Epoch [60/100]: train=2.0166 val=1.978, (0.1s)\n",
            "Epoch [61/100]: train=2.0082 val=1.9685, (0.1s)\n",
            "Epoch [62/100]: train=1.998 val=1.9587, (0.1s)\n",
            "Epoch [63/100]: train=1.9881 val=1.9486, (0.1s)\n",
            "Epoch [64/100]: train=1.9826 val=1.9385, (0.1s)\n",
            "Epoch [65/100]: train=1.9737 val=1.9281, (0.1s)\n",
            "Epoch [66/100]: train=1.9626 val=1.9174, (0.1s)\n",
            "Epoch [67/100]: train=1.9542 val=1.9066, (0.1s)\n",
            "Epoch [68/100]: train=1.9444 val=1.8954, (0.1s)\n",
            "Epoch [69/100]: train=1.9304 val=1.884, (0.1s)\n",
            "Epoch [70/100]: train=1.9262 val=1.8725, (0.1s)\n",
            "Epoch [71/100]: train=1.9111 val=1.8606, (0.1s)\n",
            "Epoch [72/100]: train=1.9029 val=1.8486, (0.1s)\n",
            "Epoch [73/100]: train=1.8913 val=1.8363, (0.1s)\n",
            "Epoch [74/100]: train=1.8792 val=1.8238, (0.1s)\n",
            "Epoch [75/100]: train=1.8641 val=1.8109, (0.1s)\n",
            "Epoch [76/100]: train=1.8577 val=1.798, (0.1s)\n",
            "Epoch [77/100]: train=1.848 val=1.7849, (0.1s)\n",
            "Epoch [78/100]: train=1.8318 val=1.7715, (0.1s)\n",
            "Epoch [79/100]: train=1.8189 val=1.7579, (0.1s)\n",
            "Epoch [80/100]: train=1.8067 val=1.744, (0.1s)\n",
            "Epoch [81/100]: train=1.7968 val=1.7301, (0.1s)\n",
            "Epoch [82/100]: train=1.7835 val=1.716, (0.1s)\n",
            "Epoch [83/100]: train=1.7711 val=1.7018, (0.1s)\n",
            "Epoch [84/100]: train=1.7543 val=1.6872, (0.1s)\n",
            "Epoch [85/100]: train=1.7441 val=1.6726, (0.1s)\n",
            "Epoch [86/100]: train=1.7293 val=1.6577, (0.1s)\n",
            "Epoch [87/100]: train=1.7167 val=1.6429, (0.1s)\n",
            "Epoch [88/100]: train=1.6999 val=1.6277, (0.1s)\n",
            "Epoch [89/100]: train=1.6889 val=1.6125, (0.1s)\n",
            "Epoch [90/100]: train=1.6651 val=1.5971, (0.1s)\n",
            "Epoch [91/100]: train=1.6572 val=1.5818, (0.1s)\n",
            "Epoch [92/100]: train=1.6463 val=1.5664, (0.1s)\n",
            "Epoch [93/100]: train=1.6278 val=1.5509, (0.1s)\n",
            "Epoch [94/100]: train=1.6164 val=1.5355, (0.1s)\n",
            "Epoch [95/100]: train=1.6011 val=1.5198, (0.1s)\n",
            "Epoch [96/100]: train=1.5888 val=1.5042, (0.1s)\n",
            "Epoch [97/100]: train=1.5693 val=1.4886, (0.1s)\n",
            "Epoch [98/100]: train=1.5503 val=1.4728, (0.1s)\n",
            "Epoch [99/100]: train=1.5409 val=1.4573, (0.1s)\n",
            "Epoch [100/100]: train=1.5317 val=1.4418, (0.1s)\n",
            "Training on task 2...\n",
            "Epoch [1/100]: train=1.9312 val=1.862, (0.1s)\n",
            "Epoch [2/100]: train=1.9182 val=1.8422, (0.1s)\n",
            "Epoch [3/100]: train=1.9014 val=1.8227, (0.1s)\n",
            "Epoch [4/100]: train=1.8802 val=1.8039, (0.1s)\n",
            "Epoch [5/100]: train=1.8623 val=1.785, (0.1s)\n",
            "Epoch [6/100]: train=1.8464 val=1.7665, (0.1s)\n",
            "Epoch [7/100]: train=1.8307 val=1.7479, (0.1s)\n",
            "Epoch [8/100]: train=1.8114 val=1.7295, (0.1s)\n",
            "Epoch [9/100]: train=1.7979 val=1.7111, (0.1s)\n",
            "Epoch [10/100]: train=1.7756 val=1.6931, (0.1s)\n",
            "Epoch [11/100]: train=1.7655 val=1.6749, (0.1s)\n",
            "Epoch [12/100]: train=1.7472 val=1.6568, (0.1s)\n",
            "Epoch [13/100]: train=1.7337 val=1.6387, (0.1s)\n",
            "Epoch [14/100]: train=1.7137 val=1.6208, (0.1s)\n",
            "Epoch [15/100]: train=1.7024 val=1.6031, (0.1s)\n",
            "Epoch [16/100]: train=1.6849 val=1.5853, (0.1s)\n",
            "Epoch [17/100]: train=1.6594 val=1.5677, (0.1s)\n",
            "Epoch [18/100]: train=1.6454 val=1.5499, (0.1s)\n",
            "Epoch [19/100]: train=1.6347 val=1.5324, (0.1s)\n",
            "Epoch [20/100]: train=1.6198 val=1.5152, (0.1s)\n",
            "Epoch [21/100]: train=1.603 val=1.4978, (0.1s)\n",
            "Epoch [22/100]: train=1.582 val=1.4807, (0.1s)\n",
            "Epoch [23/100]: train=1.5657 val=1.4638, (0.1s)\n",
            "Epoch [24/100]: train=1.559 val=1.4469, (0.1s)\n",
            "Epoch [25/100]: train=1.5375 val=1.4303, (0.1s)\n",
            "Epoch [26/100]: train=1.5249 val=1.4139, (0.1s)\n",
            "Epoch [27/100]: train=1.5017 val=1.3978, (0.1s)\n",
            "Epoch [28/100]: train=1.4869 val=1.3816, (0.1s)\n",
            "Epoch [29/100]: train=1.472 val=1.3658, (0.1s)\n",
            "Epoch [30/100]: train=1.4635 val=1.3501, (0.1s)\n",
            "Epoch [31/100]: train=1.4468 val=1.3348, (0.1s)\n",
            "Epoch [32/100]: train=1.4292 val=1.3195, (0.1s)\n",
            "Epoch [33/100]: train=1.4214 val=1.3045, (0.1s)\n",
            "Epoch [34/100]: train=1.3991 val=1.2894, (0.1s)\n",
            "Epoch [35/100]: train=1.3885 val=1.2745, (0.1s)\n",
            "Epoch [36/100]: train=1.3739 val=1.2598, (0.2s)\n",
            "Epoch [37/100]: train=1.3632 val=1.2457, (0.2s)\n",
            "Epoch [38/100]: train=1.3459 val=1.2314, (0.1s)\n",
            "Epoch [39/100]: train=1.3327 val=1.2176, (0.1s)\n",
            "Epoch [40/100]: train=1.322 val=1.2039, (0.1s)\n",
            "Epoch [41/100]: train=1.2983 val=1.1907, (0.1s)\n",
            "Epoch [42/100]: train=1.2927 val=1.1777, (0.1s)\n",
            "Epoch [43/100]: train=1.2755 val=1.1644, (0.1s)\n",
            "Epoch [44/100]: train=1.2703 val=1.1516, (0.2s)\n",
            "Epoch [45/100]: train=1.2557 val=1.1391, (0.1s)\n",
            "Epoch [46/100]: train=1.2476 val=1.1269, (0.1s)\n",
            "Epoch [47/100]: train=1.2305 val=1.1147, (0.2s)\n",
            "Epoch [48/100]: train=1.2171 val=1.1027, (0.2s)\n",
            "Epoch [49/100]: train=1.2079 val=1.0912, (0.1s)\n",
            "Epoch [50/100]: train=1.2104 val=1.0798, (0.1s)\n",
            "Epoch [51/100]: train=1.1843 val=1.0685, (0.2s)\n",
            "Epoch [52/100]: train=1.1713 val=1.0578, (0.2s)\n",
            "Epoch [53/100]: train=1.1625 val=1.0471, (0.1s)\n",
            "Epoch [54/100]: train=1.1537 val=1.0362, (0.1s)\n",
            "Epoch [55/100]: train=1.139 val=1.0257, (0.1s)\n",
            "Epoch [56/100]: train=1.1329 val=1.0155, (0.1s)\n",
            "Epoch [57/100]: train=1.1233 val=1.0058, (0.1s)\n",
            "Epoch [58/100]: train=1.1143 val=0.9959, (0.1s)\n",
            "Epoch [59/100]: train=1.1048 val=0.9862, (0.1s)\n",
            "Epoch [60/100]: train=1.0977 val=0.9769, (0.1s)\n",
            "Epoch [61/100]: train=1.0855 val=0.9675, (0.1s)\n",
            "Epoch [62/100]: train=1.0775 val=0.9585, (0.1s)\n",
            "Epoch [63/100]: train=1.0725 val=0.9499, (0.1s)\n",
            "Epoch [64/100]: train=1.0658 val=0.9414, (0.1s)\n",
            "Epoch [65/100]: train=1.0555 val=0.9332, (0.1s)\n",
            "Epoch [66/100]: train=1.0343 val=0.9246, (0.1s)\n",
            "Epoch [67/100]: train=1.0375 val=0.9163, (0.1s)\n",
            "Epoch [68/100]: train=1.023 val=0.9079, (0.1s)\n",
            "Epoch [69/100]: train=1.021 val=0.9001, (0.1s)\n",
            "Epoch [70/100]: train=1.0136 val=0.8928, (0.1s)\n",
            "Epoch [71/100]: train=1.0002 val=0.8854, (0.1s)\n",
            "Epoch [72/100]: train=0.9856 val=0.8782, (0.1s)\n",
            "Epoch [73/100]: train=0.9835 val=0.871, (0.1s)\n",
            "Epoch [74/100]: train=0.9789 val=0.8638, (0.1s)\n",
            "Epoch [75/100]: train=0.9762 val=0.857, (0.1s)\n",
            "Epoch [76/100]: train=0.9685 val=0.8502, (0.1s)\n",
            "Epoch [77/100]: train=0.9573 val=0.8439, (0.1s)\n",
            "Epoch [78/100]: train=0.9542 val=0.837, (0.1s)\n",
            "Epoch [79/100]: train=0.9435 val=0.8302, (0.1s)\n",
            "Epoch [80/100]: train=0.9423 val=0.8238, (0.1s)\n",
            "Epoch [81/100]: train=0.9312 val=0.8181, (0.1s)\n",
            "Epoch [82/100]: train=0.9177 val=0.8118, (0.1s)\n",
            "Epoch [83/100]: train=0.9225 val=0.8063, (0.1s)\n",
            "Epoch [84/100]: train=0.9166 val=0.8005, (0.1s)\n",
            "Epoch [85/100]: train=0.9155 val=0.7949, (0.1s)\n",
            "Epoch [86/100]: train=0.8936 val=0.79, (0.1s)\n",
            "Epoch [87/100]: train=0.8995 val=0.7844, (0.1s)\n",
            "Epoch [88/100]: train=0.8896 val=0.7789, (0.1s)\n",
            "Epoch [89/100]: train=0.8978 val=0.774, (0.1s)\n",
            "Epoch [90/100]: train=0.8764 val=0.7693, (0.1s)\n",
            "Epoch [91/100]: train=0.8729 val=0.7646, (0.1s)\n",
            "Epoch [92/100]: train=0.8767 val=0.7596, (0.1s)\n",
            "Epoch [93/100]: train=0.8594 val=0.7544, (0.1s)\n",
            "Epoch [94/100]: train=0.8644 val=0.7496, (0.1s)\n",
            "Epoch [95/100]: train=0.8499 val=0.7449, (0.1s)\n",
            "Epoch [96/100]: train=0.8439 val=0.7403, (0.1s)\n",
            "Epoch [97/100]: train=0.8436 val=0.7353, (0.1s)\n",
            "Epoch [98/100]: train=0.8368 val=0.731, (0.1s)\n",
            "Epoch [99/100]: train=0.8332 val=0.7266, (0.1s)\n",
            "Epoch [100/100]: train=0.8303 val=0.723, (0.1s)\n",
            "Training on task 3...\n",
            "Epoch [1/100]: train=1.681 val=1.5519, (0.1s)\n",
            "Epoch [2/100]: train=1.6302 val=1.502, (0.1s)\n",
            "Epoch [3/100]: train=1.5848 val=1.462, (0.1s)\n",
            "Epoch [4/100]: train=1.5644 val=1.4243, (0.1s)\n",
            "Epoch [5/100]: train=1.5211 val=1.3905, (0.1s)\n",
            "Epoch [6/100]: train=1.4874 val=1.3589, (0.1s)\n",
            "Epoch [7/100]: train=1.4464 val=1.3298, (0.1s)\n",
            "Epoch [8/100]: train=1.4239 val=1.3017, (0.1s)\n",
            "Epoch [9/100]: train=1.3878 val=1.276, (0.1s)\n",
            "Epoch [10/100]: train=1.3874 val=1.2512, (0.1s)\n",
            "Epoch [11/100]: train=1.3562 val=1.2277, (0.1s)\n",
            "Epoch [12/100]: train=1.3283 val=1.2053, (0.1s)\n",
            "Epoch [13/100]: train=1.3128 val=1.1833, (0.1s)\n",
            "Epoch [14/100]: train=1.2949 val=1.1637, (0.1s)\n",
            "Epoch [15/100]: train=1.2774 val=1.1439, (0.1s)\n",
            "Epoch [16/100]: train=1.2544 val=1.1262, (0.1s)\n",
            "Epoch [17/100]: train=1.2195 val=1.1095, (0.1s)\n",
            "Epoch [18/100]: train=1.2059 val=1.0918, (0.1s)\n",
            "Epoch [19/100]: train=1.2009 val=1.0759, (0.1s)\n",
            "Epoch [20/100]: train=1.1708 val=1.0608, (0.1s)\n",
            "Epoch [21/100]: train=1.1793 val=1.047, (0.1s)\n",
            "Epoch [22/100]: train=1.1528 val=1.0324, (0.1s)\n",
            "Epoch [23/100]: train=1.1387 val=1.0191, (0.1s)\n",
            "Epoch [24/100]: train=1.1301 val=1.006, (0.1s)\n",
            "Epoch [25/100]: train=1.1282 val=0.9935, (0.1s)\n",
            "Epoch [26/100]: train=1.1002 val=0.9814, (0.1s)\n",
            "Epoch [27/100]: train=1.0796 val=0.9697, (0.1s)\n",
            "Epoch [28/100]: train=1.0805 val=0.958, (0.2s)\n",
            "Epoch [29/100]: train=1.0647 val=0.9475, (0.1s)\n",
            "Epoch [30/100]: train=1.0614 val=0.9372, (0.1s)\n",
            "Epoch [31/100]: train=1.04 val=0.9279, (0.1s)\n",
            "Epoch [32/100]: train=1.0381 val=0.9181, (0.1s)\n",
            "Epoch [33/100]: train=1.0235 val=0.9086, (0.1s)\n",
            "Epoch [34/100]: train=1.0145 val=0.8995, (0.1s)\n",
            "Epoch [35/100]: train=1.0082 val=0.8902, (0.1s)\n",
            "Epoch [36/100]: train=0.9949 val=0.8827, (0.2s)\n",
            "Epoch [37/100]: train=0.9922 val=0.8745, (0.2s)\n",
            "Epoch [38/100]: train=0.9699 val=0.8662, (0.2s)\n",
            "Epoch [39/100]: train=0.9754 val=0.8583, (0.2s)\n",
            "Epoch [40/100]: train=0.9617 val=0.851, (0.2s)\n",
            "Epoch [41/100]: train=0.9639 val=0.8443, (0.2s)\n",
            "Epoch [42/100]: train=0.9553 val=0.8369, (0.2s)\n",
            "Epoch [43/100]: train=0.9532 val=0.83, (0.1s)\n",
            "Epoch [44/100]: train=0.9322 val=0.8233, (0.1s)\n",
            "Epoch [45/100]: train=0.9372 val=0.8166, (0.1s)\n",
            "Epoch [46/100]: train=0.9185 val=0.8096, (0.1s)\n",
            "Epoch [47/100]: train=0.9091 val=0.8035, (0.1s)\n",
            "Epoch [48/100]: train=0.9081 val=0.7978, (0.1s)\n",
            "Epoch [49/100]: train=0.8915 val=0.7919, (0.1s)\n",
            "Epoch [50/100]: train=0.8934 val=0.7861, (0.1s)\n",
            "Epoch [51/100]: train=0.8908 val=0.7812, (0.1s)\n",
            "Epoch [52/100]: train=0.88 val=0.7759, (0.1s)\n",
            "Epoch [53/100]: train=0.8816 val=0.7704, (0.1s)\n",
            "Epoch [54/100]: train=0.8726 val=0.7649, (0.1s)\n",
            "Epoch [55/100]: train=0.8616 val=0.7603, (0.1s)\n",
            "Epoch [56/100]: train=0.8683 val=0.7554, (0.1s)\n",
            "Epoch [57/100]: train=0.8496 val=0.7505, (0.1s)\n",
            "Epoch [58/100]: train=0.848 val=0.7462, (0.1s)\n",
            "Epoch [59/100]: train=0.85 val=0.7414, (0.1s)\n",
            "Epoch [60/100]: train=0.8401 val=0.7366, (0.1s)\n",
            "Epoch [61/100]: train=0.8312 val=0.7328, (0.1s)\n",
            "Epoch [62/100]: train=0.8265 val=0.7281, (0.1s)\n",
            "Epoch [63/100]: train=0.8356 val=0.7238, (0.1s)\n",
            "Epoch [64/100]: train=0.8219 val=0.7196, (0.1s)\n",
            "Epoch [65/100]: train=0.8162 val=0.7151, (0.1s)\n",
            "Epoch [66/100]: train=0.8132 val=0.7115, (0.1s)\n",
            "Epoch [67/100]: train=0.8008 val=0.7074, (0.1s)\n",
            "Epoch [68/100]: train=0.7971 val=0.7042, (0.1s)\n",
            "Epoch [69/100]: train=0.7959 val=0.7007, (0.1s)\n",
            "Epoch [70/100]: train=0.7925 val=0.6972, (0.1s)\n",
            "Epoch [71/100]: train=0.7877 val=0.694, (0.1s)\n",
            "Epoch [72/100]: train=0.7969 val=0.6899, (0.1s)\n",
            "Epoch [73/100]: train=0.7902 val=0.6869, (0.1s)\n",
            "Epoch [74/100]: train=0.784 val=0.684, (0.1s)\n",
            "Epoch [75/100]: train=0.7774 val=0.6804, (0.1s)\n",
            "Epoch [76/100]: train=0.7638 val=0.6767, (0.1s)\n",
            "Epoch [77/100]: train=0.7889 val=0.6735, (0.1s)\n",
            "Epoch [78/100]: train=0.7722 val=0.6706, (0.1s)\n",
            "Epoch [79/100]: train=0.7637 val=0.6675, (0.1s)\n",
            "Epoch [80/100]: train=0.7651 val=0.6642, (0.1s)\n",
            "Epoch [81/100]: train=0.7621 val=0.6614, (0.1s)\n",
            "Epoch [82/100]: train=0.7542 val=0.6588, (0.1s)\n",
            "Epoch [83/100]: train=0.7513 val=0.6565, (0.1s)\n",
            "Epoch [84/100]: train=0.7499 val=0.6535, (0.1s)\n",
            "Epoch [85/100]: train=0.7446 val=0.6511, (0.1s)\n",
            "Epoch [86/100]: train=0.7395 val=0.649, (0.1s)\n",
            "Epoch [87/100]: train=0.7363 val=0.6466, (0.1s)\n",
            "Epoch [88/100]: train=0.7335 val=0.6442, (0.1s)\n",
            "Epoch [89/100]: train=0.7308 val=0.641, (0.1s)\n",
            "Epoch [90/100]: train=0.7286 val=0.6377, (0.1s)\n",
            "Epoch [91/100]: train=0.7304 val=0.6358, (0.1s)\n",
            "Epoch [92/100]: train=0.7338 val=0.6327, (0.1s)\n",
            "Epoch [93/100]: train=0.7292 val=0.6301, (0.1s)\n",
            "Epoch [94/100]: train=0.7163 val=0.6279, (0.1s)\n",
            "Epoch [95/100]: train=0.7188 val=0.6251, (0.1s)\n",
            "Epoch [96/100]: train=0.7235 val=0.6233, (0.1s)\n",
            "Epoch [97/100]: train=0.7086 val=0.6216, (0.1s)\n",
            "Epoch [98/100]: train=0.7136 val=0.6196, (0.1s)\n",
            "Epoch [99/100]: train=0.7059 val=0.6175, (0.1s)\n",
            "Epoch [100/100]: train=0.7102 val=0.615, (0.1s)\n",
            "Training on task 4...\n",
            "Epoch [1/100]: train=1.7547 val=1.5827, (0.1s)\n",
            "Epoch [2/100]: train=1.6762 val=1.5072, (0.1s)\n",
            "Epoch [3/100]: train=1.5916 val=1.4529, (0.1s)\n",
            "Epoch [4/100]: train=1.5414 val=1.4069, (0.1s)\n",
            "Epoch [5/100]: train=1.5076 val=1.3632, (0.1s)\n",
            "Epoch [6/100]: train=1.4774 val=1.3251, (0.1s)\n",
            "Epoch [7/100]: train=1.4235 val=1.2904, (0.1s)\n",
            "Epoch [8/100]: train=1.3907 val=1.2566, (0.1s)\n",
            "Epoch [9/100]: train=1.3768 val=1.2265, (0.1s)\n",
            "Epoch [10/100]: train=1.3379 val=1.1993, (0.1s)\n",
            "Epoch [11/100]: train=1.3158 val=1.1734, (0.1s)\n",
            "Epoch [12/100]: train=1.284 val=1.1492, (0.1s)\n",
            "Epoch [13/100]: train=1.2645 val=1.1254, (0.1s)\n",
            "Epoch [14/100]: train=1.2324 val=1.1045, (0.2s)\n",
            "Epoch [15/100]: train=1.2209 val=1.084, (0.1s)\n",
            "Epoch [16/100]: train=1.1986 val=1.0651, (0.1s)\n",
            "Epoch [17/100]: train=1.1769 val=1.0471, (0.1s)\n",
            "Epoch [18/100]: train=1.1528 val=1.0305, (0.1s)\n",
            "Epoch [19/100]: train=1.1355 val=1.0153, (0.1s)\n",
            "Epoch [20/100]: train=1.1217 val=1.0004, (0.1s)\n",
            "Epoch [21/100]: train=1.1293 val=0.9862, (0.1s)\n",
            "Epoch [22/100]: train=1.0991 val=0.9726, (0.1s)\n",
            "Epoch [23/100]: train=1.0856 val=0.9596, (0.2s)\n",
            "Epoch [24/100]: train=1.0696 val=0.9466, (0.1s)\n",
            "Epoch [25/100]: train=1.0481 val=0.9351, (0.2s)\n",
            "Epoch [26/100]: train=1.0523 val=0.9251, (0.2s)\n",
            "Epoch [27/100]: train=1.0386 val=0.9149, (0.1s)\n",
            "Epoch [28/100]: train=1.0202 val=0.9042, (0.2s)\n",
            "Epoch [29/100]: train=1.0225 val=0.894, (0.1s)\n",
            "Epoch [30/100]: train=1.0064 val=0.885, (0.2s)\n",
            "Epoch [31/100]: train=0.9901 val=0.8753, (0.2s)\n",
            "Epoch [32/100]: train=0.9886 val=0.8661, (0.1s)\n",
            "Epoch [33/100]: train=0.9766 val=0.8577, (0.1s)\n",
            "Epoch [34/100]: train=0.9636 val=0.8497, (0.1s)\n",
            "Epoch [35/100]: train=0.9617 val=0.8425, (0.1s)\n",
            "Epoch [36/100]: train=0.9403 val=0.8356, (0.1s)\n",
            "Epoch [37/100]: train=0.96 val=0.8278, (0.1s)\n",
            "Epoch [38/100]: train=0.9381 val=0.8208, (0.1s)\n",
            "Epoch [39/100]: train=0.9176 val=0.8135, (0.1s)\n",
            "Epoch [40/100]: train=0.9076 val=0.8069, (0.1s)\n",
            "Epoch [41/100]: train=0.9164 val=0.8004, (0.1s)\n",
            "Epoch [42/100]: train=0.9073 val=0.7944, (0.1s)\n",
            "Epoch [43/100]: train=0.9018 val=0.7891, (0.1s)\n",
            "Epoch [44/100]: train=0.8977 val=0.7831, (0.1s)\n",
            "Epoch [45/100]: train=0.8719 val=0.7775, (0.1s)\n",
            "Epoch [46/100]: train=0.8811 val=0.7717, (0.1s)\n",
            "Epoch [47/100]: train=0.8672 val=0.7667, (0.1s)\n",
            "Epoch [48/100]: train=0.86 val=0.7614, (0.1s)\n",
            "Epoch [49/100]: train=0.8486 val=0.7559, (0.1s)\n",
            "Epoch [50/100]: train=0.8579 val=0.7516, (0.1s)\n",
            "Epoch [51/100]: train=0.8558 val=0.7469, (0.1s)\n",
            "Epoch [52/100]: train=0.8477 val=0.7424, (0.1s)\n",
            "Epoch [53/100]: train=0.8468 val=0.7376, (0.1s)\n",
            "Epoch [54/100]: train=0.8333 val=0.7323, (0.1s)\n",
            "Epoch [55/100]: train=0.8389 val=0.7287, (0.1s)\n",
            "Epoch [56/100]: train=0.8239 val=0.725, (0.1s)\n",
            "Epoch [57/100]: train=0.8175 val=0.7214, (0.1s)\n",
            "Epoch [58/100]: train=0.8176 val=0.7169, (0.1s)\n",
            "Epoch [59/100]: train=0.815 val=0.7129, (0.1s)\n",
            "Epoch [60/100]: train=0.7993 val=0.7084, (0.1s)\n",
            "Epoch [61/100]: train=0.8126 val=0.7038, (0.1s)\n",
            "Epoch [62/100]: train=0.8022 val=0.7009, (0.1s)\n",
            "Epoch [63/100]: train=0.8008 val=0.6977, (0.1s)\n",
            "Epoch [64/100]: train=0.7956 val=0.694, (0.1s)\n",
            "Epoch [65/100]: train=0.783 val=0.6906, (0.1s)\n",
            "Epoch [66/100]: train=0.7955 val=0.6872, (0.1s)\n",
            "Epoch [67/100]: train=0.7697 val=0.6841, (0.1s)\n",
            "Epoch [68/100]: train=0.7803 val=0.6811, (0.1s)\n",
            "Epoch [69/100]: train=0.7665 val=0.6774, (0.1s)\n",
            "Epoch [70/100]: train=0.77 val=0.6747, (0.1s)\n",
            "Epoch [71/100]: train=0.7628 val=0.6718, (0.1s)\n",
            "Epoch [72/100]: train=0.7664 val=0.6698, (0.1s)\n",
            "Epoch [73/100]: train=0.7728 val=0.6664, (0.1s)\n",
            "Epoch [74/100]: train=0.7514 val=0.6631, (0.1s)\n",
            "Epoch [75/100]: train=0.7504 val=0.6604, (0.1s)\n",
            "Epoch [76/100]: train=0.7484 val=0.6569, (0.1s)\n",
            "Epoch [77/100]: train=0.7527 val=0.6542, (0.1s)\n",
            "Epoch [78/100]: train=0.7358 val=0.6518, (0.1s)\n",
            "Epoch [79/100]: train=0.7374 val=0.649, (0.1s)\n",
            "Epoch [80/100]: train=0.7489 val=0.646, (0.1s)\n",
            "Epoch [81/100]: train=0.7461 val=0.6439, (0.1s)\n",
            "Epoch [82/100]: train=0.7317 val=0.6416, (0.1s)\n",
            "Epoch [83/100]: train=0.7288 val=0.639, (0.1s)\n",
            "Epoch [84/100]: train=0.7283 val=0.6364, (0.1s)\n",
            "Epoch [85/100]: train=0.7238 val=0.6344, (0.1s)\n",
            "Epoch [86/100]: train=0.7131 val=0.6315, (0.1s)\n",
            "Epoch [87/100]: train=0.7176 val=0.6286, (0.1s)\n",
            "Epoch [88/100]: train=0.7214 val=0.6265, (0.1s)\n",
            "Epoch [89/100]: train=0.6988 val=0.6244, (0.1s)\n",
            "Epoch [90/100]: train=0.7084 val=0.6222, (0.1s)\n",
            "Epoch [91/100]: train=0.7096 val=0.6204, (0.1s)\n",
            "Epoch [92/100]: train=0.7 val=0.6184, (0.1s)\n",
            "Epoch [93/100]: train=0.6965 val=0.6165, (0.1s)\n",
            "Epoch [94/100]: train=0.6959 val=0.6148, (0.1s)\n",
            "Epoch [95/100]: train=0.7048 val=0.6127, (0.1s)\n",
            "Epoch [96/100]: train=0.6913 val=0.6102, (0.1s)\n",
            "Epoch [97/100]: train=0.6894 val=0.6082, (0.1s)\n",
            "Epoch [98/100]: train=0.7021 val=0.6069, (0.1s)\n",
            "Epoch [99/100]: train=0.6792 val=0.6046, (0.1s)\n",
            "Epoch [100/100]: train=0.6893 val=0.6024, (0.1s)\n",
            "Training on task 5...\n",
            "Epoch [1/100]: train=1.6914 val=1.4969, (0.1s)\n",
            "Epoch [2/100]: train=1.6116 val=1.425, (0.2s)\n",
            "Epoch [3/100]: train=1.5441 val=1.373, (0.2s)\n",
            "Epoch [4/100]: train=1.4951 val=1.326, (0.1s)\n",
            "Epoch [5/100]: train=1.4455 val=1.2851, (0.1s)\n",
            "Epoch [6/100]: train=1.41 val=1.2483, (0.1s)\n",
            "Epoch [7/100]: train=1.3859 val=1.2142, (0.1s)\n",
            "Epoch [8/100]: train=1.331 val=1.1847, (0.2s)\n",
            "Epoch [9/100]: train=1.2981 val=1.1553, (0.2s)\n",
            "Epoch [10/100]: train=1.2694 val=1.1289, (0.2s)\n",
            "Epoch [11/100]: train=1.2492 val=1.1053, (0.2s)\n",
            "Epoch [12/100]: train=1.2274 val=1.0823, (0.2s)\n",
            "Epoch [13/100]: train=1.2047 val=1.0616, (0.1s)\n",
            "Epoch [14/100]: train=1.1782 val=1.0415, (0.1s)\n",
            "Epoch [15/100]: train=1.1596 val=1.0224, (0.1s)\n",
            "Epoch [16/100]: train=1.1296 val=1.0056, (0.1s)\n",
            "Epoch [17/100]: train=1.1154 val=0.9903, (0.1s)\n",
            "Epoch [18/100]: train=1.1026 val=0.9753, (0.1s)\n",
            "Epoch [19/100]: train=1.0912 val=0.9607, (0.1s)\n",
            "Epoch [20/100]: train=1.0787 val=0.9472, (0.1s)\n",
            "Epoch [21/100]: train=1.0684 val=0.9341, (0.1s)\n",
            "Epoch [22/100]: train=1.0499 val=0.9223, (0.1s)\n",
            "Epoch [23/100]: train=1.0162 val=0.9099, (0.1s)\n",
            "Epoch [24/100]: train=1.0231 val=0.8986, (0.1s)\n",
            "Epoch [25/100]: train=1.0077 val=0.8883, (0.1s)\n",
            "Epoch [26/100]: train=0.9999 val=0.8783, (0.1s)\n",
            "Epoch [27/100]: train=0.9799 val=0.8692, (0.1s)\n",
            "Epoch [28/100]: train=0.9868 val=0.8604, (0.1s)\n",
            "Epoch [29/100]: train=0.98 val=0.8517, (0.1s)\n",
            "Epoch [30/100]: train=0.9574 val=0.8424, (0.1s)\n",
            "Epoch [31/100]: train=0.9628 val=0.8342, (0.1s)\n",
            "Epoch [32/100]: train=0.9387 val=0.8264, (0.1s)\n",
            "Epoch [33/100]: train=0.9204 val=0.8187, (0.1s)\n",
            "Epoch [34/100]: train=0.9156 val=0.8118, (0.1s)\n",
            "Epoch [35/100]: train=0.9122 val=0.8059, (0.1s)\n",
            "Epoch [36/100]: train=0.9095 val=0.7988, (0.1s)\n",
            "Epoch [37/100]: train=0.9059 val=0.7915, (0.1s)\n",
            "Epoch [38/100]: train=0.9074 val=0.785, (0.1s)\n",
            "Epoch [39/100]: train=0.8741 val=0.779, (0.1s)\n",
            "Epoch [40/100]: train=0.881 val=0.7725, (0.1s)\n",
            "Epoch [41/100]: train=0.8736 val=0.7669, (0.1s)\n",
            "Epoch [42/100]: train=0.8863 val=0.7622, (0.1s)\n",
            "Epoch [43/100]: train=0.8544 val=0.7567, (0.1s)\n",
            "Epoch [44/100]: train=0.8667 val=0.751, (0.1s)\n",
            "Epoch [45/100]: train=0.8581 val=0.7471, (0.1s)\n",
            "Epoch [46/100]: train=0.8531 val=0.7423, (0.1s)\n",
            "Epoch [47/100]: train=0.8347 val=0.7374, (0.1s)\n",
            "Epoch [48/100]: train=0.837 val=0.7331, (0.1s)\n",
            "Epoch [49/100]: train=0.8231 val=0.7268, (0.1s)\n",
            "Epoch [50/100]: train=0.836 val=0.7234, (0.1s)\n",
            "Epoch [51/100]: train=0.8233 val=0.7192, (0.1s)\n",
            "Epoch [52/100]: train=0.8115 val=0.715, (0.1s)\n",
            "Epoch [53/100]: train=0.8057 val=0.7111, (0.1s)\n",
            "Epoch [54/100]: train=0.8117 val=0.7073, (0.1s)\n",
            "Epoch [55/100]: train=0.809 val=0.7034, (0.1s)\n",
            "Epoch [56/100]: train=0.794 val=0.7002, (0.1s)\n",
            "Epoch [57/100]: train=0.7911 val=0.696, (0.1s)\n",
            "Epoch [58/100]: train=0.7896 val=0.6933, (0.1s)\n",
            "Epoch [59/100]: train=0.7689 val=0.6902, (0.1s)\n",
            "Epoch [60/100]: train=0.7774 val=0.6863, (0.1s)\n",
            "Epoch [61/100]: train=0.7745 val=0.6822, (0.1s)\n",
            "Epoch [62/100]: train=0.7715 val=0.6791, (0.1s)\n",
            "Epoch [63/100]: train=0.7628 val=0.6756, (0.1s)\n",
            "Epoch [64/100]: train=0.7667 val=0.672, (0.1s)\n",
            "Epoch [65/100]: train=0.7718 val=0.6689, (0.1s)\n",
            "Epoch [66/100]: train=0.771 val=0.667, (0.1s)\n",
            "Epoch [67/100]: train=0.7527 val=0.6638, (0.1s)\n",
            "Epoch [68/100]: train=0.7549 val=0.6601, (0.1s)\n",
            "Epoch [69/100]: train=0.7557 val=0.6571, (0.1s)\n",
            "Epoch [70/100]: train=0.7318 val=0.6543, (0.1s)\n",
            "Epoch [71/100]: train=0.7286 val=0.6511, (0.1s)\n",
            "Epoch [72/100]: train=0.7353 val=0.6481, (0.1s)\n",
            "Epoch [73/100]: train=0.7309 val=0.6459, (0.1s)\n",
            "Epoch [74/100]: train=0.7368 val=0.6436, (0.1s)\n",
            "Epoch [75/100]: train=0.735 val=0.6415, (0.1s)\n",
            "Epoch [76/100]: train=0.72 val=0.6388, (0.1s)\n",
            "Epoch [77/100]: train=0.7241 val=0.6361, (0.1s)\n",
            "Epoch [78/100]: train=0.7168 val=0.6339, (0.1s)\n",
            "Epoch [79/100]: train=0.7222 val=0.6315, (0.1s)\n",
            "Epoch [80/100]: train=0.7254 val=0.6287, (0.1s)\n",
            "Epoch [81/100]: train=0.7033 val=0.6261, (0.1s)\n",
            "Epoch [82/100]: train=0.7272 val=0.6244, (0.1s)\n",
            "Epoch [83/100]: train=0.7209 val=0.6224, (0.1s)\n",
            "Epoch [84/100]: train=0.705 val=0.6206, (0.1s)\n",
            "Epoch [85/100]: train=0.6989 val=0.6188, (0.1s)\n",
            "Epoch [86/100]: train=0.7102 val=0.6167, (0.1s)\n",
            "Epoch [87/100]: train=0.7003 val=0.6148, (0.1s)\n",
            "Epoch [88/100]: train=0.6815 val=0.6124, (0.1s)\n",
            "Epoch [89/100]: train=0.6897 val=0.6106, (0.1s)\n",
            "Epoch [90/100]: train=0.6832 val=0.6082, (0.1s)\n",
            "Epoch [91/100]: train=0.6813 val=0.6063, (0.1s)\n",
            "Epoch [92/100]: train=0.6849 val=0.6042, (0.1s)\n",
            "Epoch [93/100]: train=0.6908 val=0.6017, (0.1s)\n",
            "Epoch [94/100]: train=0.6874 val=0.5999, (0.1s)\n",
            "Epoch [95/100]: train=0.6854 val=0.5977, (0.1s)\n",
            "Epoch [96/100]: train=0.6769 val=0.5963, (0.1s)\n",
            "Epoch [97/100]: train=0.6674 val=0.595, (0.2s)\n",
            "Epoch [98/100]: train=0.6726 val=0.5926, (0.1s)\n",
            "Epoch [99/100]: train=0.671 val=0.5911, (0.1s)\n",
            "Epoch [100/100]: train=0.667 val=0.5894, (0.1s)\n",
            "Training on task 6...\n",
            "Epoch [1/100]: train=1.7742 val=1.5751, (0.1s)\n",
            "Epoch [2/100]: train=1.6569 val=1.4925, (0.1s)\n",
            "Epoch [3/100]: train=1.6297 val=1.4286, (0.1s)\n",
            "Epoch [4/100]: train=1.5451 val=1.3735, (0.1s)\n",
            "Epoch [5/100]: train=1.4766 val=1.3277, (0.1s)\n",
            "Epoch [6/100]: train=1.4592 val=1.2844, (0.1s)\n",
            "Epoch [7/100]: train=1.4108 val=1.2447, (0.1s)\n",
            "Epoch [8/100]: train=1.3763 val=1.2098, (0.1s)\n",
            "Epoch [9/100]: train=1.3306 val=1.1778, (0.1s)\n",
            "Epoch [10/100]: train=1.2906 val=1.1485, (0.1s)\n",
            "Epoch [11/100]: train=1.2634 val=1.121, (0.1s)\n",
            "Epoch [12/100]: train=1.2504 val=1.0962, (0.1s)\n",
            "Epoch [13/100]: train=1.2128 val=1.0718, (0.1s)\n",
            "Epoch [14/100]: train=1.19 val=1.0504, (0.1s)\n",
            "Epoch [15/100]: train=1.1689 val=1.03, (0.1s)\n",
            "Epoch [16/100]: train=1.1491 val=1.0111, (0.1s)\n",
            "Epoch [17/100]: train=1.1276 val=0.994, (0.1s)\n",
            "Epoch [18/100]: train=1.1039 val=0.9777, (0.1s)\n",
            "Epoch [19/100]: train=1.0916 val=0.9624, (0.1s)\n",
            "Epoch [20/100]: train=1.0877 val=0.9474, (0.1s)\n",
            "Epoch [21/100]: train=1.0581 val=0.9338, (0.1s)\n",
            "Epoch [22/100]: train=1.0425 val=0.9218, (0.1s)\n",
            "Epoch [23/100]: train=1.0328 val=0.9096, (0.1s)\n",
            "Epoch [24/100]: train=1.0269 val=0.8981, (0.1s)\n",
            "Epoch [25/100]: train=1.0121 val=0.8859, (0.1s)\n",
            "Epoch [26/100]: train=0.9811 val=0.8749, (0.1s)\n",
            "Epoch [27/100]: train=0.9894 val=0.8655, (0.1s)\n",
            "Epoch [28/100]: train=0.9792 val=0.8555, (0.1s)\n",
            "Epoch [29/100]: train=0.9663 val=0.8462, (0.1s)\n",
            "Epoch [30/100]: train=0.9536 val=0.8375, (0.1s)\n",
            "Epoch [31/100]: train=0.9435 val=0.8299, (0.1s)\n",
            "Epoch [32/100]: train=0.9361 val=0.8213, (0.1s)\n",
            "Epoch [33/100]: train=0.934 val=0.8125, (0.1s)\n",
            "Epoch [34/100]: train=0.9222 val=0.8052, (0.1s)\n",
            "Epoch [35/100]: train=0.9075 val=0.7986, (0.1s)\n",
            "Epoch [36/100]: train=0.8931 val=0.7923, (0.1s)\n",
            "Epoch [37/100]: train=0.8898 val=0.7858, (0.1s)\n",
            "Epoch [38/100]: train=0.8861 val=0.7788, (0.1s)\n",
            "Epoch [39/100]: train=0.8781 val=0.7732, (0.1s)\n",
            "Epoch [40/100]: train=0.8722 val=0.7668, (0.1s)\n",
            "Epoch [41/100]: train=0.8711 val=0.7607, (0.1s)\n",
            "Epoch [42/100]: train=0.8641 val=0.7553, (0.1s)\n",
            "Epoch [43/100]: train=0.8569 val=0.7508, (0.1s)\n",
            "Epoch [44/100]: train=0.852 val=0.7452, (0.1s)\n",
            "Epoch [45/100]: train=0.8518 val=0.7393, (0.1s)\n",
            "Epoch [46/100]: train=0.8512 val=0.7337, (0.1s)\n",
            "Epoch [47/100]: train=0.8311 val=0.7293, (0.1s)\n",
            "Epoch [48/100]: train=0.8345 val=0.7247, (0.1s)\n",
            "Epoch [49/100]: train=0.8253 val=0.7203, (0.1s)\n",
            "Epoch [50/100]: train=0.8078 val=0.7165, (0.1s)\n",
            "Epoch [51/100]: train=0.8099 val=0.7119, (0.1s)\n",
            "Epoch [52/100]: train=0.8113 val=0.7079, (0.1s)\n",
            "Epoch [53/100]: train=0.8113 val=0.7035, (0.1s)\n",
            "Epoch [54/100]: train=0.7943 val=0.6999, (0.1s)\n",
            "Epoch [55/100]: train=0.7836 val=0.6963, (0.1s)\n",
            "Epoch [56/100]: train=0.7826 val=0.6921, (0.1s)\n",
            "Epoch [57/100]: train=0.7919 val=0.6884, (0.1s)\n",
            "Epoch [58/100]: train=0.783 val=0.685, (0.1s)\n",
            "Epoch [59/100]: train=0.7747 val=0.6801, (0.1s)\n",
            "Epoch [60/100]: train=0.7813 val=0.6764, (0.1s)\n",
            "Epoch [61/100]: train=0.7657 val=0.6735, (0.1s)\n",
            "Epoch [62/100]: train=0.7706 val=0.6712, (0.1s)\n",
            "Epoch [63/100]: train=0.7517 val=0.6686, (0.1s)\n",
            "Epoch [64/100]: train=0.7446 val=0.665, (0.1s)\n",
            "Epoch [65/100]: train=0.774 val=0.6612, (0.1s)\n",
            "Epoch [66/100]: train=0.7529 val=0.6578, (0.1s)\n",
            "Epoch [67/100]: train=0.7376 val=0.6549, (0.1s)\n",
            "Epoch [68/100]: train=0.7414 val=0.652, (0.1s)\n",
            "Epoch [69/100]: train=0.7374 val=0.6489, (0.1s)\n",
            "Epoch [70/100]: train=0.7272 val=0.646, (0.1s)\n",
            "Epoch [71/100]: train=0.7308 val=0.6429, (0.1s)\n",
            "Epoch [72/100]: train=0.7418 val=0.6399, (0.1s)\n",
            "Epoch [73/100]: train=0.7192 val=0.6374, (0.1s)\n",
            "Epoch [74/100]: train=0.7159 val=0.6355, (0.1s)\n",
            "Epoch [75/100]: train=0.714 val=0.6325, (0.1s)\n",
            "Epoch [76/100]: train=0.7063 val=0.6296, (0.2s)\n",
            "Epoch [77/100]: train=0.7112 val=0.6275, (0.2s)\n",
            "Epoch [78/100]: train=0.7196 val=0.6252, (0.1s)\n",
            "Epoch [79/100]: train=0.7121 val=0.6225, (0.1s)\n",
            "Epoch [80/100]: train=0.7034 val=0.6204, (0.1s)\n",
            "Epoch [81/100]: train=0.7043 val=0.6178, (0.1s)\n",
            "Epoch [82/100]: train=0.7075 val=0.6158, (0.1s)\n",
            "Epoch [83/100]: train=0.7059 val=0.6127, (0.1s)\n",
            "Epoch [84/100]: train=0.7023 val=0.6097, (0.1s)\n",
            "Epoch [85/100]: train=0.6899 val=0.6079, (0.2s)\n",
            "Epoch [86/100]: train=0.6886 val=0.6055, (0.2s)\n",
            "Epoch [87/100]: train=0.689 val=0.6043, (0.2s)\n",
            "Epoch [88/100]: train=0.6803 val=0.6019, (0.2s)\n",
            "Epoch [89/100]: train=0.6813 val=0.6003, (0.1s)\n",
            "Epoch [90/100]: train=0.6861 val=0.5982, (0.1s)\n",
            "Epoch [91/100]: train=0.6681 val=0.5968, (0.1s)\n",
            "Epoch [92/100]: train=0.6704 val=0.5944, (0.2s)\n",
            "Epoch [93/100]: train=0.6665 val=0.5925, (0.1s)\n",
            "Epoch [94/100]: train=0.6878 val=0.5908, (0.2s)\n",
            "Epoch [95/100]: train=0.6622 val=0.5884, (0.1s)\n",
            "Epoch [96/100]: train=0.6643 val=0.5864, (0.1s)\n",
            "Epoch [97/100]: train=0.6682 val=0.5844, (0.1s)\n",
            "Epoch [98/100]: train=0.6658 val=0.5832, (0.1s)\n",
            "Epoch [99/100]: train=0.6648 val=0.5803, (0.1s)\n",
            "Epoch [100/100]: train=0.6551 val=0.5793, (0.1s)\n",
            "Training on task 7...\n",
            "Epoch [1/100]: train=1.7392 val=1.5687, (0.1s)\n",
            "Epoch [2/100]: train=1.6319 val=1.4857, (0.1s)\n",
            "Epoch [3/100]: train=1.5685 val=1.4215, (0.1s)\n",
            "Epoch [4/100]: train=1.5038 val=1.3669, (0.1s)\n",
            "Epoch [5/100]: train=1.4815 val=1.3164, (0.1s)\n",
            "Epoch [6/100]: train=1.4128 val=1.2731, (0.1s)\n",
            "Epoch [7/100]: train=1.3928 val=1.2345, (0.1s)\n",
            "Epoch [8/100]: train=1.3348 val=1.199, (0.1s)\n",
            "Epoch [9/100]: train=1.2967 val=1.1674, (0.1s)\n",
            "Epoch [10/100]: train=1.2756 val=1.1374, (0.1s)\n",
            "Epoch [11/100]: train=1.2343 val=1.1098, (0.1s)\n",
            "Epoch [12/100]: train=1.232 val=1.0848, (0.1s)\n",
            "Epoch [13/100]: train=1.1935 val=1.0627, (0.1s)\n",
            "Epoch [14/100]: train=1.1814 val=1.0403, (0.1s)\n",
            "Epoch [15/100]: train=1.1426 val=1.0207, (0.1s)\n",
            "Epoch [16/100]: train=1.1326 val=1.0021, (0.1s)\n",
            "Epoch [17/100]: train=1.1116 val=0.9837, (0.1s)\n",
            "Epoch [18/100]: train=1.0775 val=0.9684, (0.1s)\n",
            "Epoch [19/100]: train=1.0786 val=0.9544, (0.1s)\n",
            "Epoch [20/100]: train=1.0606 val=0.9403, (0.1s)\n",
            "Epoch [21/100]: train=1.0331 val=0.9272, (0.1s)\n",
            "Epoch [22/100]: train=1.0287 val=0.914, (0.1s)\n",
            "Epoch [23/100]: train=1.0214 val=0.9017, (0.1s)\n",
            "Epoch [24/100]: train=1.0033 val=0.8899, (0.1s)\n",
            "Epoch [25/100]: train=0.9883 val=0.8788, (0.1s)\n",
            "Epoch [26/100]: train=0.9856 val=0.8683, (0.1s)\n",
            "Epoch [27/100]: train=0.9675 val=0.8582, (0.1s)\n",
            "Epoch [28/100]: train=0.9573 val=0.8484, (0.1s)\n",
            "Epoch [29/100]: train=0.9582 val=0.8396, (0.1s)\n",
            "Epoch [30/100]: train=0.9363 val=0.8316, (0.1s)\n",
            "Epoch [31/100]: train=0.9351 val=0.8239, (0.1s)\n",
            "Epoch [32/100]: train=0.9133 val=0.8152, (0.1s)\n",
            "Epoch [33/100]: train=0.9126 val=0.8077, (0.1s)\n",
            "Epoch [34/100]: train=0.9091 val=0.8005, (0.1s)\n",
            "Epoch [35/100]: train=0.896 val=0.7933, (0.1s)\n",
            "Epoch [36/100]: train=0.8945 val=0.7864, (0.1s)\n",
            "Epoch [37/100]: train=0.8823 val=0.7788, (0.1s)\n",
            "Epoch [38/100]: train=0.8685 val=0.773, (0.1s)\n",
            "Epoch [39/100]: train=0.8735 val=0.7668, (0.1s)\n",
            "Epoch [40/100]: train=0.8663 val=0.7608, (0.1s)\n",
            "Epoch [41/100]: train=0.859 val=0.7549, (0.1s)\n",
            "Epoch [42/100]: train=0.8617 val=0.7499, (0.1s)\n",
            "Epoch [43/100]: train=0.8496 val=0.7445, (0.1s)\n",
            "Epoch [44/100]: train=0.8406 val=0.7394, (0.1s)\n",
            "Epoch [45/100]: train=0.8181 val=0.7343, (0.1s)\n",
            "Epoch [46/100]: train=0.8309 val=0.7295, (0.1s)\n",
            "Epoch [47/100]: train=0.8192 val=0.7251, (0.1s)\n",
            "Epoch [48/100]: train=0.8121 val=0.7203, (0.1s)\n",
            "Epoch [49/100]: train=0.8042 val=0.7159, (0.1s)\n",
            "Epoch [50/100]: train=0.8137 val=0.7112, (0.1s)\n",
            "Epoch [51/100]: train=0.7973 val=0.7075, (0.1s)\n",
            "Epoch [52/100]: train=0.7852 val=0.7031, (0.1s)\n",
            "Epoch [53/100]: train=0.7834 val=0.6986, (0.2s)\n",
            "Epoch [54/100]: train=0.788 val=0.6948, (0.1s)\n",
            "Epoch [55/100]: train=0.7728 val=0.6904, (0.1s)\n",
            "Epoch [56/100]: train=0.7741 val=0.687, (0.1s)\n",
            "Epoch [57/100]: train=0.7699 val=0.6834, (0.1s)\n",
            "Epoch [58/100]: train=0.7619 val=0.6799, (0.1s)\n",
            "Epoch [59/100]: train=0.7657 val=0.676, (0.1s)\n",
            "Epoch [60/100]: train=0.7556 val=0.6726, (0.1s)\n",
            "Epoch [61/100]: train=0.7642 val=0.669, (0.1s)\n",
            "Epoch [62/100]: train=0.7485 val=0.6655, (0.1s)\n",
            "Epoch [63/100]: train=0.7513 val=0.6621, (0.2s)\n",
            "Epoch [64/100]: train=0.7477 val=0.6587, (0.2s)\n",
            "Epoch [65/100]: train=0.7379 val=0.6559, (0.2s)\n",
            "Epoch [66/100]: train=0.7374 val=0.6531, (0.2s)\n",
            "Epoch [67/100]: train=0.7437 val=0.6502, (0.2s)\n",
            "Epoch [68/100]: train=0.7445 val=0.6471, (0.2s)\n",
            "Epoch [69/100]: train=0.7255 val=0.6448, (0.1s)\n",
            "Epoch [70/100]: train=0.7245 val=0.6415, (0.1s)\n",
            "Epoch [71/100]: train=0.7288 val=0.6387, (0.1s)\n",
            "Epoch [72/100]: train=0.7189 val=0.6361, (0.1s)\n",
            "Epoch [73/100]: train=0.7269 val=0.6333, (0.1s)\n",
            "Epoch [74/100]: train=0.7118 val=0.6307, (0.1s)\n",
            "Epoch [75/100]: train=0.7122 val=0.6283, (0.1s)\n",
            "Epoch [76/100]: train=0.6962 val=0.626, (0.1s)\n",
            "Epoch [77/100]: train=0.7 val=0.6234, (0.1s)\n",
            "Epoch [78/100]: train=0.7048 val=0.6203, (0.1s)\n",
            "Epoch [79/100]: train=0.708 val=0.6185, (0.1s)\n",
            "Epoch [80/100]: train=0.7036 val=0.6163, (0.1s)\n",
            "Epoch [81/100]: train=0.6957 val=0.6138, (0.1s)\n",
            "Epoch [82/100]: train=0.6924 val=0.6113, (0.1s)\n",
            "Epoch [83/100]: train=0.6916 val=0.6093, (0.1s)\n",
            "Epoch [84/100]: train=0.6822 val=0.6067, (0.1s)\n",
            "Epoch [85/100]: train=0.6704 val=0.6047, (0.1s)\n",
            "Epoch [86/100]: train=0.6823 val=0.6034, (0.1s)\n",
            "Epoch [87/100]: train=0.696 val=0.6005, (0.1s)\n",
            "Epoch [88/100]: train=0.6842 val=0.5981, (0.1s)\n",
            "Epoch [89/100]: train=0.6862 val=0.5958, (0.1s)\n",
            "Epoch [90/100]: train=0.6733 val=0.5928, (0.1s)\n",
            "Epoch [91/100]: train=0.6722 val=0.591, (0.1s)\n",
            "Epoch [92/100]: train=0.6696 val=0.59, (0.1s)\n",
            "Epoch [93/100]: train=0.6579 val=0.5885, (0.1s)\n",
            "Epoch [94/100]: train=0.6643 val=0.5859, (0.1s)\n",
            "Epoch [95/100]: train=0.6683 val=0.5843, (0.1s)\n",
            "Epoch [96/100]: train=0.6463 val=0.5824, (0.1s)\n",
            "Epoch [97/100]: train=0.6599 val=0.5804, (0.1s)\n",
            "Epoch [98/100]: train=0.6531 val=0.5784, (0.1s)\n",
            "Epoch [99/100]: train=0.659 val=0.5761, (0.1s)\n",
            "Epoch [100/100]: train=0.6539 val=0.5743, (0.1s)\n",
            "Training on task 8...\n",
            "Epoch [1/100]: train=1.6496 val=1.503, (0.1s)\n",
            "Epoch [2/100]: train=1.5704 val=1.43, (0.1s)\n",
            "Epoch [3/100]: train=1.5038 val=1.3691, (0.1s)\n",
            "Epoch [4/100]: train=1.4384 val=1.3185, (0.1s)\n",
            "Epoch [5/100]: train=1.4329 val=1.2751, (0.1s)\n",
            "Epoch [6/100]: train=1.3602 val=1.2357, (0.1s)\n",
            "Epoch [7/100]: train=1.338 val=1.2014, (0.1s)\n",
            "Epoch [8/100]: train=1.2955 val=1.1687, (0.1s)\n",
            "Epoch [9/100]: train=1.269 val=1.1385, (0.1s)\n",
            "Epoch [10/100]: train=1.24 val=1.1126, (0.1s)\n",
            "Epoch [11/100]: train=1.2086 val=1.0874, (0.1s)\n",
            "Epoch [12/100]: train=1.2026 val=1.0643, (0.1s)\n",
            "Epoch [13/100]: train=1.1556 val=1.0425, (0.1s)\n",
            "Epoch [14/100]: train=1.1316 val=1.0229, (0.1s)\n",
            "Epoch [15/100]: train=1.1103 val=1.0035, (0.1s)\n",
            "Epoch [16/100]: train=1.0984 val=0.9861, (0.1s)\n",
            "Epoch [17/100]: train=1.0723 val=0.9712, (0.1s)\n",
            "Epoch [18/100]: train=1.0715 val=0.9557, (0.1s)\n",
            "Epoch [19/100]: train=1.0541 val=0.9413, (0.1s)\n",
            "Epoch [20/100]: train=1.0338 val=0.9285, (0.1s)\n",
            "Epoch [21/100]: train=1.0184 val=0.9154, (0.1s)\n",
            "Epoch [22/100]: train=1.0097 val=0.9032, (0.1s)\n",
            "Epoch [23/100]: train=0.9945 val=0.8924, (0.2s)\n",
            "Epoch [24/100]: train=0.9773 val=0.8817, (0.2s)\n",
            "Epoch [25/100]: train=0.9669 val=0.8716, (0.1s)\n",
            "Epoch [26/100]: train=0.9542 val=0.8614, (0.1s)\n",
            "Epoch [27/100]: train=0.949 val=0.852, (0.1s)\n",
            "Epoch [28/100]: train=0.9578 val=0.8424, (0.1s)\n",
            "Epoch [29/100]: train=0.9395 val=0.8341, (0.1s)\n",
            "Epoch [30/100]: train=0.9294 val=0.8259, (0.1s)\n",
            "Epoch [31/100]: train=0.919 val=0.8181, (0.1s)\n",
            "Epoch [32/100]: train=0.9026 val=0.8109, (0.2s)\n",
            "Epoch [33/100]: train=0.8911 val=0.8034, (0.2s)\n",
            "Epoch [34/100]: train=0.879 val=0.7967, (0.2s)\n",
            "Epoch [35/100]: train=0.8857 val=0.7902, (0.2s)\n",
            "Epoch [36/100]: train=0.8653 val=0.7834, (0.2s)\n",
            "Epoch [37/100]: train=0.8671 val=0.7766, (0.2s)\n",
            "Epoch [38/100]: train=0.8541 val=0.7706, (0.2s)\n",
            "Epoch [39/100]: train=0.8416 val=0.7649, (0.1s)\n",
            "Epoch [40/100]: train=0.8563 val=0.7584, (0.1s)\n",
            "Epoch [41/100]: train=0.8341 val=0.7532, (0.1s)\n",
            "Epoch [42/100]: train=0.8298 val=0.7481, (0.1s)\n",
            "Epoch [43/100]: train=0.8329 val=0.7425, (0.1s)\n",
            "Epoch [44/100]: train=0.828 val=0.7375, (0.1s)\n",
            "Epoch [45/100]: train=0.813 val=0.7322, (0.1s)\n",
            "Epoch [46/100]: train=0.8083 val=0.7273, (0.1s)\n",
            "Epoch [47/100]: train=0.8051 val=0.7231, (0.1s)\n",
            "Epoch [48/100]: train=0.8152 val=0.7184, (0.1s)\n",
            "Epoch [49/100]: train=0.7932 val=0.7146, (0.1s)\n",
            "Epoch [50/100]: train=0.7943 val=0.7101, (0.1s)\n",
            "Epoch [51/100]: train=0.786 val=0.7058, (0.1s)\n",
            "Epoch [52/100]: train=0.783 val=0.7021, (0.1s)\n",
            "Epoch [53/100]: train=0.7782 val=0.698, (0.1s)\n",
            "Epoch [54/100]: train=0.7712 val=0.694, (0.1s)\n",
            "Epoch [55/100]: train=0.7729 val=0.6896, (0.1s)\n",
            "Epoch [56/100]: train=0.764 val=0.6857, (0.1s)\n",
            "Epoch [57/100]: train=0.7681 val=0.6826, (0.1s)\n",
            "Epoch [58/100]: train=0.7461 val=0.6783, (0.1s)\n",
            "Epoch [59/100]: train=0.7552 val=0.6747, (0.1s)\n",
            "Epoch [60/100]: train=0.7516 val=0.671, (0.1s)\n",
            "Epoch [61/100]: train=0.7387 val=0.6683, (0.1s)\n",
            "Epoch [62/100]: train=0.7503 val=0.664, (0.1s)\n",
            "Epoch [63/100]: train=0.736 val=0.6614, (0.1s)\n",
            "Epoch [64/100]: train=0.7374 val=0.6583, (0.1s)\n",
            "Epoch [65/100]: train=0.7269 val=0.6557, (0.1s)\n",
            "Epoch [66/100]: train=0.7195 val=0.6526, (0.1s)\n",
            "Epoch [67/100]: train=0.7199 val=0.6498, (0.1s)\n",
            "Epoch [68/100]: train=0.719 val=0.6474, (0.1s)\n",
            "Epoch [69/100]: train=0.706 val=0.644, (0.1s)\n",
            "Epoch [70/100]: train=0.7131 val=0.6417, (0.1s)\n",
            "Epoch [71/100]: train=0.7123 val=0.6388, (0.1s)\n",
            "Epoch [72/100]: train=0.7029 val=0.6355, (0.1s)\n",
            "Epoch [73/100]: train=0.7057 val=0.6326, (0.1s)\n",
            "Epoch [74/100]: train=0.6984 val=0.6296, (0.1s)\n",
            "Epoch [75/100]: train=0.7028 val=0.6273, (0.1s)\n",
            "Epoch [76/100]: train=0.6968 val=0.6245, (0.1s)\n",
            "Epoch [77/100]: train=0.7014 val=0.6229, (0.1s)\n",
            "Epoch [78/100]: train=0.6986 val=0.6203, (0.1s)\n",
            "Epoch [79/100]: train=0.6906 val=0.6176, (0.1s)\n",
            "Epoch [80/100]: train=0.6924 val=0.6155, (0.1s)\n",
            "Epoch [81/100]: train=0.686 val=0.6132, (0.1s)\n",
            "Epoch [82/100]: train=0.6797 val=0.6102, (0.1s)\n",
            "Epoch [83/100]: train=0.6671 val=0.6079, (0.1s)\n",
            "Epoch [84/100]: train=0.6652 val=0.6071, (0.1s)\n",
            "Epoch [85/100]: train=0.6775 val=0.6047, (0.1s)\n",
            "Epoch [86/100]: train=0.6634 val=0.6023, (0.1s)\n",
            "Epoch [87/100]: train=0.6699 val=0.6004, (0.1s)\n",
            "Epoch [88/100]: train=0.6707 val=0.5984, (0.1s)\n",
            "Epoch [89/100]: train=0.6722 val=0.596, (0.1s)\n",
            "Epoch [90/100]: train=0.6526 val=0.594, (0.1s)\n",
            "Epoch [91/100]: train=0.648 val=0.5918, (0.1s)\n",
            "Epoch [92/100]: train=0.6541 val=0.5901, (0.1s)\n",
            "Epoch [93/100]: train=0.6469 val=0.5882, (0.1s)\n",
            "Epoch [94/100]: train=0.6396 val=0.5865, (0.1s)\n",
            "Epoch [95/100]: train=0.6603 val=0.5837, (0.1s)\n",
            "Epoch [96/100]: train=0.6432 val=0.583, (0.1s)\n",
            "Epoch [97/100]: train=0.6467 val=0.5808, (0.1s)\n",
            "Epoch [98/100]: train=0.6435 val=0.5788, (0.1s)\n",
            "Epoch [99/100]: train=0.6459 val=0.5771, (0.1s)\n",
            "Epoch [100/100]: train=0.6312 val=0.5751, (0.1s)\n",
            "Training on task 9...\n",
            "Epoch [1/100]: train=1.6665 val=1.5087, (0.2s)\n",
            "Epoch [2/100]: train=1.5803 val=1.4344, (0.2s)\n",
            "Epoch [3/100]: train=1.5036 val=1.3773, (0.2s)\n",
            "Epoch [4/100]: train=1.4878 val=1.3284, (0.2s)\n",
            "Epoch [5/100]: train=1.4107 val=1.2846, (0.1s)\n",
            "Epoch [6/100]: train=1.362 val=1.2455, (0.1s)\n",
            "Epoch [7/100]: train=1.3447 val=1.2104, (0.1s)\n",
            "Epoch [8/100]: train=1.3088 val=1.178, (0.1s)\n",
            "Epoch [9/100]: train=1.2735 val=1.1495, (0.1s)\n",
            "Epoch [10/100]: train=1.2444 val=1.1231, (0.1s)\n",
            "Epoch [11/100]: train=1.2368 val=1.098, (0.1s)\n",
            "Epoch [12/100]: train=1.1933 val=1.0749, (0.1s)\n",
            "Epoch [13/100]: train=1.1718 val=1.0532, (0.1s)\n",
            "Epoch [14/100]: train=1.1508 val=1.0338, (0.1s)\n",
            "Epoch [15/100]: train=1.1385 val=1.0152, (0.1s)\n",
            "Epoch [16/100]: train=1.1161 val=0.9967, (0.1s)\n",
            "Epoch [17/100]: train=1.0964 val=0.9815, (0.1s)\n",
            "Epoch [18/100]: train=1.0791 val=0.9661, (0.1s)\n",
            "Epoch [19/100]: train=1.0636 val=0.9519, (0.1s)\n",
            "Epoch [20/100]: train=1.0528 val=0.9374, (0.1s)\n",
            "Epoch [21/100]: train=1.0403 val=0.924, (0.1s)\n",
            "Epoch [22/100]: train=1.0234 val=0.912, (0.1s)\n",
            "Epoch [23/100]: train=0.9906 val=0.9008, (0.1s)\n",
            "Epoch [24/100]: train=1.0022 val=0.8896, (0.1s)\n",
            "Epoch [25/100]: train=0.9896 val=0.8783, (0.1s)\n",
            "Epoch [26/100]: train=0.961 val=0.8683, (0.1s)\n",
            "Epoch [27/100]: train=0.9485 val=0.8594, (0.1s)\n",
            "Epoch [28/100]: train=0.9541 val=0.8502, (0.1s)\n",
            "Epoch [29/100]: train=0.9463 val=0.8412, (0.1s)\n",
            "Epoch [30/100]: train=0.9302 val=0.8333, (0.1s)\n",
            "Epoch [31/100]: train=0.9257 val=0.8257, (0.1s)\n",
            "Epoch [32/100]: train=0.9176 val=0.8179, (0.1s)\n",
            "Epoch [33/100]: train=0.901 val=0.8104, (0.1s)\n",
            "Epoch [34/100]: train=0.9009 val=0.8037, (0.1s)\n",
            "Epoch [35/100]: train=0.8951 val=0.7967, (0.1s)\n",
            "Epoch [36/100]: train=0.8907 val=0.7902, (0.1s)\n",
            "Epoch [37/100]: train=0.8852 val=0.7825, (0.1s)\n",
            "Epoch [38/100]: train=0.8653 val=0.7764, (0.1s)\n",
            "Epoch [39/100]: train=0.8515 val=0.7706, (0.1s)\n",
            "Epoch [40/100]: train=0.8505 val=0.7648, (0.1s)\n",
            "Epoch [41/100]: train=0.8555 val=0.7596, (0.1s)\n",
            "Epoch [42/100]: train=0.8492 val=0.7547, (0.1s)\n",
            "Epoch [43/100]: train=0.8388 val=0.7489, (0.1s)\n",
            "Epoch [44/100]: train=0.8402 val=0.7437, (0.1s)\n",
            "Epoch [45/100]: train=0.827 val=0.7385, (0.1s)\n",
            "Epoch [46/100]: train=0.8272 val=0.7336, (0.1s)\n",
            "Epoch [47/100]: train=0.8249 val=0.7285, (0.1s)\n",
            "Epoch [48/100]: train=0.8162 val=0.7227, (0.1s)\n",
            "Epoch [49/100]: train=0.8148 val=0.7189, (0.1s)\n",
            "Epoch [50/100]: train=0.7975 val=0.7138, (0.1s)\n",
            "Epoch [51/100]: train=0.8023 val=0.7091, (0.1s)\n",
            "Epoch [52/100]: train=0.7828 val=0.7045, (0.1s)\n",
            "Epoch [53/100]: train=0.7997 val=0.7003, (0.1s)\n",
            "Epoch [54/100]: train=0.7833 val=0.6961, (0.1s)\n",
            "Epoch [55/100]: train=0.7726 val=0.6927, (0.1s)\n",
            "Epoch [56/100]: train=0.7759 val=0.6893, (0.1s)\n",
            "Epoch [57/100]: train=0.7597 val=0.6854, (0.1s)\n",
            "Epoch [58/100]: train=0.7572 val=0.6821, (0.1s)\n",
            "Epoch [59/100]: train=0.7611 val=0.6787, (0.1s)\n",
            "Epoch [60/100]: train=0.7585 val=0.6744, (0.1s)\n",
            "Epoch [61/100]: train=0.7511 val=0.6712, (0.1s)\n",
            "Epoch [62/100]: train=0.7527 val=0.668, (0.1s)\n",
            "Epoch [63/100]: train=0.7428 val=0.6648, (0.1s)\n",
            "Epoch [64/100]: train=0.7471 val=0.6613, (0.1s)\n",
            "Epoch [65/100]: train=0.7377 val=0.6582, (0.1s)\n",
            "Epoch [66/100]: train=0.7311 val=0.6551, (0.1s)\n",
            "Epoch [67/100]: train=0.7323 val=0.6522, (0.1s)\n",
            "Epoch [68/100]: train=0.7263 val=0.6495, (0.1s)\n",
            "Epoch [69/100]: train=0.7161 val=0.6457, (0.1s)\n",
            "Epoch [70/100]: train=0.7149 val=0.6435, (0.1s)\n",
            "Epoch [71/100]: train=0.7286 val=0.6407, (0.1s)\n",
            "Epoch [72/100]: train=0.725 val=0.6378, (0.1s)\n",
            "Epoch [73/100]: train=0.71 val=0.6357, (0.1s)\n",
            "Epoch [74/100]: train=0.7238 val=0.632, (0.1s)\n",
            "Epoch [75/100]: train=0.7096 val=0.6297, (0.1s)\n",
            "Epoch [76/100]: train=0.7055 val=0.6267, (0.1s)\n",
            "Epoch [77/100]: train=0.7005 val=0.6242, (0.1s)\n",
            "Epoch [78/100]: train=0.6896 val=0.6211, (0.1s)\n",
            "Epoch [79/100]: train=0.699 val=0.6184, (0.1s)\n",
            "Epoch [80/100]: train=0.6818 val=0.6164, (0.1s)\n",
            "Epoch [81/100]: train=0.6858 val=0.6131, (0.1s)\n",
            "Epoch [82/100]: train=0.6825 val=0.6111, (0.1s)\n",
            "Epoch [83/100]: train=0.6957 val=0.6098, (0.1s)\n",
            "Epoch [84/100]: train=0.6834 val=0.6074, (0.1s)\n",
            "Epoch [85/100]: train=0.6796 val=0.6047, (0.1s)\n",
            "Epoch [86/100]: train=0.6787 val=0.6023, (0.1s)\n",
            "Epoch [87/100]: train=0.6812 val=0.5993, (0.1s)\n",
            "Epoch [88/100]: train=0.6698 val=0.5967, (0.2s)\n",
            "Epoch [89/100]: train=0.664 val=0.5946, (0.1s)\n",
            "Epoch [90/100]: train=0.6577 val=0.5931, (0.2s)\n",
            "Epoch [91/100]: train=0.6643 val=0.5906, (0.1s)\n",
            "Epoch [92/100]: train=0.659 val=0.5891, (0.1s)\n",
            "Epoch [93/100]: train=0.6667 val=0.5876, (0.1s)\n",
            "Epoch [94/100]: train=0.6686 val=0.5859, (0.1s)\n",
            "Epoch [95/100]: train=0.6617 val=0.5839, (0.1s)\n",
            "Epoch [96/100]: train=0.6577 val=0.5815, (0.1s)\n",
            "Epoch [97/100]: train=0.6524 val=0.5797, (0.2s)\n",
            "Epoch [98/100]: train=0.6575 val=0.5783, (0.2s)\n",
            "Epoch [99/100]: train=0.6527 val=0.5765, (0.1s)\n",
            "Epoch [100/100]: train=0.65 val=0.5747, (0.2s)\n",
            "Training on task 10...\n",
            "Epoch [1/100]: train=1.6101 val=1.4465, (0.1s)\n",
            "Epoch [2/100]: train=1.5292 val=1.3744, (0.1s)\n",
            "Epoch [3/100]: train=1.4895 val=1.3177, (0.1s)\n",
            "Epoch [4/100]: train=1.4152 val=1.2697, (0.1s)\n",
            "Epoch [5/100]: train=1.3903 val=1.2297, (0.1s)\n",
            "Epoch [6/100]: train=1.3355 val=1.1938, (0.1s)\n",
            "Epoch [7/100]: train=1.3049 val=1.1608, (0.1s)\n",
            "Epoch [8/100]: train=1.2707 val=1.1317, (0.1s)\n",
            "Epoch [9/100]: train=1.2353 val=1.1043, (0.1s)\n",
            "Epoch [10/100]: train=1.2158 val=1.0788, (0.1s)\n",
            "Epoch [11/100]: train=1.1975 val=1.0552, (0.1s)\n",
            "Epoch [12/100]: train=1.164 val=1.0342, (0.1s)\n",
            "Epoch [13/100]: train=1.1345 val=1.0145, (0.1s)\n",
            "Epoch [14/100]: train=1.1218 val=0.9963, (0.1s)\n",
            "Epoch [15/100]: train=1.1095 val=0.9788, (0.1s)\n",
            "Epoch [16/100]: train=1.0862 val=0.9626, (0.1s)\n",
            "Epoch [17/100]: train=1.0742 val=0.9483, (0.1s)\n",
            "Epoch [18/100]: train=1.0396 val=0.9334, (0.1s)\n",
            "Epoch [19/100]: train=1.0308 val=0.9204, (0.1s)\n",
            "Epoch [20/100]: train=1.0446 val=0.9078, (0.1s)\n",
            "Epoch [21/100]: train=1.0091 val=0.8952, (0.1s)\n",
            "Epoch [22/100]: train=0.9972 val=0.8835, (0.1s)\n",
            "Epoch [23/100]: train=0.9981 val=0.8728, (0.1s)\n",
            "Epoch [24/100]: train=0.9669 val=0.8623, (0.1s)\n",
            "Epoch [25/100]: train=0.9652 val=0.8519, (0.1s)\n",
            "Epoch [26/100]: train=0.9484 val=0.8429, (0.1s)\n",
            "Epoch [27/100]: train=0.9344 val=0.8339, (0.1s)\n",
            "Epoch [28/100]: train=0.9358 val=0.8252, (0.1s)\n",
            "Epoch [29/100]: train=0.9274 val=0.817, (0.1s)\n",
            "Epoch [30/100]: train=0.9119 val=0.8087, (0.1s)\n",
            "Epoch [31/100]: train=0.891 val=0.8015, (0.1s)\n",
            "Epoch [32/100]: train=0.8952 val=0.7947, (0.1s)\n",
            "Epoch [33/100]: train=0.877 val=0.7877, (0.1s)\n",
            "Epoch [34/100]: train=0.878 val=0.7813, (0.1s)\n",
            "Epoch [35/100]: train=0.8842 val=0.7747, (0.1s)\n",
            "Epoch [36/100]: train=0.8695 val=0.7677, (0.1s)\n",
            "Epoch [37/100]: train=0.8473 val=0.762, (0.1s)\n",
            "Epoch [38/100]: train=0.8494 val=0.7557, (0.1s)\n",
            "Epoch [39/100]: train=0.8312 val=0.7504, (0.1s)\n",
            "Epoch [40/100]: train=0.8322 val=0.7451, (0.1s)\n",
            "Epoch [41/100]: train=0.8339 val=0.739, (0.1s)\n",
            "Epoch [42/100]: train=0.837 val=0.7342, (0.1s)\n",
            "Epoch [43/100]: train=0.8219 val=0.7295, (0.1s)\n",
            "Epoch [44/100]: train=0.8318 val=0.7241, (0.1s)\n",
            "Epoch [45/100]: train=0.8148 val=0.7193, (0.1s)\n",
            "Epoch [46/100]: train=0.7895 val=0.7139, (0.1s)\n",
            "Epoch [47/100]: train=0.8059 val=0.7093, (0.1s)\n",
            "Epoch [48/100]: train=0.7913 val=0.7054, (0.1s)\n",
            "Epoch [49/100]: train=0.7959 val=0.7019, (0.1s)\n",
            "Epoch [50/100]: train=0.7865 val=0.6973, (0.1s)\n",
            "Epoch [51/100]: train=0.7747 val=0.6936, (0.2s)\n",
            "Epoch [52/100]: train=0.7742 val=0.6888, (0.2s)\n",
            "Epoch [53/100]: train=0.7663 val=0.6844, (0.1s)\n",
            "Epoch [54/100]: train=0.7699 val=0.6803, (0.1s)\n",
            "Epoch [55/100]: train=0.7582 val=0.6764, (0.1s)\n",
            "Epoch [56/100]: train=0.7658 val=0.6728, (0.1s)\n",
            "Epoch [57/100]: train=0.7468 val=0.6696, (0.2s)\n",
            "Epoch [58/100]: train=0.7414 val=0.6664, (0.1s)\n",
            "Epoch [59/100]: train=0.7458 val=0.6631, (0.1s)\n",
            "Epoch [60/100]: train=0.7485 val=0.6597, (0.2s)\n",
            "Epoch [61/100]: train=0.7348 val=0.6564, (0.1s)\n",
            "Epoch [62/100]: train=0.7372 val=0.6534, (0.2s)\n",
            "Epoch [63/100]: train=0.7325 val=0.6497, (0.2s)\n",
            "Epoch [64/100]: train=0.7311 val=0.6471, (0.2s)\n",
            "Epoch [65/100]: train=0.724 val=0.6435, (0.2s)\n",
            "Epoch [66/100]: train=0.7117 val=0.6403, (0.2s)\n",
            "Epoch [67/100]: train=0.7137 val=0.638, (0.1s)\n",
            "Epoch [68/100]: train=0.7212 val=0.6346, (0.1s)\n",
            "Epoch [69/100]: train=0.7167 val=0.6324, (0.1s)\n",
            "Epoch [70/100]: train=0.7028 val=0.629, (0.1s)\n",
            "Epoch [71/100]: train=0.6995 val=0.6263, (0.1s)\n",
            "Epoch [72/100]: train=0.7112 val=0.6238, (0.1s)\n",
            "Epoch [73/100]: train=0.6915 val=0.6211, (0.1s)\n",
            "Epoch [74/100]: train=0.7069 val=0.618, (0.1s)\n",
            "Epoch [75/100]: train=0.6854 val=0.6158, (0.1s)\n",
            "Epoch [76/100]: train=0.6841 val=0.6126, (0.1s)\n",
            "Epoch [77/100]: train=0.6949 val=0.6105, (0.1s)\n",
            "Epoch [78/100]: train=0.6852 val=0.6076, (0.1s)\n",
            "Epoch [79/100]: train=0.6847 val=0.606, (0.1s)\n",
            "Epoch [80/100]: train=0.6722 val=0.6039, (0.1s)\n",
            "Epoch [81/100]: train=0.6629 val=0.6011, (0.1s)\n",
            "Epoch [82/100]: train=0.6853 val=0.5982, (0.1s)\n",
            "Epoch [83/100]: train=0.6808 val=0.5964, (0.1s)\n",
            "Epoch [84/100]: train=0.671 val=0.5935, (0.1s)\n",
            "Epoch [85/100]: train=0.6789 val=0.5909, (0.1s)\n",
            "Epoch [86/100]: train=0.6593 val=0.589, (0.1s)\n",
            "Epoch [87/100]: train=0.6471 val=0.5877, (0.1s)\n",
            "Epoch [88/100]: train=0.663 val=0.5855, (0.1s)\n",
            "Epoch [89/100]: train=0.6512 val=0.5835, (0.1s)\n",
            "Epoch [90/100]: train=0.6512 val=0.5818, (0.1s)\n",
            "Epoch [91/100]: train=0.6536 val=0.5805, (0.1s)\n",
            "Epoch [92/100]: train=0.6502 val=0.5785, (0.1s)\n",
            "Epoch [93/100]: train=0.647 val=0.5764, (0.1s)\n",
            "Epoch [94/100]: train=0.6414 val=0.5735, (0.1s)\n",
            "Epoch [95/100]: train=0.6362 val=0.5716, (0.1s)\n",
            "Epoch [96/100]: train=0.6375 val=0.5689, (0.1s)\n",
            "Epoch [97/100]: train=0.6443 val=0.5674, (0.1s)\n",
            "Epoch [98/100]: train=0.642 val=0.5661, (0.1s)\n",
            "Epoch [99/100]: train=0.641 val=0.5642, (0.1s)\n",
            "Epoch [100/100]: train=0.6313 val=0.5621, (0.1s)\n",
            "================================================\n",
            "SGD_one_task\n",
            "Training on task 1...\n",
            "Epoch [1/100]: train=2.3045 val=2.3026, (0.1s)\n",
            "Epoch [2/100]: train=2.3055 val=2.3026, (0.1s)\n",
            "Epoch [3/100]: train=2.3061 val=2.3026, (0.1s)\n",
            "Epoch [4/100]: train=2.3038 val=2.3026, (0.1s)\n",
            "Epoch [5/100]: train=2.3047 val=2.3026, (0.1s)\n",
            "Epoch [6/100]: train=2.3053 val=2.3026, (0.1s)\n",
            "Epoch [7/100]: train=2.3054 val=2.3026, (0.2s)\n",
            "Epoch [8/100]: train=2.3039 val=2.3026, (0.2s)\n",
            "Epoch [9/100]: train=2.3046 val=2.3026, (0.1s)\n",
            "Epoch [10/100]: train=2.3061 val=2.3026, (0.1s)\n",
            "Epoch [11/100]: train=2.3049 val=2.3026, (0.1s)\n",
            "Epoch [12/100]: train=2.3045 val=2.3026, (0.2s)\n",
            "Epoch [13/100]: train=2.3054 val=2.3026, (0.1s)\n",
            "Epoch [14/100]: train=2.3062 val=2.3026, (0.1s)\n",
            "Epoch [15/100]: train=2.3053 val=2.3026, (0.1s)\n",
            "Epoch [16/100]: train=2.305 val=2.3026, (0.2s)\n",
            "Epoch [17/100]: train=2.3048 val=2.3026, (0.1s)\n",
            "Epoch [18/100]: train=2.3058 val=2.3026, (0.2s)\n",
            "Epoch [19/100]: train=2.3071 val=2.3026, (0.2s)\n",
            "Epoch [20/100]: train=2.3042 val=2.3026, (0.1s)\n",
            "Epoch [21/100]: train=2.3052 val=2.3026, (0.1s)\n",
            "Epoch [22/100]: train=2.3043 val=2.3026, (0.2s)\n",
            "Epoch [23/100]: train=2.3055 val=2.3026, (0.2s)\n",
            "Epoch [24/100]: train=2.3042 val=2.3026, (0.1s)\n",
            "Epoch [25/100]: train=2.3043 val=2.3026, (0.2s)\n",
            "Epoch [26/100]: train=2.3047 val=2.3026, (0.1s)\n",
            "Epoch [27/100]: train=2.3051 val=2.3026, (0.1s)\n",
            "Epoch [28/100]: train=2.3067 val=2.3026, (0.1s)\n",
            "Epoch [29/100]: train=2.3053 val=2.3026, (0.1s)\n",
            "Epoch [30/100]: train=2.3053 val=2.3026, (0.1s)\n",
            "Epoch [31/100]: train=2.3035 val=2.3026, (0.1s)\n",
            "Epoch [32/100]: train=2.3054 val=2.3026, (0.1s)\n",
            "Epoch [33/100]: train=2.3038 val=2.3026, (0.1s)\n",
            "Epoch [34/100]: train=2.3055 val=2.3026, (0.1s)\n",
            "Epoch [35/100]: train=2.3046 val=2.3026, (0.1s)\n",
            "Epoch [36/100]: train=2.3047 val=2.3026, (0.1s)\n",
            "Epoch [37/100]: train=2.3045 val=2.3026, (0.1s)\n",
            "Epoch [38/100]: train=2.305 val=2.3026, (0.1s)\n",
            "Epoch [39/100]: train=2.3041 val=2.3026, (0.1s)\n",
            "Epoch [40/100]: train=2.3043 val=2.3026, (0.1s)\n",
            "Epoch [41/100]: train=2.3055 val=2.3026, (0.1s)\n",
            "Epoch [42/100]: train=2.3049 val=2.3026, (0.1s)\n",
            "Epoch [43/100]: train=2.3057 val=2.3026, (0.1s)\n",
            "Epoch [44/100]: train=2.3061 val=2.3026, (0.1s)\n",
            "Epoch [45/100]: train=2.3055 val=2.3026, (0.1s)\n",
            "Epoch [46/100]: train=2.3052 val=2.3026, (0.1s)\n",
            "Epoch [47/100]: train=2.3052 val=2.3026, (0.1s)\n",
            "Epoch [48/100]: train=2.3067 val=2.3026, (0.1s)\n",
            "Epoch [49/100]: train=2.3061 val=2.3026, (0.1s)\n",
            "Epoch [50/100]: train=2.3054 val=2.3026, (0.1s)\n",
            "Epoch [51/100]: train=2.3055 val=2.3026, (0.1s)\n",
            "Epoch [52/100]: train=2.3032 val=2.3026, (0.1s)\n",
            "Epoch [53/100]: train=2.3033 val=2.3026, (0.1s)\n",
            "Epoch [54/100]: train=2.3048 val=2.3026, (0.1s)\n",
            "Epoch [55/100]: train=2.305 val=2.3026, (0.1s)\n",
            "Epoch [56/100]: train=2.3054 val=2.3026, (0.1s)\n",
            "Epoch [57/100]: train=2.3067 val=2.3026, (0.1s)\n",
            "Epoch [58/100]: train=2.305 val=2.3026, (0.1s)\n",
            "Epoch [59/100]: train=2.3056 val=2.3026, (0.1s)\n",
            "Epoch [60/100]: train=2.3047 val=2.3026, (0.1s)\n",
            "Epoch [61/100]: train=2.3057 val=2.3026, (0.1s)\n",
            "Epoch [62/100]: train=2.3053 val=2.3026, (0.1s)\n",
            "Epoch [63/100]: train=2.3052 val=2.3026, (0.1s)\n",
            "Epoch [64/100]: train=2.3053 val=2.3026, (0.1s)\n",
            "Epoch [65/100]: train=2.3057 val=2.3026, (0.1s)\n",
            "Epoch [66/100]: train=2.3069 val=2.3026, (0.1s)\n",
            "Epoch [67/100]: train=2.3053 val=2.3026, (0.1s)\n",
            "Epoch [68/100]: train=2.3058 val=2.3026, (0.1s)\n",
            "Epoch [69/100]: train=2.3037 val=2.3026, (0.1s)\n",
            "Epoch [70/100]: train=2.3043 val=2.3026, (0.1s)\n",
            "Epoch [71/100]: train=2.3058 val=2.3026, (0.1s)\n",
            "Epoch [72/100]: train=2.3044 val=2.3026, (0.1s)\n",
            "Epoch [73/100]: train=2.3065 val=2.3026, (0.1s)\n",
            "Epoch [74/100]: train=2.3052 val=2.3026, (0.1s)\n",
            "Epoch [75/100]: train=2.3044 val=2.3026, (0.1s)\n",
            "Epoch [76/100]: train=2.3037 val=2.3026, (0.1s)\n",
            "Epoch [77/100]: train=2.3053 val=2.3026, (0.1s)\n",
            "Epoch [78/100]: train=2.306 val=2.3026, (0.1s)\n",
            "Epoch [79/100]: train=2.3054 val=2.3026, (0.1s)\n",
            "Epoch [80/100]: train=2.3055 val=2.3026, (0.1s)\n",
            "Epoch [81/100]: train=2.3059 val=2.3026, (0.1s)\n",
            "Epoch [82/100]: train=2.3061 val=2.3026, (0.1s)\n",
            "Epoch [83/100]: train=2.3046 val=2.3026, (0.1s)\n",
            "Epoch [84/100]: train=2.3051 val=2.3026, (0.1s)\n",
            "Epoch [85/100]: train=2.3051 val=2.3026, (0.1s)\n",
            "Epoch [86/100]: train=2.304 val=2.3026, (0.1s)\n",
            "Epoch [87/100]: train=2.3032 val=2.3026, (0.1s)\n",
            "Epoch [88/100]: train=2.3044 val=2.3026, (0.1s)\n",
            "Epoch [89/100]: train=2.3049 val=2.3026, (0.1s)\n",
            "Epoch [90/100]: train=2.3069 val=2.3026, (0.1s)\n",
            "Epoch [91/100]: train=2.305 val=2.3026, (0.1s)\n",
            "Epoch [92/100]: train=2.3045 val=2.3026, (0.1s)\n",
            "Epoch [93/100]: train=2.3037 val=2.3026, (0.1s)\n",
            "Epoch [94/100]: train=2.3039 val=2.3026, (0.1s)\n",
            "Epoch [95/100]: train=2.3035 val=2.3026, (0.1s)\n",
            "Epoch [96/100]: train=2.3054 val=2.3026, (0.1s)\n",
            "Epoch [97/100]: train=2.305 val=2.3026, (0.1s)\n",
            "Epoch [98/100]: train=2.3066 val=2.3026, (0.1s)\n",
            "Epoch [99/100]: train=2.3044 val=2.3026, (0.1s)\n",
            "Epoch [100/100]: train=2.3044 val=2.3026, (0.1s)\n",
            "Training on task 2...\n",
            "Epoch [1/100]: train=2.3064 val=2.3072, (0.1s)\n",
            "Epoch [2/100]: train=2.3069 val=2.3072, (0.1s)\n",
            "Epoch [3/100]: train=2.3067 val=2.3072, (0.1s)\n",
            "Epoch [4/100]: train=2.3066 val=2.3072, (0.1s)\n",
            "Epoch [5/100]: train=2.3072 val=2.3072, (0.1s)\n",
            "Epoch [6/100]: train=2.305 val=2.3072, (0.1s)\n",
            "Epoch [7/100]: train=2.3059 val=2.3072, (0.1s)\n",
            "Epoch [8/100]: train=2.3066 val=2.3072, (0.1s)\n",
            "Epoch [9/100]: train=2.3058 val=2.3072, (0.2s)\n",
            "Epoch [10/100]: train=2.3079 val=2.3072, (0.1s)\n",
            "Epoch [11/100]: train=2.3062 val=2.3072, (0.2s)\n",
            "Epoch [12/100]: train=2.307 val=2.3072, (0.1s)\n",
            "Epoch [13/100]: train=2.3069 val=2.3072, (0.1s)\n",
            "Epoch [14/100]: train=2.3077 val=2.3072, (0.1s)\n",
            "Epoch [15/100]: train=2.307 val=2.3072, (0.1s)\n",
            "Epoch [16/100]: train=2.3073 val=2.3072, (0.1s)\n",
            "Epoch [17/100]: train=2.307 val=2.3072, (0.1s)\n",
            "Epoch [18/100]: train=2.3075 val=2.3072, (0.2s)\n",
            "Epoch [19/100]: train=2.3051 val=2.3072, (0.1s)\n",
            "Epoch [20/100]: train=2.3073 val=2.3072, (0.2s)\n",
            "Epoch [21/100]: train=2.308 val=2.3072, (0.2s)\n",
            "Epoch [22/100]: train=2.3063 val=2.3072, (0.1s)\n",
            "Epoch [23/100]: train=2.3068 val=2.3072, (0.1s)\n",
            "Epoch [24/100]: train=2.3051 val=2.3072, (0.1s)\n",
            "Epoch [25/100]: train=2.3068 val=2.3072, (0.2s)\n",
            "Epoch [26/100]: train=2.3055 val=2.3072, (0.2s)\n",
            "Epoch [27/100]: train=2.3076 val=2.3072, (0.1s)\n",
            "Epoch [28/100]: train=2.306 val=2.3072, (0.1s)\n",
            "Epoch [29/100]: train=2.3072 val=2.3072, (0.1s)\n",
            "Epoch [30/100]: train=2.3055 val=2.3072, (0.1s)\n",
            "Epoch [31/100]: train=2.308 val=2.3072, (0.1s)\n",
            "Epoch [32/100]: train=2.3072 val=2.3072, (0.1s)\n",
            "Epoch [33/100]: train=2.3074 val=2.3072, (0.1s)\n",
            "Epoch [34/100]: train=2.3068 val=2.3072, (0.1s)\n",
            "Epoch [35/100]: train=2.3076 val=2.3072, (0.1s)\n",
            "Epoch [36/100]: train=2.3061 val=2.3072, (0.1s)\n",
            "Epoch [37/100]: train=2.3061 val=2.3072, (0.1s)\n",
            "Epoch [38/100]: train=2.3064 val=2.3072, (0.1s)\n",
            "Epoch [39/100]: train=2.3058 val=2.3072, (0.1s)\n",
            "Epoch [40/100]: train=2.3072 val=2.3072, (0.1s)\n",
            "Epoch [41/100]: train=2.307 val=2.3072, (0.1s)\n",
            "Epoch [42/100]: train=2.3067 val=2.3072, (0.1s)\n",
            "Epoch [43/100]: train=2.3057 val=2.3072, (0.1s)\n",
            "Epoch [44/100]: train=2.3072 val=2.3072, (0.1s)\n",
            "Epoch [45/100]: train=2.3066 val=2.3072, (0.1s)\n",
            "Epoch [46/100]: train=2.3064 val=2.3072, (0.1s)\n",
            "Epoch [47/100]: train=2.306 val=2.3072, (0.1s)\n",
            "Epoch [48/100]: train=2.3072 val=2.3072, (0.1s)\n",
            "Epoch [49/100]: train=2.308 val=2.3072, (0.1s)\n",
            "Epoch [50/100]: train=2.3057 val=2.3072, (0.1s)\n",
            "Epoch [51/100]: train=2.3075 val=2.3072, (0.1s)\n",
            "Epoch [52/100]: train=2.3065 val=2.3072, (0.1s)\n",
            "Epoch [53/100]: train=2.3073 val=2.3072, (0.1s)\n",
            "Epoch [54/100]: train=2.3063 val=2.3072, (0.1s)\n",
            "Epoch [55/100]: train=2.3069 val=2.3072, (0.1s)\n",
            "Epoch [56/100]: train=2.3064 val=2.3072, (0.1s)\n",
            "Epoch [57/100]: train=2.3077 val=2.3072, (0.1s)\n",
            "Epoch [58/100]: train=2.3069 val=2.3072, (0.1s)\n",
            "Epoch [59/100]: train=2.3065 val=2.3072, (0.1s)\n",
            "Epoch [60/100]: train=2.3073 val=2.3072, (0.1s)\n",
            "Epoch [61/100]: train=2.3072 val=2.3072, (0.1s)\n",
            "Epoch [62/100]: train=2.3072 val=2.3072, (0.1s)\n",
            "Epoch [63/100]: train=2.3069 val=2.3072, (0.1s)\n",
            "Epoch [64/100]: train=2.3067 val=2.3072, (0.1s)\n",
            "Epoch [65/100]: train=2.3062 val=2.3072, (0.1s)\n",
            "Epoch [66/100]: train=2.3077 val=2.3072, (0.1s)\n",
            "Epoch [67/100]: train=2.3063 val=2.3072, (0.1s)\n",
            "Epoch [68/100]: train=2.3049 val=2.3072, (0.1s)\n",
            "Epoch [69/100]: train=2.3063 val=2.3072, (0.1s)\n",
            "Epoch [70/100]: train=2.3056 val=2.3072, (0.1s)\n",
            "Epoch [71/100]: train=2.3072 val=2.3072, (0.1s)\n",
            "Epoch [72/100]: train=2.3072 val=2.3072, (0.1s)\n",
            "Epoch [73/100]: train=2.3051 val=2.3072, (0.1s)\n",
            "Epoch [74/100]: train=2.3064 val=2.3072, (0.1s)\n",
            "Epoch [75/100]: train=2.3067 val=2.3072, (0.1s)\n",
            "Epoch [76/100]: train=2.3064 val=2.3072, (0.1s)\n",
            "Epoch [77/100]: train=2.3073 val=2.3072, (0.1s)\n",
            "Epoch [78/100]: train=2.3075 val=2.3072, (0.1s)\n",
            "Epoch [79/100]: train=2.3065 val=2.3072, (0.1s)\n",
            "Epoch [80/100]: train=2.309 val=2.3072, (0.1s)\n",
            "Epoch [81/100]: train=2.3064 val=2.3072, (0.1s)\n",
            "Epoch [82/100]: train=2.3064 val=2.3072, (0.1s)\n",
            "Epoch [83/100]: train=2.3055 val=2.3072, (0.1s)\n",
            "Epoch [84/100]: train=2.3055 val=2.3072, (0.1s)\n",
            "Epoch [85/100]: train=2.3053 val=2.3072, (0.1s)\n",
            "Epoch [86/100]: train=2.3081 val=2.3072, (0.1s)\n",
            "Epoch [87/100]: train=2.3056 val=2.3072, (0.1s)\n",
            "Epoch [88/100]: train=2.3065 val=2.3072, (0.1s)\n",
            "Epoch [89/100]: train=2.3079 val=2.3072, (0.1s)\n",
            "Epoch [90/100]: train=2.3071 val=2.3072, (0.1s)\n",
            "Epoch [91/100]: train=2.307 val=2.3072, (0.1s)\n",
            "Epoch [92/100]: train=2.3078 val=2.3072, (0.1s)\n",
            "Epoch [93/100]: train=2.3063 val=2.3072, (0.1s)\n",
            "Epoch [94/100]: train=2.3074 val=2.3072, (0.1s)\n",
            "Epoch [95/100]: train=2.3074 val=2.3072, (0.1s)\n",
            "Epoch [96/100]: train=2.3075 val=2.3072, (0.1s)\n",
            "Epoch [97/100]: train=2.3055 val=2.3072, (0.1s)\n",
            "Epoch [98/100]: train=2.3083 val=2.3072, (0.1s)\n",
            "Epoch [99/100]: train=2.3073 val=2.3072, (0.1s)\n",
            "Epoch [100/100]: train=2.3077 val=2.3072, (0.1s)\n",
            "Training on task 3...\n",
            "Epoch [1/100]: train=2.3087 val=2.3056, (0.1s)\n",
            "Epoch [2/100]: train=2.3081 val=2.3056, (0.1s)\n",
            "Epoch [3/100]: train=2.3089 val=2.3056, (0.1s)\n",
            "Epoch [4/100]: train=2.3083 val=2.3056, (0.1s)\n",
            "Epoch [5/100]: train=2.3099 val=2.3056, (0.1s)\n",
            "Epoch [6/100]: train=2.3097 val=2.3056, (0.1s)\n",
            "Epoch [7/100]: train=2.307 val=2.3056, (0.1s)\n",
            "Epoch [8/100]: train=2.3076 val=2.3056, (0.1s)\n",
            "Epoch [9/100]: train=2.3089 val=2.3056, (0.1s)\n",
            "Epoch [10/100]: train=2.308 val=2.3056, (0.1s)\n",
            "Epoch [11/100]: train=2.3075 val=2.3056, (0.2s)\n",
            "Epoch [12/100]: train=2.3075 val=2.3056, (0.1s)\n",
            "Epoch [13/100]: train=2.3082 val=2.3056, (0.1s)\n",
            "Epoch [14/100]: train=2.3077 val=2.3056, (0.1s)\n",
            "Epoch [15/100]: train=2.3079 val=2.3056, (0.1s)\n",
            "Epoch [16/100]: train=2.3083 val=2.3056, (0.1s)\n",
            "Epoch [17/100]: train=2.3076 val=2.3056, (0.1s)\n",
            "Epoch [18/100]: train=2.308 val=2.3056, (0.1s)\n",
            "Epoch [19/100]: train=2.3078 val=2.3056, (0.1s)\n",
            "Epoch [20/100]: train=2.3079 val=2.3056, (0.2s)\n",
            "Epoch [21/100]: train=2.3067 val=2.3056, (0.1s)\n",
            "Epoch [22/100]: train=2.3101 val=2.3056, (0.2s)\n",
            "Epoch [23/100]: train=2.3085 val=2.3056, (0.2s)\n",
            "Epoch [24/100]: train=2.3096 val=2.3056, (0.1s)\n",
            "Epoch [25/100]: train=2.3085 val=2.3056, (0.2s)\n",
            "Epoch [26/100]: train=2.308 val=2.3056, (0.1s)\n",
            "Epoch [27/100]: train=2.3077 val=2.3056, (0.1s)\n",
            "Epoch [28/100]: train=2.3086 val=2.3056, (0.2s)\n",
            "Epoch [29/100]: train=2.3092 val=2.3056, (0.1s)\n",
            "Epoch [30/100]: train=2.309 val=2.3056, (0.1s)\n",
            "Epoch [31/100]: train=2.3084 val=2.3056, (0.1s)\n",
            "Epoch [32/100]: train=2.3076 val=2.3056, (0.1s)\n",
            "Epoch [33/100]: train=2.3077 val=2.3056, (0.1s)\n",
            "Epoch [34/100]: train=2.3083 val=2.3056, (0.1s)\n",
            "Epoch [35/100]: train=2.3076 val=2.3056, (0.1s)\n",
            "Epoch [36/100]: train=2.309 val=2.3056, (0.1s)\n",
            "Epoch [37/100]: train=2.3089 val=2.3056, (0.1s)\n",
            "Epoch [38/100]: train=2.3096 val=2.3056, (0.1s)\n",
            "Epoch [39/100]: train=2.3081 val=2.3056, (0.1s)\n",
            "Epoch [40/100]: train=2.3084 val=2.3056, (0.1s)\n",
            "Epoch [41/100]: train=2.3071 val=2.3056, (0.1s)\n",
            "Epoch [42/100]: train=2.308 val=2.3056, (0.1s)\n",
            "Epoch [43/100]: train=2.309 val=2.3056, (0.1s)\n",
            "Epoch [44/100]: train=2.3082 val=2.3056, (0.1s)\n",
            "Epoch [45/100]: train=2.308 val=2.3056, (0.1s)\n",
            "Epoch [46/100]: train=2.3071 val=2.3056, (0.1s)\n",
            "Epoch [47/100]: train=2.3097 val=2.3056, (0.1s)\n",
            "Epoch [48/100]: train=2.3075 val=2.3056, (0.1s)\n",
            "Epoch [49/100]: train=2.3072 val=2.3056, (0.1s)\n",
            "Epoch [50/100]: train=2.3088 val=2.3056, (0.1s)\n",
            "Epoch [51/100]: train=2.3075 val=2.3056, (0.1s)\n",
            "Epoch [52/100]: train=2.3063 val=2.3056, (0.1s)\n",
            "Epoch [53/100]: train=2.3089 val=2.3056, (0.1s)\n",
            "Epoch [54/100]: train=2.3076 val=2.3056, (0.1s)\n",
            "Epoch [55/100]: train=2.3077 val=2.3056, (0.1s)\n",
            "Epoch [56/100]: train=2.3067 val=2.3056, (0.1s)\n",
            "Epoch [57/100]: train=2.308 val=2.3056, (0.1s)\n",
            "Epoch [58/100]: train=2.3076 val=2.3056, (0.1s)\n",
            "Epoch [59/100]: train=2.3086 val=2.3056, (0.1s)\n",
            "Epoch [60/100]: train=2.309 val=2.3056, (0.1s)\n",
            "Epoch [61/100]: train=2.3071 val=2.3056, (0.1s)\n",
            "Epoch [62/100]: train=2.308 val=2.3056, (0.1s)\n",
            "Epoch [63/100]: train=2.3079 val=2.3056, (0.1s)\n",
            "Epoch [64/100]: train=2.3063 val=2.3056, (0.1s)\n",
            "Epoch [65/100]: train=2.3083 val=2.3056, (0.1s)\n",
            "Epoch [66/100]: train=2.3086 val=2.3056, (0.1s)\n",
            "Epoch [67/100]: train=2.3084 val=2.3056, (0.1s)\n",
            "Epoch [68/100]: train=2.3069 val=2.3056, (0.1s)\n",
            "Epoch [69/100]: train=2.3065 val=2.3056, (0.1s)\n",
            "Epoch [70/100]: train=2.3066 val=2.3056, (0.1s)\n",
            "Epoch [71/100]: train=2.3071 val=2.3056, (0.1s)\n",
            "Epoch [72/100]: train=2.3079 val=2.3056, (0.1s)\n",
            "Epoch [73/100]: train=2.308 val=2.3056, (0.1s)\n",
            "Epoch [74/100]: train=2.308 val=2.3056, (0.1s)\n",
            "Epoch [75/100]: train=2.3075 val=2.3056, (0.1s)\n",
            "Epoch [76/100]: train=2.3078 val=2.3056, (0.1s)\n",
            "Epoch [77/100]: train=2.309 val=2.3056, (0.1s)\n",
            "Epoch [78/100]: train=2.3087 val=2.3056, (0.1s)\n",
            "Epoch [79/100]: train=2.3076 val=2.3056, (0.1s)\n",
            "Epoch [80/100]: train=2.3082 val=2.3056, (0.1s)\n",
            "Epoch [81/100]: train=2.3097 val=2.3056, (0.1s)\n",
            "Epoch [82/100]: train=2.3084 val=2.3056, (0.1s)\n",
            "Epoch [83/100]: train=2.3093 val=2.3056, (0.1s)\n",
            "Epoch [84/100]: train=2.3078 val=2.3056, (0.1s)\n",
            "Epoch [85/100]: train=2.3073 val=2.3056, (0.1s)\n",
            "Epoch [86/100]: train=2.3089 val=2.3056, (0.1s)\n",
            "Epoch [87/100]: train=2.3087 val=2.3056, (0.1s)\n",
            "Epoch [88/100]: train=2.3095 val=2.3056, (0.1s)\n",
            "Epoch [89/100]: train=2.3075 val=2.3056, (0.1s)\n",
            "Epoch [90/100]: train=2.3092 val=2.3056, (0.1s)\n",
            "Epoch [91/100]: train=2.3084 val=2.3056, (0.1s)\n",
            "Epoch [92/100]: train=2.3092 val=2.3056, (0.1s)\n",
            "Epoch [93/100]: train=2.3086 val=2.3056, (0.1s)\n",
            "Epoch [94/100]: train=2.308 val=2.3056, (0.1s)\n",
            "Epoch [95/100]: train=2.3076 val=2.3056, (0.1s)\n",
            "Epoch [96/100]: train=2.3089 val=2.3056, (0.1s)\n",
            "Epoch [97/100]: train=2.3087 val=2.3056, (0.1s)\n",
            "Epoch [98/100]: train=2.308 val=2.3056, (0.1s)\n",
            "Epoch [99/100]: train=2.3094 val=2.3056, (0.1s)\n",
            "Epoch [100/100]: train=2.3083 val=2.3056, (0.1s)\n",
            "Training on task 4...\n",
            "Epoch [1/100]: train=2.3057 val=2.3022, (0.1s)\n",
            "Epoch [2/100]: train=2.3057 val=2.3022, (0.1s)\n",
            "Epoch [3/100]: train=2.3044 val=2.3022, (0.1s)\n",
            "Epoch [4/100]: train=2.3051 val=2.3022, (0.1s)\n",
            "Epoch [5/100]: train=2.3053 val=2.3022, (0.1s)\n",
            "Epoch [6/100]: train=2.3057 val=2.3022, (0.1s)\n",
            "Epoch [7/100]: train=2.305 val=2.3022, (0.1s)\n",
            "Epoch [8/100]: train=2.3056 val=2.3022, (0.1s)\n",
            "Epoch [9/100]: train=2.305 val=2.3022, (0.1s)\n",
            "Epoch [10/100]: train=2.3045 val=2.3022, (0.1s)\n",
            "Epoch [11/100]: train=2.3052 val=2.3022, (0.1s)\n",
            "Epoch [12/100]: train=2.3053 val=2.3022, (0.2s)\n",
            "Epoch [13/100]: train=2.3059 val=2.3022, (0.2s)\n",
            "Epoch [14/100]: train=2.305 val=2.3022, (0.1s)\n",
            "Epoch [15/100]: train=2.3049 val=2.3022, (0.2s)\n",
            "Epoch [16/100]: train=2.305 val=2.3022, (0.1s)\n",
            "Epoch [17/100]: train=2.3036 val=2.3022, (0.1s)\n",
            "Epoch [18/100]: train=2.3065 val=2.3022, (0.1s)\n",
            "Epoch [19/100]: train=2.3048 val=2.3022, (0.1s)\n",
            "Epoch [20/100]: train=2.305 val=2.3022, (0.1s)\n",
            "Epoch [21/100]: train=2.3058 val=2.3022, (0.2s)\n",
            "Epoch [22/100]: train=2.3038 val=2.3022, (0.1s)\n",
            "Epoch [23/100]: train=2.3036 val=2.3022, (0.2s)\n",
            "Epoch [24/100]: train=2.3051 val=2.3022, (0.2s)\n",
            "Epoch [25/100]: train=2.3049 val=2.3022, (0.2s)\n",
            "Epoch [26/100]: train=2.3047 val=2.3022, (0.1s)\n",
            "Epoch [27/100]: train=2.3042 val=2.3022, (0.2s)\n",
            "Epoch [28/100]: train=2.3052 val=2.3022, (0.1s)\n",
            "Epoch [29/100]: train=2.3049 val=2.3022, (0.2s)\n",
            "Epoch [30/100]: train=2.3061 val=2.3022, (0.1s)\n",
            "Epoch [31/100]: train=2.305 val=2.3022, (0.1s)\n",
            "Epoch [32/100]: train=2.3047 val=2.3022, (0.1s)\n",
            "Epoch [33/100]: train=2.3047 val=2.3022, (0.1s)\n",
            "Epoch [34/100]: train=2.3047 val=2.3022, (0.1s)\n",
            "Epoch [35/100]: train=2.3048 val=2.3022, (0.1s)\n",
            "Epoch [36/100]: train=2.3048 val=2.3022, (0.1s)\n",
            "Epoch [37/100]: train=2.3065 val=2.3022, (0.1s)\n",
            "Epoch [38/100]: train=2.3046 val=2.3022, (0.1s)\n",
            "Epoch [39/100]: train=2.3043 val=2.3022, (0.1s)\n",
            "Epoch [40/100]: train=2.3055 val=2.3022, (0.1s)\n",
            "Epoch [41/100]: train=2.3054 val=2.3022, (0.1s)\n",
            "Epoch [42/100]: train=2.3055 val=2.3022, (0.1s)\n",
            "Epoch [43/100]: train=2.3046 val=2.3022, (0.1s)\n",
            "Epoch [44/100]: train=2.3042 val=2.3022, (0.1s)\n",
            "Epoch [45/100]: train=2.3044 val=2.3022, (0.1s)\n",
            "Epoch [46/100]: train=2.3067 val=2.3022, (0.1s)\n",
            "Epoch [47/100]: train=2.3045 val=2.3022, (0.1s)\n",
            "Epoch [48/100]: train=2.3043 val=2.3022, (0.1s)\n",
            "Epoch [49/100]: train=2.304 val=2.3022, (0.1s)\n",
            "Epoch [50/100]: train=2.3066 val=2.3022, (0.1s)\n",
            "Epoch [51/100]: train=2.3049 val=2.3022, (0.1s)\n",
            "Epoch [52/100]: train=2.3037 val=2.3022, (0.1s)\n",
            "Epoch [53/100]: train=2.3046 val=2.3022, (0.1s)\n",
            "Epoch [54/100]: train=2.3045 val=2.3022, (0.1s)\n",
            "Epoch [55/100]: train=2.3045 val=2.3022, (0.1s)\n",
            "Epoch [56/100]: train=2.3063 val=2.3022, (0.1s)\n",
            "Epoch [57/100]: train=2.3042 val=2.3022, (0.1s)\n",
            "Epoch [58/100]: train=2.306 val=2.3022, (0.1s)\n",
            "Epoch [59/100]: train=2.3055 val=2.3022, (0.1s)\n",
            "Epoch [60/100]: train=2.3058 val=2.3022, (0.1s)\n",
            "Epoch [61/100]: train=2.3047 val=2.3022, (0.1s)\n",
            "Epoch [62/100]: train=2.305 val=2.3022, (0.1s)\n",
            "Epoch [63/100]: train=2.3043 val=2.3022, (0.1s)\n",
            "Epoch [64/100]: train=2.3042 val=2.3022, (0.1s)\n",
            "Epoch [65/100]: train=2.3048 val=2.3022, (0.1s)\n",
            "Epoch [66/100]: train=2.3047 val=2.3022, (0.1s)\n",
            "Epoch [67/100]: train=2.3047 val=2.3022, (0.1s)\n",
            "Epoch [68/100]: train=2.3051 val=2.3022, (0.1s)\n",
            "Epoch [69/100]: train=2.3059 val=2.3022, (0.1s)\n",
            "Epoch [70/100]: train=2.3034 val=2.3022, (0.1s)\n",
            "Epoch [71/100]: train=2.3058 val=2.3022, (0.1s)\n",
            "Epoch [72/100]: train=2.3057 val=2.3022, (0.1s)\n",
            "Epoch [73/100]: train=2.3035 val=2.3022, (0.1s)\n",
            "Epoch [74/100]: train=2.3051 val=2.3022, (0.1s)\n",
            "Epoch [75/100]: train=2.3051 val=2.3022, (0.1s)\n",
            "Epoch [76/100]: train=2.3057 val=2.3022, (0.1s)\n",
            "Epoch [77/100]: train=2.3044 val=2.3022, (0.1s)\n",
            "Epoch [78/100]: train=2.3051 val=2.3022, (0.1s)\n",
            "Epoch [79/100]: train=2.3036 val=2.3022, (0.1s)\n",
            "Epoch [80/100]: train=2.3059 val=2.3022, (0.1s)\n",
            "Epoch [81/100]: train=2.3055 val=2.3022, (0.1s)\n",
            "Epoch [82/100]: train=2.3062 val=2.3022, (0.1s)\n",
            "Epoch [83/100]: train=2.3053 val=2.3022, (0.1s)\n",
            "Epoch [84/100]: train=2.3052 val=2.3022, (0.1s)\n",
            "Epoch [85/100]: train=2.3057 val=2.3022, (0.1s)\n",
            "Epoch [86/100]: train=2.3056 val=2.3022, (0.1s)\n",
            "Epoch [87/100]: train=2.3054 val=2.3022, (0.1s)\n",
            "Epoch [88/100]: train=2.3066 val=2.3022, (0.1s)\n",
            "Epoch [89/100]: train=2.3039 val=2.3022, (0.1s)\n",
            "Epoch [90/100]: train=2.3049 val=2.3022, (0.1s)\n",
            "Epoch [91/100]: train=2.3047 val=2.3022, (0.1s)\n",
            "Epoch [92/100]: train=2.3059 val=2.3022, (0.1s)\n",
            "Epoch [93/100]: train=2.3059 val=2.3022, (0.1s)\n",
            "Epoch [94/100]: train=2.3055 val=2.3022, (0.1s)\n",
            "Epoch [95/100]: train=2.3048 val=2.3022, (0.1s)\n",
            "Epoch [96/100]: train=2.3055 val=2.3022, (0.1s)\n",
            "Epoch [97/100]: train=2.3055 val=2.3022, (0.1s)\n",
            "Epoch [98/100]: train=2.3061 val=2.3022, (0.1s)\n",
            "Epoch [99/100]: train=2.304 val=2.3022, (0.1s)\n",
            "Epoch [100/100]: train=2.3044 val=2.3022, (0.1s)\n",
            "Training on task 5...\n",
            "Epoch [1/100]: train=2.3072 val=2.3054, (0.1s)\n",
            "Epoch [2/100]: train=2.3075 val=2.3054, (0.1s)\n",
            "Epoch [3/100]: train=2.3074 val=2.3054, (0.1s)\n",
            "Epoch [4/100]: train=2.306 val=2.3054, (0.1s)\n",
            "Epoch [5/100]: train=2.3071 val=2.3054, (0.1s)\n",
            "Epoch [6/100]: train=2.3053 val=2.3054, (0.1s)\n",
            "Epoch [7/100]: train=2.308 val=2.3054, (0.1s)\n",
            "Epoch [8/100]: train=2.3062 val=2.3054, (0.1s)\n",
            "Epoch [9/100]: train=2.3088 val=2.3054, (0.1s)\n",
            "Epoch [10/100]: train=2.307 val=2.3054, (0.1s)\n",
            "Epoch [11/100]: train=2.3072 val=2.3054, (0.1s)\n",
            "Epoch [12/100]: train=2.3073 val=2.3054, (0.1s)\n",
            "Epoch [13/100]: train=2.3065 val=2.3054, (0.2s)\n",
            "Epoch [14/100]: train=2.3069 val=2.3054, (0.2s)\n",
            "Epoch [15/100]: train=2.3073 val=2.3054, (0.1s)\n",
            "Epoch [16/100]: train=2.3075 val=2.3054, (0.1s)\n",
            "Epoch [17/100]: train=2.3069 val=2.3054, (0.2s)\n",
            "Epoch [18/100]: train=2.3065 val=2.3054, (0.1s)\n",
            "Epoch [19/100]: train=2.3077 val=2.3054, (0.1s)\n",
            "Epoch [20/100]: train=2.306 val=2.3054, (0.2s)\n",
            "Epoch [21/100]: train=2.3072 val=2.3054, (0.2s)\n",
            "Epoch [22/100]: train=2.3089 val=2.3054, (0.2s)\n",
            "Epoch [23/100]: train=2.3059 val=2.3054, (0.2s)\n",
            "Epoch [24/100]: train=2.3067 val=2.3054, (0.2s)\n",
            "Epoch [25/100]: train=2.3073 val=2.3054, (0.2s)\n",
            "Epoch [26/100]: train=2.3074 val=2.3054, (0.2s)\n",
            "Epoch [27/100]: train=2.3069 val=2.3054, (0.2s)\n",
            "Epoch [28/100]: train=2.3066 val=2.3054, (0.2s)\n",
            "Epoch [29/100]: train=2.3075 val=2.3054, (0.2s)\n",
            "Epoch [30/100]: train=2.3058 val=2.3054, (0.2s)\n",
            "Epoch [31/100]: train=2.3073 val=2.3054, (0.2s)\n",
            "Epoch [32/100]: train=2.3065 val=2.3054, (0.1s)\n",
            "Epoch [33/100]: train=2.306 val=2.3054, (0.1s)\n",
            "Epoch [34/100]: train=2.3061 val=2.3054, (0.1s)\n",
            "Epoch [35/100]: train=2.3063 val=2.3054, (0.1s)\n",
            "Epoch [36/100]: train=2.3074 val=2.3054, (0.1s)\n",
            "Epoch [37/100]: train=2.3074 val=2.3054, (0.1s)\n",
            "Epoch [38/100]: train=2.3068 val=2.3054, (0.1s)\n",
            "Epoch [39/100]: train=2.3079 val=2.3054, (0.1s)\n",
            "Epoch [40/100]: train=2.3054 val=2.3054, (0.1s)\n",
            "Epoch [41/100]: train=2.3057 val=2.3054, (0.1s)\n",
            "Epoch [42/100]: train=2.3071 val=2.3054, (0.1s)\n",
            "Epoch [43/100]: train=2.3066 val=2.3054, (0.1s)\n",
            "Epoch [44/100]: train=2.3087 val=2.3054, (0.1s)\n",
            "Epoch [45/100]: train=2.3075 val=2.3054, (0.1s)\n",
            "Epoch [46/100]: train=2.3062 val=2.3054, (0.1s)\n",
            "Epoch [47/100]: train=2.3078 val=2.3054, (0.1s)\n",
            "Epoch [48/100]: train=2.3072 val=2.3054, (0.1s)\n",
            "Epoch [49/100]: train=2.3067 val=2.3054, (0.1s)\n",
            "Epoch [50/100]: train=2.3081 val=2.3054, (0.1s)\n",
            "Epoch [51/100]: train=2.307 val=2.3054, (0.1s)\n",
            "Epoch [52/100]: train=2.3068 val=2.3054, (0.1s)\n",
            "Epoch [53/100]: train=2.3073 val=2.3054, (0.1s)\n",
            "Epoch [54/100]: train=2.3064 val=2.3054, (0.1s)\n",
            "Epoch [55/100]: train=2.3065 val=2.3054, (0.1s)\n",
            "Epoch [56/100]: train=2.3056 val=2.3054, (0.1s)\n",
            "Epoch [57/100]: train=2.3096 val=2.3054, (0.1s)\n",
            "Epoch [58/100]: train=2.3065 val=2.3054, (0.1s)\n",
            "Epoch [59/100]: train=2.3061 val=2.3054, (0.1s)\n",
            "Epoch [60/100]: train=2.308 val=2.3054, (0.1s)\n",
            "Epoch [61/100]: train=2.3071 val=2.3054, (0.1s)\n",
            "Epoch [62/100]: train=2.3079 val=2.3054, (0.1s)\n",
            "Epoch [63/100]: train=2.3096 val=2.3054, (0.1s)\n",
            "Epoch [64/100]: train=2.3076 val=2.3054, (0.1s)\n",
            "Epoch [65/100]: train=2.3058 val=2.3054, (0.1s)\n",
            "Epoch [66/100]: train=2.306 val=2.3054, (0.1s)\n",
            "Epoch [67/100]: train=2.3061 val=2.3054, (0.1s)\n",
            "Epoch [68/100]: train=2.3054 val=2.3054, (0.1s)\n",
            "Epoch [69/100]: train=2.3069 val=2.3054, (0.1s)\n",
            "Epoch [70/100]: train=2.3057 val=2.3054, (0.1s)\n",
            "Epoch [71/100]: train=2.3062 val=2.3054, (0.1s)\n",
            "Epoch [72/100]: train=2.3079 val=2.3054, (0.1s)\n",
            "Epoch [73/100]: train=2.3078 val=2.3054, (0.1s)\n",
            "Epoch [74/100]: train=2.3076 val=2.3054, (0.1s)\n",
            "Epoch [75/100]: train=2.3062 val=2.3054, (0.1s)\n",
            "Epoch [76/100]: train=2.3057 val=2.3054, (0.1s)\n",
            "Epoch [77/100]: train=2.3078 val=2.3054, (0.1s)\n",
            "Epoch [78/100]: train=2.3067 val=2.3054, (0.1s)\n",
            "Epoch [79/100]: train=2.3066 val=2.3054, (0.1s)\n",
            "Epoch [80/100]: train=2.3079 val=2.3054, (0.1s)\n",
            "Epoch [81/100]: train=2.3067 val=2.3054, (0.1s)\n",
            "Epoch [82/100]: train=2.3066 val=2.3054, (0.1s)\n",
            "Epoch [83/100]: train=2.3071 val=2.3054, (0.1s)\n",
            "Epoch [84/100]: train=2.3068 val=2.3054, (0.1s)\n",
            "Epoch [85/100]: train=2.308 val=2.3054, (0.1s)\n",
            "Epoch [86/100]: train=2.3063 val=2.3054, (0.1s)\n",
            "Epoch [87/100]: train=2.3063 val=2.3054, (0.1s)\n",
            "Epoch [88/100]: train=2.3074 val=2.3054, (0.1s)\n",
            "Epoch [89/100]: train=2.3086 val=2.3054, (0.1s)\n",
            "Epoch [90/100]: train=2.3063 val=2.3054, (0.1s)\n",
            "Epoch [91/100]: train=2.3068 val=2.3054, (0.1s)\n",
            "Epoch [92/100]: train=2.3072 val=2.3054, (0.1s)\n",
            "Epoch [93/100]: train=2.3062 val=2.3054, (0.1s)\n",
            "Epoch [94/100]: train=2.3077 val=2.3054, (0.1s)\n",
            "Epoch [95/100]: train=2.3061 val=2.3054, (0.1s)\n",
            "Epoch [96/100]: train=2.3057 val=2.3054, (0.1s)\n",
            "Epoch [97/100]: train=2.307 val=2.3054, (0.1s)\n",
            "Epoch [98/100]: train=2.3065 val=2.3054, (0.1s)\n",
            "Epoch [99/100]: train=2.3065 val=2.3054, (0.1s)\n",
            "Epoch [100/100]: train=2.3062 val=2.3054, (0.1s)\n",
            "Training on task 6...\n",
            "Epoch [1/100]: train=2.3043 val=2.3011, (0.1s)\n",
            "Epoch [2/100]: train=2.3051 val=2.3011, (0.1s)\n",
            "Epoch [3/100]: train=2.304 val=2.3011, (0.1s)\n",
            "Epoch [4/100]: train=2.3059 val=2.3011, (0.1s)\n",
            "Epoch [5/100]: train=2.3062 val=2.3011, (0.1s)\n",
            "Epoch [6/100]: train=2.3056 val=2.3011, (0.1s)\n",
            "Epoch [7/100]: train=2.3047 val=2.3011, (0.1s)\n",
            "Epoch [8/100]: train=2.3035 val=2.3011, (0.1s)\n",
            "Epoch [9/100]: train=2.3053 val=2.3011, (0.1s)\n",
            "Epoch [10/100]: train=2.3044 val=2.3011, (0.1s)\n",
            "Epoch [11/100]: train=2.3071 val=2.3011, (0.1s)\n",
            "Epoch [12/100]: train=2.306 val=2.3011, (0.1s)\n",
            "Epoch [13/100]: train=2.3061 val=2.3011, (0.2s)\n",
            "Epoch [14/100]: train=2.3057 val=2.3011, (0.2s)\n",
            "Epoch [15/100]: train=2.3054 val=2.3011, (0.2s)\n",
            "Epoch [16/100]: train=2.3046 val=2.3011, (0.1s)\n",
            "Epoch [17/100]: train=2.3061 val=2.3011, (0.1s)\n",
            "Epoch [18/100]: train=2.3047 val=2.3011, (0.1s)\n",
            "Epoch [19/100]: train=2.3069 val=2.3011, (0.1s)\n",
            "Epoch [20/100]: train=2.3059 val=2.3011, (0.1s)\n",
            "Epoch [21/100]: train=2.3038 val=2.3011, (0.1s)\n",
            "Epoch [22/100]: train=2.3031 val=2.3011, (0.1s)\n",
            "Epoch [23/100]: train=2.3042 val=2.3011, (0.2s)\n",
            "Epoch [24/100]: train=2.3047 val=2.3011, (0.2s)\n",
            "Epoch [25/100]: train=2.3047 val=2.3011, (0.2s)\n",
            "Epoch [26/100]: train=2.3051 val=2.3011, (0.2s)\n",
            "Epoch [27/100]: train=2.3061 val=2.3011, (0.2s)\n",
            "Epoch [28/100]: train=2.3065 val=2.3011, (0.2s)\n",
            "Epoch [29/100]: train=2.3055 val=2.3011, (0.2s)\n",
            "Epoch [30/100]: train=2.3063 val=2.3011, (0.2s)\n",
            "Epoch [31/100]: train=2.3043 val=2.3011, (0.1s)\n",
            "Epoch [32/100]: train=2.3055 val=2.3011, (0.1s)\n",
            "Epoch [33/100]: train=2.3048 val=2.3011, (0.1s)\n",
            "Epoch [34/100]: train=2.3038 val=2.3011, (0.1s)\n",
            "Epoch [35/100]: train=2.3059 val=2.3011, (0.1s)\n",
            "Epoch [36/100]: train=2.3057 val=2.3011, (0.1s)\n",
            "Epoch [37/100]: train=2.3053 val=2.3011, (0.1s)\n",
            "Epoch [38/100]: train=2.3046 val=2.3011, (0.1s)\n",
            "Epoch [39/100]: train=2.3044 val=2.3011, (0.1s)\n",
            "Epoch [40/100]: train=2.3054 val=2.3011, (0.1s)\n",
            "Epoch [41/100]: train=2.3064 val=2.3011, (0.1s)\n",
            "Epoch [42/100]: train=2.3056 val=2.3011, (0.1s)\n",
            "Epoch [43/100]: train=2.3047 val=2.3011, (0.1s)\n",
            "Epoch [44/100]: train=2.3048 val=2.3011, (0.1s)\n",
            "Epoch [45/100]: train=2.3046 val=2.3011, (0.1s)\n",
            "Epoch [46/100]: train=2.305 val=2.3011, (0.1s)\n",
            "Epoch [47/100]: train=2.3055 val=2.3011, (0.1s)\n",
            "Epoch [48/100]: train=2.3059 val=2.3011, (0.1s)\n",
            "Epoch [49/100]: train=2.3051 val=2.3011, (0.1s)\n",
            "Epoch [50/100]: train=2.3036 val=2.3011, (0.1s)\n",
            "Epoch [51/100]: train=2.3038 val=2.3011, (0.1s)\n",
            "Epoch [52/100]: train=2.3049 val=2.3011, (0.1s)\n",
            "Epoch [53/100]: train=2.3057 val=2.3011, (0.1s)\n",
            "Epoch [54/100]: train=2.3042 val=2.3011, (0.1s)\n",
            "Epoch [55/100]: train=2.3057 val=2.3011, (0.1s)\n",
            "Epoch [56/100]: train=2.3054 val=2.3011, (0.1s)\n",
            "Epoch [57/100]: train=2.3055 val=2.3011, (0.1s)\n",
            "Epoch [58/100]: train=2.3031 val=2.3011, (0.1s)\n",
            "Epoch [59/100]: train=2.3056 val=2.3011, (0.1s)\n",
            "Epoch [60/100]: train=2.3054 val=2.3011, (0.1s)\n",
            "Epoch [61/100]: train=2.3067 val=2.3011, (0.1s)\n",
            "Epoch [62/100]: train=2.3059 val=2.3011, (0.1s)\n",
            "Epoch [63/100]: train=2.3033 val=2.3011, (0.1s)\n",
            "Epoch [64/100]: train=2.3067 val=2.3011, (0.1s)\n",
            "Epoch [65/100]: train=2.3054 val=2.3011, (0.1s)\n",
            "Epoch [66/100]: train=2.3047 val=2.3011, (0.1s)\n",
            "Epoch [67/100]: train=2.3056 val=2.3011, (0.1s)\n",
            "Epoch [68/100]: train=2.3048 val=2.3011, (0.1s)\n",
            "Epoch [69/100]: train=2.3051 val=2.3011, (0.1s)\n",
            "Epoch [70/100]: train=2.3054 val=2.3011, (0.1s)\n",
            "Epoch [71/100]: train=2.3051 val=2.3011, (0.1s)\n",
            "Epoch [72/100]: train=2.3062 val=2.3011, (0.1s)\n",
            "Epoch [73/100]: train=2.3046 val=2.3011, (0.1s)\n",
            "Epoch [74/100]: train=2.306 val=2.3011, (0.1s)\n",
            "Epoch [75/100]: train=2.3048 val=2.3011, (0.1s)\n",
            "Epoch [76/100]: train=2.3056 val=2.3011, (0.1s)\n",
            "Epoch [77/100]: train=2.3049 val=2.3011, (0.1s)\n",
            "Epoch [78/100]: train=2.3051 val=2.3011, (0.1s)\n",
            "Epoch [79/100]: train=2.3055 val=2.3011, (0.1s)\n",
            "Epoch [80/100]: train=2.305 val=2.3011, (0.1s)\n",
            "Epoch [81/100]: train=2.3058 val=2.3011, (0.1s)\n",
            "Epoch [82/100]: train=2.3047 val=2.3011, (0.1s)\n",
            "Epoch [83/100]: train=2.304 val=2.3011, (0.1s)\n",
            "Epoch [84/100]: train=2.305 val=2.3011, (0.1s)\n",
            "Epoch [85/100]: train=2.305 val=2.3011, (0.1s)\n",
            "Epoch [86/100]: train=2.3054 val=2.3011, (0.1s)\n",
            "Epoch [87/100]: train=2.3057 val=2.3011, (0.1s)\n",
            "Epoch [88/100]: train=2.305 val=2.3011, (0.1s)\n",
            "Epoch [89/100]: train=2.3051 val=2.3011, (0.1s)\n",
            "Epoch [90/100]: train=2.305 val=2.3011, (0.1s)\n",
            "Epoch [91/100]: train=2.3055 val=2.3011, (0.1s)\n",
            "Epoch [92/100]: train=2.3049 val=2.3011, (0.1s)\n",
            "Epoch [93/100]: train=2.3051 val=2.3011, (0.1s)\n",
            "Epoch [94/100]: train=2.3048 val=2.3011, (0.1s)\n",
            "Epoch [95/100]: train=2.3047 val=2.3011, (0.1s)\n",
            "Epoch [96/100]: train=2.3042 val=2.3011, (0.1s)\n",
            "Epoch [97/100]: train=2.3058 val=2.3011, (0.1s)\n",
            "Epoch [98/100]: train=2.3065 val=2.3011, (0.1s)\n",
            "Epoch [99/100]: train=2.3059 val=2.3011, (0.1s)\n",
            "Epoch [100/100]: train=2.3045 val=2.3011, (0.1s)\n",
            "Training on task 7...\n",
            "Epoch [1/100]: train=2.3057 val=2.3071, (0.1s)\n",
            "Epoch [2/100]: train=2.3054 val=2.3071, (0.1s)\n",
            "Epoch [3/100]: train=2.3059 val=2.3071, (0.1s)\n",
            "Epoch [4/100]: train=2.3068 val=2.3071, (0.1s)\n",
            "Epoch [5/100]: train=2.3057 val=2.3071, (0.1s)\n",
            "Epoch [6/100]: train=2.3051 val=2.3071, (0.1s)\n",
            "Epoch [7/100]: train=2.3049 val=2.3071, (0.1s)\n",
            "Epoch [8/100]: train=2.306 val=2.3071, (0.1s)\n",
            "Epoch [9/100]: train=2.3059 val=2.3071, (0.1s)\n",
            "Epoch [10/100]: train=2.3048 val=2.3071, (0.1s)\n",
            "Epoch [11/100]: train=2.3044 val=2.3071, (0.1s)\n",
            "Epoch [12/100]: train=2.3063 val=2.3071, (0.1s)\n",
            "Epoch [13/100]: train=2.3062 val=2.3071, (0.2s)\n",
            "Epoch [14/100]: train=2.3058 val=2.3071, (0.2s)\n",
            "Epoch [15/100]: train=2.3054 val=2.3071, (0.1s)\n",
            "Epoch [16/100]: train=2.3056 val=2.3071, (0.1s)\n",
            "Epoch [17/100]: train=2.3066 val=2.3071, (0.1s)\n",
            "Epoch [18/100]: train=2.3056 val=2.3071, (0.1s)\n",
            "Epoch [19/100]: train=2.3041 val=2.3071, (0.1s)\n",
            "Epoch [20/100]: train=2.3056 val=2.3071, (0.1s)\n",
            "Epoch [21/100]: train=2.3059 val=2.3071, (0.2s)\n",
            "Epoch [22/100]: train=2.3076 val=2.3071, (0.2s)\n",
            "Epoch [23/100]: train=2.3048 val=2.3071, (0.2s)\n",
            "Epoch [24/100]: train=2.3054 val=2.3071, (0.2s)\n",
            "Epoch [25/100]: train=2.3064 val=2.3071, (0.2s)\n",
            "Epoch [26/100]: train=2.3044 val=2.3071, (0.1s)\n",
            "Epoch [27/100]: train=2.3057 val=2.3071, (0.2s)\n",
            "Epoch [28/100]: train=2.3052 val=2.3071, (0.2s)\n",
            "Epoch [29/100]: train=2.3058 val=2.3071, (0.1s)\n",
            "Epoch [30/100]: train=2.3048 val=2.3071, (0.1s)\n",
            "Epoch [31/100]: train=2.3061 val=2.3071, (0.1s)\n",
            "Epoch [32/100]: train=2.3061 val=2.3071, (0.1s)\n",
            "Epoch [33/100]: train=2.3051 val=2.3071, (0.1s)\n",
            "Epoch [34/100]: train=2.3068 val=2.3071, (0.1s)\n",
            "Epoch [35/100]: train=2.3056 val=2.3071, (0.1s)\n",
            "Epoch [36/100]: train=2.3057 val=2.3071, (0.1s)\n",
            "Epoch [37/100]: train=2.3057 val=2.3071, (0.1s)\n",
            "Epoch [38/100]: train=2.3054 val=2.3071, (0.1s)\n",
            "Epoch [39/100]: train=2.3066 val=2.3071, (0.1s)\n",
            "Epoch [40/100]: train=2.3045 val=2.3071, (0.1s)\n",
            "Epoch [41/100]: train=2.3043 val=2.3071, (0.1s)\n",
            "Epoch [42/100]: train=2.3047 val=2.3071, (0.1s)\n",
            "Epoch [43/100]: train=2.3045 val=2.3071, (0.1s)\n",
            "Epoch [44/100]: train=2.3056 val=2.3071, (0.1s)\n",
            "Epoch [45/100]: train=2.3051 val=2.3071, (0.1s)\n",
            "Epoch [46/100]: train=2.3047 val=2.3071, (0.1s)\n",
            "Epoch [47/100]: train=2.306 val=2.3071, (0.1s)\n",
            "Epoch [48/100]: train=2.3068 val=2.3071, (0.1s)\n",
            "Epoch [49/100]: train=2.3057 val=2.3071, (0.1s)\n",
            "Epoch [50/100]: train=2.3067 val=2.3071, (0.1s)\n",
            "Epoch [51/100]: train=2.3065 val=2.3071, (0.1s)\n",
            "Epoch [52/100]: train=2.305 val=2.3071, (0.1s)\n",
            "Epoch [53/100]: train=2.3069 val=2.3071, (0.1s)\n",
            "Epoch [54/100]: train=2.3054 val=2.3071, (0.1s)\n",
            "Epoch [55/100]: train=2.3058 val=2.3071, (0.1s)\n",
            "Epoch [56/100]: train=2.3051 val=2.3071, (0.1s)\n",
            "Epoch [57/100]: train=2.3062 val=2.3071, (0.1s)\n",
            "Epoch [58/100]: train=2.3073 val=2.3071, (0.1s)\n",
            "Epoch [59/100]: train=2.3052 val=2.3071, (0.1s)\n",
            "Epoch [60/100]: train=2.3055 val=2.3071, (0.1s)\n",
            "Epoch [61/100]: train=2.306 val=2.3071, (0.1s)\n",
            "Epoch [62/100]: train=2.3049 val=2.3071, (0.1s)\n",
            "Epoch [63/100]: train=2.3056 val=2.3071, (0.1s)\n",
            "Epoch [64/100]: train=2.3036 val=2.3071, (0.1s)\n",
            "Epoch [65/100]: train=2.3053 val=2.3071, (0.1s)\n",
            "Epoch [66/100]: train=2.3069 val=2.3071, (0.1s)\n",
            "Epoch [67/100]: train=2.3061 val=2.3071, (0.1s)\n",
            "Epoch [68/100]: train=2.3052 val=2.3071, (0.1s)\n",
            "Epoch [69/100]: train=2.3057 val=2.3071, (0.1s)\n",
            "Epoch [70/100]: train=2.3054 val=2.3071, (0.1s)\n",
            "Epoch [71/100]: train=2.3058 val=2.3071, (0.1s)\n",
            "Epoch [72/100]: train=2.3053 val=2.3071, (0.1s)\n",
            "Epoch [73/100]: train=2.3046 val=2.3071, (0.1s)\n",
            "Epoch [74/100]: train=2.3039 val=2.3071, (0.1s)\n",
            "Epoch [75/100]: train=2.3046 val=2.3071, (0.1s)\n",
            "Epoch [76/100]: train=2.3056 val=2.3071, (0.1s)\n",
            "Epoch [77/100]: train=2.3069 val=2.3071, (0.1s)\n",
            "Epoch [78/100]: train=2.3049 val=2.3071, (0.1s)\n",
            "Epoch [79/100]: train=2.3059 val=2.3071, (0.1s)\n",
            "Epoch [80/100]: train=2.3051 val=2.3071, (0.1s)\n",
            "Epoch [81/100]: train=2.3068 val=2.3071, (0.1s)\n",
            "Epoch [82/100]: train=2.3035 val=2.3071, (0.1s)\n",
            "Epoch [83/100]: train=2.303 val=2.3071, (0.1s)\n",
            "Epoch [84/100]: train=2.3061 val=2.3071, (0.1s)\n",
            "Epoch [85/100]: train=2.3051 val=2.3071, (0.1s)\n",
            "Epoch [86/100]: train=2.3059 val=2.3071, (0.1s)\n",
            "Epoch [87/100]: train=2.3068 val=2.3071, (0.1s)\n",
            "Epoch [88/100]: train=2.3055 val=2.3071, (0.1s)\n",
            "Epoch [89/100]: train=2.3043 val=2.3071, (0.1s)\n",
            "Epoch [90/100]: train=2.3062 val=2.3071, (0.1s)\n",
            "Epoch [91/100]: train=2.3059 val=2.3071, (0.1s)\n",
            "Epoch [92/100]: train=2.3048 val=2.3071, (0.1s)\n",
            "Epoch [93/100]: train=2.304 val=2.3071, (0.1s)\n",
            "Epoch [94/100]: train=2.3048 val=2.3071, (0.1s)\n",
            "Epoch [95/100]: train=2.3046 val=2.3071, (0.1s)\n",
            "Epoch [96/100]: train=2.3048 val=2.3071, (0.1s)\n",
            "Epoch [97/100]: train=2.3042 val=2.3071, (0.1s)\n",
            "Epoch [98/100]: train=2.3047 val=2.3071, (0.1s)\n",
            "Epoch [99/100]: train=2.3058 val=2.3071, (0.1s)\n",
            "Epoch [100/100]: train=2.3059 val=2.3071, (0.1s)\n",
            "Training on task 8...\n",
            "Epoch [1/100]: train=2.3122 val=2.307, (0.1s)\n",
            "Epoch [2/100]: train=2.3112 val=2.307, (0.1s)\n",
            "Epoch [3/100]: train=2.3113 val=2.307, (0.1s)\n",
            "Epoch [4/100]: train=2.3103 val=2.307, (0.1s)\n",
            "Epoch [5/100]: train=2.3103 val=2.307, (0.1s)\n",
            "Epoch [6/100]: train=2.3112 val=2.307, (0.1s)\n",
            "Epoch [7/100]: train=2.311 val=2.307, (0.1s)\n",
            "Epoch [8/100]: train=2.3101 val=2.307, (0.1s)\n",
            "Epoch [9/100]: train=2.3107 val=2.307, (0.1s)\n",
            "Epoch [10/100]: train=2.3106 val=2.307, (0.1s)\n",
            "Epoch [11/100]: train=2.3109 val=2.307, (0.1s)\n",
            "Epoch [12/100]: train=2.3111 val=2.307, (0.1s)\n",
            "Epoch [13/100]: train=2.3103 val=2.307, (0.2s)\n",
            "Epoch [14/100]: train=2.3105 val=2.307, (0.1s)\n",
            "Epoch [15/100]: train=2.3108 val=2.307, (0.1s)\n",
            "Epoch [16/100]: train=2.3119 val=2.307, (0.1s)\n",
            "Epoch [17/100]: train=2.3105 val=2.307, (0.2s)\n",
            "Epoch [18/100]: train=2.3105 val=2.307, (0.1s)\n",
            "Epoch [19/100]: train=2.3108 val=2.307, (0.1s)\n",
            "Epoch [20/100]: train=2.312 val=2.307, (0.1s)\n",
            "Epoch [21/100]: train=2.3095 val=2.307, (0.1s)\n",
            "Epoch [22/100]: train=2.3104 val=2.307, (0.2s)\n",
            "Epoch [23/100]: train=2.31 val=2.307, (0.1s)\n",
            "Epoch [24/100]: train=2.3113 val=2.307, (0.2s)\n",
            "Epoch [25/100]: train=2.3115 val=2.307, (0.2s)\n",
            "Epoch [26/100]: train=2.312 val=2.307, (0.1s)\n",
            "Epoch [27/100]: train=2.3091 val=2.307, (0.2s)\n",
            "Epoch [28/100]: train=2.3107 val=2.307, (0.1s)\n",
            "Epoch [29/100]: train=2.3112 val=2.307, (0.2s)\n",
            "Epoch [30/100]: train=2.3097 val=2.307, (0.2s)\n",
            "Epoch [31/100]: train=2.3107 val=2.307, (0.1s)\n",
            "Epoch [32/100]: train=2.3106 val=2.307, (0.1s)\n",
            "Epoch [33/100]: train=2.312 val=2.307, (0.1s)\n",
            "Epoch [34/100]: train=2.3101 val=2.307, (0.1s)\n",
            "Epoch [35/100]: train=2.3104 val=2.307, (0.1s)\n",
            "Epoch [36/100]: train=2.311 val=2.307, (0.1s)\n",
            "Epoch [37/100]: train=2.3104 val=2.307, (0.1s)\n",
            "Epoch [38/100]: train=2.3117 val=2.307, (0.1s)\n",
            "Epoch [39/100]: train=2.3091 val=2.307, (0.1s)\n",
            "Epoch [40/100]: train=2.3111 val=2.307, (0.1s)\n",
            "Epoch [41/100]: train=2.3102 val=2.307, (0.1s)\n",
            "Epoch [42/100]: train=2.3103 val=2.307, (0.1s)\n",
            "Epoch [43/100]: train=2.3093 val=2.307, (0.1s)\n",
            "Epoch [44/100]: train=2.3093 val=2.307, (0.1s)\n",
            "Epoch [45/100]: train=2.3093 val=2.307, (0.1s)\n",
            "Epoch [46/100]: train=2.31 val=2.307, (0.1s)\n",
            "Epoch [47/100]: train=2.3114 val=2.307, (0.1s)\n",
            "Epoch [48/100]: train=2.3116 val=2.307, (0.1s)\n",
            "Epoch [49/100]: train=2.3117 val=2.307, (0.1s)\n",
            "Epoch [50/100]: train=2.312 val=2.307, (0.1s)\n",
            "Epoch [51/100]: train=2.3101 val=2.307, (0.1s)\n",
            "Epoch [52/100]: train=2.3124 val=2.307, (0.1s)\n",
            "Epoch [53/100]: train=2.3106 val=2.307, (0.1s)\n",
            "Epoch [54/100]: train=2.3106 val=2.307, (0.1s)\n",
            "Epoch [55/100]: train=2.3107 val=2.307, (0.1s)\n",
            "Epoch [56/100]: train=2.3111 val=2.307, (0.1s)\n",
            "Epoch [57/100]: train=2.3111 val=2.307, (0.1s)\n",
            "Epoch [58/100]: train=2.311 val=2.307, (0.1s)\n",
            "Epoch [59/100]: train=2.3117 val=2.307, (0.1s)\n",
            "Epoch [60/100]: train=2.3112 val=2.307, (0.1s)\n",
            "Epoch [61/100]: train=2.3108 val=2.307, (0.1s)\n",
            "Epoch [62/100]: train=2.3107 val=2.307, (0.1s)\n",
            "Epoch [63/100]: train=2.3101 val=2.307, (0.1s)\n",
            "Epoch [64/100]: train=2.3118 val=2.307, (0.1s)\n",
            "Epoch [65/100]: train=2.3102 val=2.307, (0.1s)\n",
            "Epoch [66/100]: train=2.3104 val=2.307, (0.1s)\n",
            "Epoch [67/100]: train=2.3104 val=2.307, (0.1s)\n",
            "Epoch [68/100]: train=2.3101 val=2.307, (0.1s)\n",
            "Epoch [69/100]: train=2.3104 val=2.307, (0.1s)\n",
            "Epoch [70/100]: train=2.3112 val=2.307, (0.1s)\n",
            "Epoch [71/100]: train=2.3111 val=2.307, (0.1s)\n",
            "Epoch [72/100]: train=2.3105 val=2.307, (0.1s)\n",
            "Epoch [73/100]: train=2.3108 val=2.307, (0.1s)\n",
            "Epoch [74/100]: train=2.3104 val=2.307, (0.1s)\n",
            "Epoch [75/100]: train=2.3103 val=2.307, (0.1s)\n",
            "Epoch [76/100]: train=2.3105 val=2.307, (0.1s)\n",
            "Epoch [77/100]: train=2.3116 val=2.307, (0.1s)\n",
            "Epoch [78/100]: train=2.3114 val=2.307, (0.1s)\n",
            "Epoch [79/100]: train=2.311 val=2.307, (0.1s)\n",
            "Epoch [80/100]: train=2.3108 val=2.307, (0.1s)\n",
            "Epoch [81/100]: train=2.3091 val=2.307, (0.1s)\n",
            "Epoch [82/100]: train=2.3117 val=2.307, (0.1s)\n",
            "Epoch [83/100]: train=2.3086 val=2.307, (0.1s)\n",
            "Epoch [84/100]: train=2.311 val=2.307, (0.1s)\n",
            "Epoch [85/100]: train=2.3097 val=2.307, (0.1s)\n",
            "Epoch [86/100]: train=2.3108 val=2.307, (0.1s)\n",
            "Epoch [87/100]: train=2.3102 val=2.307, (0.1s)\n",
            "Epoch [88/100]: train=2.3105 val=2.307, (0.1s)\n",
            "Epoch [89/100]: train=2.3103 val=2.307, (0.1s)\n",
            "Epoch [90/100]: train=2.31 val=2.307, (0.1s)\n",
            "Epoch [91/100]: train=2.3109 val=2.307, (0.1s)\n",
            "Epoch [92/100]: train=2.3099 val=2.307, (0.1s)\n",
            "Epoch [93/100]: train=2.3106 val=2.307, (0.1s)\n",
            "Epoch [94/100]: train=2.3121 val=2.307, (0.1s)\n",
            "Epoch [95/100]: train=2.3105 val=2.307, (0.1s)\n",
            "Epoch [96/100]: train=2.3104 val=2.307, (0.1s)\n",
            "Epoch [97/100]: train=2.3095 val=2.307, (0.1s)\n",
            "Epoch [98/100]: train=2.3113 val=2.307, (0.1s)\n",
            "Epoch [99/100]: train=2.3114 val=2.307, (0.1s)\n",
            "Epoch [100/100]: train=2.3095 val=2.307, (0.1s)\n",
            "Training on task 9...\n",
            "Epoch [1/100]: train=2.307 val=2.3075, (0.1s)\n",
            "Epoch [2/100]: train=2.3093 val=2.3075, (0.1s)\n",
            "Epoch [3/100]: train=2.3091 val=2.3075, (0.1s)\n",
            "Epoch [4/100]: train=2.3087 val=2.3075, (0.1s)\n",
            "Epoch [5/100]: train=2.3087 val=2.3075, (0.1s)\n",
            "Epoch [6/100]: train=2.3085 val=2.3075, (0.1s)\n",
            "Epoch [7/100]: train=2.3086 val=2.3075, (0.1s)\n",
            "Epoch [8/100]: train=2.309 val=2.3075, (0.1s)\n",
            "Epoch [9/100]: train=2.3089 val=2.3075, (0.1s)\n",
            "Epoch [10/100]: train=2.3077 val=2.3075, (0.1s)\n",
            "Epoch [11/100]: train=2.3088 val=2.3075, (0.1s)\n",
            "Epoch [12/100]: train=2.3083 val=2.3075, (0.1s)\n",
            "Epoch [13/100]: train=2.3086 val=2.3075, (0.1s)\n",
            "Epoch [14/100]: train=2.3082 val=2.3075, (0.1s)\n",
            "Epoch [15/100]: train=2.3082 val=2.3075, (0.2s)\n",
            "Epoch [16/100]: train=2.308 val=2.3075, (0.1s)\n",
            "Epoch [17/100]: train=2.3101 val=2.3075, (0.1s)\n",
            "Epoch [18/100]: train=2.3081 val=2.3075, (0.2s)\n",
            "Epoch [19/100]: train=2.3089 val=2.3075, (0.1s)\n",
            "Epoch [20/100]: train=2.3092 val=2.3075, (0.1s)\n",
            "Epoch [21/100]: train=2.3092 val=2.3075, (0.1s)\n",
            "Epoch [22/100]: train=2.3079 val=2.3075, (0.1s)\n",
            "Epoch [23/100]: train=2.3087 val=2.3075, (0.2s)\n",
            "Epoch [24/100]: train=2.3087 val=2.3075, (0.1s)\n",
            "Epoch [25/100]: train=2.309 val=2.3075, (0.2s)\n",
            "Epoch [26/100]: train=2.308 val=2.3075, (0.2s)\n",
            "Epoch [27/100]: train=2.3089 val=2.3075, (0.2s)\n",
            "Epoch [28/100]: train=2.3074 val=2.3075, (0.1s)\n",
            "Epoch [29/100]: train=2.3101 val=2.3075, (0.2s)\n",
            "Epoch [30/100]: train=2.3084 val=2.3075, (0.1s)\n",
            "Epoch [31/100]: train=2.3087 val=2.3075, (0.1s)\n",
            "Epoch [32/100]: train=2.31 val=2.3075, (0.1s)\n",
            "Epoch [33/100]: train=2.3092 val=2.3075, (0.1s)\n",
            "Epoch [34/100]: train=2.3092 val=2.3075, (0.1s)\n",
            "Epoch [35/100]: train=2.3089 val=2.3075, (0.1s)\n",
            "Epoch [36/100]: train=2.3087 val=2.3075, (0.1s)\n",
            "Epoch [37/100]: train=2.3088 val=2.3075, (0.1s)\n",
            "Epoch [38/100]: train=2.3088 val=2.3075, (0.1s)\n",
            "Epoch [39/100]: train=2.3082 val=2.3075, (0.1s)\n",
            "Epoch [40/100]: train=2.3085 val=2.3075, (0.1s)\n",
            "Epoch [41/100]: train=2.3083 val=2.3075, (0.1s)\n",
            "Epoch [42/100]: train=2.3089 val=2.3075, (0.1s)\n",
            "Epoch [43/100]: train=2.3089 val=2.3075, (0.1s)\n",
            "Epoch [44/100]: train=2.3067 val=2.3075, (0.1s)\n",
            "Epoch [45/100]: train=2.3086 val=2.3075, (0.1s)\n",
            "Epoch [46/100]: train=2.3067 val=2.3075, (0.1s)\n",
            "Epoch [47/100]: train=2.3098 val=2.3075, (0.1s)\n",
            "Epoch [48/100]: train=2.3089 val=2.3075, (0.1s)\n",
            "Epoch [49/100]: train=2.3084 val=2.3075, (0.1s)\n",
            "Epoch [50/100]: train=2.3081 val=2.3075, (0.1s)\n",
            "Epoch [51/100]: train=2.3087 val=2.3075, (0.1s)\n",
            "Epoch [52/100]: train=2.3079 val=2.3075, (0.1s)\n",
            "Epoch [53/100]: train=2.3075 val=2.3075, (0.1s)\n",
            "Epoch [54/100]: train=2.3091 val=2.3075, (0.1s)\n",
            "Epoch [55/100]: train=2.3083 val=2.3075, (0.1s)\n",
            "Epoch [56/100]: train=2.3093 val=2.3075, (0.1s)\n",
            "Epoch [57/100]: train=2.3079 val=2.3075, (0.1s)\n",
            "Epoch [58/100]: train=2.3073 val=2.3075, (0.1s)\n",
            "Epoch [59/100]: train=2.3087 val=2.3075, (0.1s)\n",
            "Epoch [60/100]: train=2.3071 val=2.3075, (0.1s)\n",
            "Epoch [61/100]: train=2.3079 val=2.3075, (0.1s)\n",
            "Epoch [62/100]: train=2.3082 val=2.3075, (0.1s)\n",
            "Epoch [63/100]: train=2.3095 val=2.3075, (0.1s)\n",
            "Epoch [64/100]: train=2.3084 val=2.3075, (0.1s)\n",
            "Epoch [65/100]: train=2.3083 val=2.3075, (0.1s)\n",
            "Epoch [66/100]: train=2.3081 val=2.3075, (0.1s)\n",
            "Epoch [67/100]: train=2.307 val=2.3075, (0.1s)\n",
            "Epoch [68/100]: train=2.3112 val=2.3075, (0.1s)\n",
            "Epoch [69/100]: train=2.309 val=2.3075, (0.1s)\n",
            "Epoch [70/100]: train=2.308 val=2.3075, (0.1s)\n",
            "Epoch [71/100]: train=2.3107 val=2.3075, (0.1s)\n",
            "Epoch [72/100]: train=2.3088 val=2.3075, (0.1s)\n",
            "Epoch [73/100]: train=2.3077 val=2.3075, (0.1s)\n",
            "Epoch [74/100]: train=2.3095 val=2.3075, (0.1s)\n",
            "Epoch [75/100]: train=2.308 val=2.3075, (0.1s)\n",
            "Epoch [76/100]: train=2.3089 val=2.3075, (0.1s)\n",
            "Epoch [77/100]: train=2.3102 val=2.3075, (0.1s)\n",
            "Epoch [78/100]: train=2.3085 val=2.3075, (0.1s)\n",
            "Epoch [79/100]: train=2.3079 val=2.3075, (0.1s)\n",
            "Epoch [80/100]: train=2.3089 val=2.3075, (0.1s)\n",
            "Epoch [81/100]: train=2.3079 val=2.3075, (0.1s)\n",
            "Epoch [82/100]: train=2.3085 val=2.3075, (0.1s)\n",
            "Epoch [83/100]: train=2.3101 val=2.3075, (0.1s)\n",
            "Epoch [84/100]: train=2.3083 val=2.3075, (0.1s)\n",
            "Epoch [85/100]: train=2.3083 val=2.3075, (0.1s)\n",
            "Epoch [86/100]: train=2.3091 val=2.3075, (0.1s)\n",
            "Epoch [87/100]: train=2.3083 val=2.3075, (0.1s)\n",
            "Epoch [88/100]: train=2.3094 val=2.3075, (0.1s)\n",
            "Epoch [89/100]: train=2.3084 val=2.3075, (0.1s)\n",
            "Epoch [90/100]: train=2.3091 val=2.3075, (0.1s)\n",
            "Epoch [91/100]: train=2.3096 val=2.3075, (0.1s)\n",
            "Epoch [92/100]: train=2.308 val=2.3075, (0.1s)\n",
            "Epoch [93/100]: train=2.3088 val=2.3075, (0.1s)\n",
            "Epoch [94/100]: train=2.3093 val=2.3075, (0.1s)\n",
            "Epoch [95/100]: train=2.3095 val=2.3075, (0.1s)\n",
            "Epoch [96/100]: train=2.3092 val=2.3075, (0.1s)\n",
            "Epoch [97/100]: train=2.3095 val=2.3075, (0.1s)\n",
            "Epoch [98/100]: train=2.3079 val=2.3075, (0.1s)\n",
            "Epoch [99/100]: train=2.3104 val=2.3075, (0.1s)\n",
            "Epoch [100/100]: train=2.3074 val=2.3075, (0.1s)\n",
            "Training on task 10...\n",
            "Epoch [1/100]: train=2.3052 val=2.3071, (0.1s)\n",
            "Epoch [2/100]: train=2.3043 val=2.3071, (0.1s)\n",
            "Epoch [3/100]: train=2.3049 val=2.3071, (0.1s)\n",
            "Epoch [4/100]: train=2.3032 val=2.3071, (0.1s)\n",
            "Epoch [5/100]: train=2.3048 val=2.3071, (0.1s)\n",
            "Epoch [6/100]: train=2.3042 val=2.3071, (0.1s)\n",
            "Epoch [7/100]: train=2.3048 val=2.3071, (0.1s)\n",
            "Epoch [8/100]: train=2.3044 val=2.3071, (0.1s)\n",
            "Epoch [9/100]: train=2.3045 val=2.3071, (0.1s)\n",
            "Epoch [10/100]: train=2.305 val=2.3071, (0.1s)\n",
            "Epoch [11/100]: train=2.3034 val=2.3071, (0.1s)\n",
            "Epoch [12/100]: train=2.3056 val=2.3071, (0.1s)\n",
            "Epoch [13/100]: train=2.3046 val=2.3071, (0.1s)\n",
            "Epoch [14/100]: train=2.3039 val=2.3071, (0.1s)\n",
            "Epoch [15/100]: train=2.3043 val=2.3071, (0.1s)\n",
            "Epoch [16/100]: train=2.3048 val=2.3071, (0.1s)\n",
            "Epoch [17/100]: train=2.3045 val=2.3071, (0.1s)\n",
            "Epoch [18/100]: train=2.305 val=2.3071, (0.1s)\n",
            "Epoch [19/100]: train=2.3066 val=2.3071, (0.1s)\n",
            "Epoch [20/100]: train=2.3047 val=2.3071, (0.1s)\n",
            "Epoch [21/100]: train=2.3049 val=2.3071, (0.1s)\n",
            "Epoch [22/100]: train=2.3044 val=2.3071, (0.1s)\n",
            "Epoch [23/100]: train=2.3056 val=2.3071, (0.2s)\n",
            "Epoch [24/100]: train=2.306 val=2.3071, (0.1s)\n",
            "Epoch [25/100]: train=2.3045 val=2.3071, (0.2s)\n",
            "Epoch [26/100]: train=2.305 val=2.3071, (0.1s)\n",
            "Epoch [27/100]: train=2.3044 val=2.3071, (0.2s)\n",
            "Epoch [28/100]: train=2.304 val=2.3071, (0.1s)\n",
            "Epoch [29/100]: train=2.3041 val=2.3071, (0.2s)\n",
            "Epoch [30/100]: train=2.3042 val=2.3071, (0.1s)\n",
            "Epoch [31/100]: train=2.3049 val=2.3071, (0.2s)\n",
            "Epoch [32/100]: train=2.3056 val=2.3071, (0.1s)\n",
            "Epoch [33/100]: train=2.3045 val=2.3071, (0.1s)\n",
            "Epoch [34/100]: train=2.3052 val=2.3071, (0.1s)\n",
            "Epoch [35/100]: train=2.3044 val=2.3071, (0.1s)\n",
            "Epoch [36/100]: train=2.3039 val=2.3071, (0.1s)\n",
            "Epoch [37/100]: train=2.3045 val=2.3071, (0.1s)\n",
            "Epoch [38/100]: train=2.3022 val=2.3071, (0.1s)\n",
            "Epoch [39/100]: train=2.3053 val=2.3071, (0.1s)\n",
            "Epoch [40/100]: train=2.305 val=2.3071, (0.1s)\n",
            "Epoch [41/100]: train=2.3038 val=2.3071, (0.1s)\n",
            "Epoch [42/100]: train=2.3048 val=2.3071, (0.1s)\n",
            "Epoch [43/100]: train=2.3035 val=2.3071, (0.1s)\n",
            "Epoch [44/100]: train=2.3036 val=2.3071, (0.1s)\n",
            "Epoch [45/100]: train=2.3035 val=2.3071, (0.1s)\n",
            "Epoch [46/100]: train=2.3042 val=2.3071, (0.1s)\n",
            "Epoch [47/100]: train=2.3059 val=2.3071, (0.1s)\n",
            "Epoch [48/100]: train=2.3045 val=2.3071, (0.1s)\n",
            "Epoch [49/100]: train=2.3053 val=2.3071, (0.1s)\n",
            "Epoch [50/100]: train=2.3044 val=2.3071, (0.1s)\n",
            "Epoch [51/100]: train=2.3042 val=2.3071, (0.1s)\n",
            "Epoch [52/100]: train=2.3044 val=2.3071, (0.1s)\n",
            "Epoch [53/100]: train=2.3053 val=2.3071, (0.1s)\n",
            "Epoch [54/100]: train=2.3039 val=2.3071, (0.1s)\n",
            "Epoch [55/100]: train=2.305 val=2.3071, (0.1s)\n",
            "Epoch [56/100]: train=2.3041 val=2.3071, (0.1s)\n",
            "Epoch [57/100]: train=2.3058 val=2.3071, (0.1s)\n",
            "Epoch [58/100]: train=2.3058 val=2.3071, (0.1s)\n",
            "Epoch [59/100]: train=2.3068 val=2.3071, (0.1s)\n",
            "Epoch [60/100]: train=2.3051 val=2.3071, (0.1s)\n",
            "Epoch [61/100]: train=2.3041 val=2.3071, (0.1s)\n",
            "Epoch [62/100]: train=2.3047 val=2.3071, (0.1s)\n",
            "Epoch [63/100]: train=2.3049 val=2.3071, (0.1s)\n",
            "Epoch [64/100]: train=2.3035 val=2.3071, (0.1s)\n",
            "Epoch [65/100]: train=2.304 val=2.3071, (0.1s)\n",
            "Epoch [66/100]: train=2.3036 val=2.3071, (0.1s)\n",
            "Epoch [67/100]: train=2.3054 val=2.3071, (0.1s)\n",
            "Epoch [68/100]: train=2.3036 val=2.3071, (0.1s)\n",
            "Epoch [69/100]: train=2.3064 val=2.3071, (0.1s)\n",
            "Epoch [70/100]: train=2.3042 val=2.3071, (0.1s)\n",
            "Epoch [71/100]: train=2.3039 val=2.3071, (0.1s)\n",
            "Epoch [72/100]: train=2.3036 val=2.3071, (0.1s)\n",
            "Epoch [73/100]: train=2.3054 val=2.3071, (0.1s)\n",
            "Epoch [74/100]: train=2.3048 val=2.3071, (0.1s)\n",
            "Epoch [75/100]: train=2.3058 val=2.3071, (0.1s)\n",
            "Epoch [76/100]: train=2.3045 val=2.3071, (0.1s)\n",
            "Epoch [77/100]: train=2.3055 val=2.3071, (0.1s)\n",
            "Epoch [78/100]: train=2.3063 val=2.3071, (0.1s)\n",
            "Epoch [79/100]: train=2.3044 val=2.3071, (0.1s)\n",
            "Epoch [80/100]: train=2.3038 val=2.3071, (0.1s)\n",
            "Epoch [81/100]: train=2.3042 val=2.3071, (0.1s)\n",
            "Epoch [82/100]: train=2.3059 val=2.3071, (0.1s)\n",
            "Epoch [83/100]: train=2.3051 val=2.3071, (0.1s)\n",
            "Epoch [84/100]: train=2.3042 val=2.3071, (0.1s)\n",
            "Epoch [85/100]: train=2.3041 val=2.3071, (0.1s)\n",
            "Epoch [86/100]: train=2.3054 val=2.3071, (0.1s)\n",
            "Epoch [87/100]: train=2.3057 val=2.3071, (0.1s)\n",
            "Epoch [88/100]: train=2.3047 val=2.3071, (0.1s)\n",
            "Epoch [89/100]: train=2.3046 val=2.3071, (0.1s)\n",
            "Epoch [90/100]: train=2.3062 val=2.3071, (0.1s)\n",
            "Epoch [91/100]: train=2.3056 val=2.3071, (0.1s)\n",
            "Epoch [92/100]: train=2.3044 val=2.3071, (0.1s)\n",
            "Epoch [93/100]: train=2.3057 val=2.3071, (0.1s)\n",
            "Epoch [94/100]: train=2.3033 val=2.3071, (0.1s)\n",
            "Epoch [95/100]: train=2.3051 val=2.3071, (0.1s)\n",
            "Epoch [96/100]: train=2.3044 val=2.3071, (0.1s)\n",
            "Epoch [97/100]: train=2.3045 val=2.3071, (0.1s)\n",
            "Epoch [98/100]: train=2.3049 val=2.3071, (0.1s)\n",
            "Epoch [99/100]: train=2.3051 val=2.3071, (0.1s)\n",
            "Epoch [100/100]: train=2.3046 val=2.3071, (0.1s)\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "#################################################################################\n",
        "# N_EPOCHS    = Number of epochs per task.\n",
        "# N_TASKS     = Number of tasks to train the model on.\n",
        "# DATASET_GEN = Type of tasks. We can choose between permuted MNIST and rotated MNIST\n",
        "# REGUL_TYPE  = Type of regularization. Very important for the paper, as it changes the training process.\n",
        "#               - `SGD` | Classic SGD with no regularization term\n",
        "#               - `L2`  | SGD with L2 regularization term\n",
        "#               - `EWC` | SGD with elastic weight consolidation regularization\n",
        "#################################################################################\n",
        "N_EPOCHS    = 100\n",
        "N_TASKS     = 10\n",
        "DATASET_GEN = generate_rotated_mnist\n",
        "lambda_regul = 10\n",
        "\n",
        "train_dataloaders, val_dataloaders, test_dataloaders = generate_tasks(N_TASKS, DATASET_GEN)\n",
        "\n",
        "\n",
        "\n",
        "for REGUL_TYPE in [\"EWC\", \"SGD\", \"SGD_one_task\"]:\n",
        "    print('================================================')\n",
        "    print(REGUL_TYPE)\n",
        "    # Initialize model\n",
        "    model = SmallNet(width_hidden_layers=2000)\n",
        "    model.to(device)\n",
        "    # Loss, optimizer and scheduler\n",
        "    if REGUL_TYPE == 'SGD' or REGUL_TYPE == 'SGD_one_task':\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)#, momentum=0.9)\n",
        "        criterion = F.cross_entropy\n",
        "    elif REGUL_TYPE == 'L2':\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4)\n",
        "        criterion = F.cross_entropy\n",
        "    elif REGUL_TYPE == 'EWC':\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)#, momentum=0.9)\n",
        "    else:\n",
        "        raise Exception('Invalid regularization')\n",
        "\n",
        "\n",
        "\n",
        "    full_test_accuracies = []\n",
        "    penalties_ewc = []\n",
        "    for i_task in range(0, N_TASKS):\n",
        "\n",
        "        # Get tasks\n",
        "        train_dataloader = train_dataloaders[i_task]\n",
        "        val_dataloader = val_dataloaders[i_task]\n",
        "\n",
        "        if REGUL_TYPE == 'SGD_one_task' :\n",
        "            # Reset model\n",
        "            model = SmallNet(width_hidden_layers=2000)\n",
        "            model.to(device)\n",
        "\n",
        "\n",
        "        print(f'Training on task {i_task + 1}...')\n",
        "\n",
        "        # Fit on task\n",
        "        if REGUL_TYPE == 'EWC': # Need to redefine the loss function with the fisher of the former task\n",
        "            penalties_ewc.append(EWC(model, dataset=train_dataloader).penalty) # Add one regularization per task, as proposed by Kirkpatrick et al.\n",
        "            def ewc_loss(output, target, new_model):\n",
        "                loss = F.cross_entropy(output, target)\n",
        "                for penalty in penalties_ewc:\n",
        "                    loss += lambda_regul * penalty(new_model)\n",
        "                return loss\n",
        "            criterion = ewc_loss\n",
        "\n",
        "\n",
        "        train_losses, val_losses = fit(\n",
        "                model=model,\n",
        "                train_dataloader=train_dataloader,\n",
        "                val_dataloader=val_dataloader,\n",
        "                optimizer=optimizer,\n",
        "                scheduler=None,\n",
        "                criterion=criterion,\n",
        "                epochs=N_EPOCHS,\n",
        "                device=device,\n",
        "                early_stopping = True\n",
        "            )\n",
        "\n",
        "        # After training on n_tasks, we evaluate the model on all the tasks it learnt.\n",
        "        if i_task >=1:  # At least two tasks learnt\n",
        "          if REGUL_TYPE == \"SGD_one_task\":\n",
        "            test_dataloader = test_dataloaders[i_task]\n",
        "          else:\n",
        "            test_dataloader = DataLoader(torch.utils.data.ConcatDataset([test_dataloaders[j].dataset for j in range(i_task+1)]))\n",
        "          full_test_accuracies.append(evaluate_accuracy(model, test_dataloader, device))\n",
        "\n",
        "    # Save model and metrics\n",
        "    np.save(f'{REGUL_TYPE}_test_accuracy_Fig_2b.npy', np.array(full_test_accuracies))\n",
        "\n",
        "\n",
        "print('Done!');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFMHm2INpVBc",
        "outputId": "5b9f6ad2-cdac-4d67-aade-fa83d7cd8659"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.052, 0.1]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "full_test_accuracies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g67RcIvZ7Cj"
      },
      "source": [
        "## Generate Figure 2B\n",
        "\n",
        "Follow these steps to generate figure 2B. You can then redo all these steps after changing the dataset from permuted to rotated MNIST using the option `DATASET_GEN`.\n",
        "The regularization technique used can be chosen by changing the option `REGUL_TYPE`. Each reg technique will save their respective train accuracy curves to different files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "93jO6ImkZ7Cj",
        "outputId": "98a9d101-7c66-4703-89e6-5283a2a86665"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "FILE_NAMES = [\n",
        "    'SGD',\n",
        "    'SGD_one_task',\n",
        "    'EWC',\n",
        "]\n",
        "color_dict = {'SGD':\"blue\",\n",
        "              'SGD_one_task': 'black',\n",
        "              'EWC':'red'}\n",
        "legend_dict = {'SGD':'SGD + Dropout',\n",
        "                'SGD_one_task': 'Single task performance',\n",
        "                'EWC':'EWC'}\n",
        "\n",
        "\n",
        "for file_name in FILE_NAMES:\n",
        "    test_accuracy = np.load(f'{file_name}_test_accuracy_Fig_2b.npy')\n",
        "    plt.plot(range(2, N_TASKS +1), test_accuracy, label=file_name, color = color_dict[file_name], alpha = 0.8, marker = 'o')\n",
        "\n",
        "\n",
        "plt.ylabel('Frac. correct')\n",
        "plt.xlabel('Number of tasks')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
